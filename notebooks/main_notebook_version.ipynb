{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "from config.execution_parameters import *\n",
    "\n",
    "# Project libraries\n",
    "from src.simulator_package.simulator_functions import *\n",
    "import src.hmm_package.generate_hmm\n",
    "from src.hmm_package.generate_hmm import *\n",
    "from src.plot_and_print_info.plots_and_print_info import *\n",
    "\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "importlib.reload(src.hmm_package.generate_hmm)\n",
    "from src.hmm_package.generate_hmm import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 18:24:57.188841: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "advertising_campaign = SimulationClass(ANALYSIS_MODE)\n",
    "advertising_campaign.simulate()\n",
    "\n",
    "adstock = compute_adstock(observation=advertising_campaign.results[\"user_expositions\"])\n",
    "output = np.append( np.zeros([adstock.shape[0], 1]), advertising_campaign.results[\"user_outcome\"], axis=1 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([12860, 3, 31])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    adstock.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "empty_users = 8000\n",
    "adstock_with_empty = tf.concat([adstock, tf.zeros([empty_users, adstock.shape[1], adstock.shape[2]], dtype=float)], axis = 0)\n",
    "output_with_empty = np.append(output, np.zeros([empty_users, adstock.shape[2]]), axis = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "adstock_with_empty = tf.zeros([2000, adstock.shape[1], adstock.shape[2]], dtype=float)\n",
    "output_with_empty = np.zeros([2000, adstock.shape[2]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 23s 3s/step - loss: 3048.9768\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 22s 3s/step - loss: 2955.5283\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 21s 3s/step - loss: 2932.1565\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 24s 3s/step - loss: 2908.9656\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 27s 3s/step - loss: 2885.9661\n",
      "Epoch 6/100\n",
      "3/8 [==========>...................] - ETA: 18s - loss: 2926.8997"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [31]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m compiler \u001B[38;5;241m=\u001B[39m CompilerInfo(LR_EXPONENTIAL_DECAY)\n\u001B[1;32m      4\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(\n\u001B[1;32m      5\u001B[0m     loss \u001B[38;5;241m=\u001B[39m compiler\u001B[38;5;241m.\u001B[39mloss,\n\u001B[1;32m      6\u001B[0m     optimizer \u001B[38;5;241m=\u001B[39m compiler\u001B[38;5;241m.\u001B[39moptimizer,\n\u001B[1;32m      7\u001B[0m     run_eagerly \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m      8\u001B[0m )\n\u001B[0;32m---> 10\u001B[0m \u001B[43mfit_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madstock_with_empty\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_with_empty\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/AttributionSingleUser/src/hmm_package/generate_hmm.py:222\u001B[0m, in \u001B[0;36mfit_model\u001B[0;34m(model, adstock, emission_real)\u001B[0m\n\u001B[1;32m    221\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit_model\u001B[39m(model, adstock, emission_real):\n\u001B[0;32m--> 222\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43madstock\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    223\u001B[0m \u001B[43m                     \u001B[49m\u001B[43memission_real\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    224\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mEPOCHS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    225\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    226\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/engine/training.py:1384\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1377\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1378\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   1379\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   1380\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[1;32m   1381\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m   1382\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m   1383\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1384\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1385\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1386\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/engine/training.py:1021\u001B[0m, in \u001B[0;36mModel.make_train_function.<locals>.train_function\u001B[0;34m(iterator)\u001B[0m\n\u001B[1;32m   1019\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_function\u001B[39m(iterator):\n\u001B[1;32m   1020\u001B[0m   \u001B[38;5;124;03m\"\"\"Runs a training execution with a single step.\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1021\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mstep_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/engine/training.py:1010\u001B[0m, in \u001B[0;36mModel.make_train_function.<locals>.step_function\u001B[0;34m(model, iterator)\u001B[0m\n\u001B[1;32m   1007\u001B[0m   run_step \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mfunction(\n\u001B[1;32m   1008\u001B[0m       run_step, jit_compile\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, experimental_relax_shapes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   1009\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(iterator)\n\u001B[0;32m-> 1010\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistribute_strategy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_step\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1011\u001B[0m outputs \u001B[38;5;241m=\u001B[39m reduce_per_replica(\n\u001B[1;32m   1012\u001B[0m     outputs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistribute_strategy, reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfirst\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m   1013\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1312\u001B[0m, in \u001B[0;36mStrategyBase.run\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m   1307\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscope():\n\u001B[1;32m   1308\u001B[0m   \u001B[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001B[39;00m\n\u001B[1;32m   1309\u001B[0m   \u001B[38;5;66;03m# applied when the caller is also in Eager mode.\u001B[39;00m\n\u001B[1;32m   1310\u001B[0m   fn \u001B[38;5;241m=\u001B[39m autograph\u001B[38;5;241m.\u001B[39mtf_convert(\n\u001B[1;32m   1311\u001B[0m       fn, autograph_ctx\u001B[38;5;241m.\u001B[39mcontrol_status_ctx(), convert_by_default\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m-> 1312\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_extended\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_for_each_replica\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2888\u001B[0m, in \u001B[0;36mStrategyExtendedV1.call_for_each_replica\u001B[0;34m(self, fn, args, kwargs)\u001B[0m\n\u001B[1;32m   2886\u001B[0m   kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m   2887\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_container_strategy()\u001B[38;5;241m.\u001B[39mscope():\n\u001B[0;32m-> 2888\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_for_each_replica\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3689\u001B[0m, in \u001B[0;36m_DefaultDistributionExtended._call_for_each_replica\u001B[0;34m(self, fn, args, kwargs)\u001B[0m\n\u001B[1;32m   3687\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_call_for_each_replica\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn, args, kwargs):\n\u001B[1;32m   3688\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ReplicaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_container_strategy(), replica_id_in_sync_group\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m-> 3689\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:595\u001B[0m, in \u001B[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    593\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    594\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ag_ctx\u001B[38;5;241m.\u001B[39mControlStatusCtx(status\u001B[38;5;241m=\u001B[39mag_ctx\u001B[38;5;241m.\u001B[39mStatus\u001B[38;5;241m.\u001B[39mUNSPECIFIED):\n\u001B[0;32m--> 595\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/engine/training.py:1000\u001B[0m, in \u001B[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m    999\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_step\u001B[39m(data):\n\u001B[0;32m-> 1000\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1001\u001B[0m   \u001B[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001B[39;00m\n\u001B[1;32m   1002\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/engine/training.py:863\u001B[0m, in \u001B[0;36mModel.train_step\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m    861\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_target_and_loss(y, loss)\n\u001B[1;32m    862\u001B[0m \u001B[38;5;66;03m# Run backwards pass.\u001B[39;00m\n\u001B[0;32m--> 863\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mminimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainable_variables\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtape\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    864\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:530\u001B[0m, in \u001B[0;36mOptimizerV2.minimize\u001B[0;34m(self, loss, var_list, grad_loss, name, tape)\u001B[0m\n\u001B[1;32m    499\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mminimize\u001B[39m(\u001B[38;5;28mself\u001B[39m, loss, var_list, grad_loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, tape\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    500\u001B[0m   \u001B[38;5;124;03m\"\"\"Minimize `loss` by updating `var_list`.\u001B[39;00m\n\u001B[1;32m    501\u001B[0m \n\u001B[1;32m    502\u001B[0m \u001B[38;5;124;03m  This method simply computes gradient using `tf.GradientTape` and calls\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    528\u001B[0m \n\u001B[1;32m    529\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m--> 530\u001B[0m   grads_and_vars \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute_gradients\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    531\u001B[0m \u001B[43m      \u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvar_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvar_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_loss\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtape\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    532\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_gradients(grads_and_vars, name\u001B[38;5;241m=\u001B[39mname)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:583\u001B[0m, in \u001B[0;36mOptimizerV2._compute_gradients\u001B[0;34m(self, loss, var_list, grad_loss, tape)\u001B[0m\n\u001B[1;32m    581\u001B[0m var_list \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mnest\u001B[38;5;241m.\u001B[39mflatten(var_list)\n\u001B[1;32m    582\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mname_scope(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_name \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/gradients\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 583\u001B[0m   grads_and_vars \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_gradients\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvar_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_loss\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    585\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assert_valid_dtypes([\n\u001B[1;32m    586\u001B[0m     v \u001B[38;5;28;01mfor\u001B[39;00m g, v \u001B[38;5;129;01min\u001B[39;00m grads_and_vars\n\u001B[1;32m    587\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m g \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m v\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m tf\u001B[38;5;241m.\u001B[39mresource\n\u001B[1;32m    588\u001B[0m ])\n\u001B[1;32m    590\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m grads_and_vars\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:464\u001B[0m, in \u001B[0;36mOptimizerV2._get_gradients\u001B[0;34m(self, tape, loss, var_list, grad_loss)\u001B[0m\n\u001B[1;32m    462\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_gradients\u001B[39m(\u001B[38;5;28mself\u001B[39m, tape, loss, var_list, grad_loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    463\u001B[0m   \u001B[38;5;124;03m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 464\u001B[0m   grads \u001B[38;5;241m=\u001B[39m \u001B[43mtape\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgradient\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvar_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_loss\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    465\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(grads, var_list))\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py:1081\u001B[0m, in \u001B[0;36mGradientTape.gradient\u001B[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001B[0m\n\u001B[1;32m   1077\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m output_gradients \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1078\u001B[0m   output_gradients \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m x \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mconvert_to_tensor(x)\n\u001B[1;32m   1079\u001B[0m                       \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m nest\u001B[38;5;241m.\u001B[39mflatten(output_gradients)]\n\u001B[0;32m-> 1081\u001B[0m flat_grad \u001B[38;5;241m=\u001B[39m \u001B[43mimperative_grad\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimperative_grad\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1082\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tape\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1083\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_targets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1084\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_sources\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1085\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_gradients\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_gradients\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1086\u001B[0m \u001B[43m    \u001B[49m\u001B[43msources_raw\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mflat_sources_raw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1087\u001B[0m \u001B[43m    \u001B[49m\u001B[43munconnected_gradients\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43munconnected_gradients\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1089\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_persistent:\n\u001B[1;32m   1090\u001B[0m   \u001B[38;5;66;03m# Keep track of watched variables before setting tape to None\u001B[39;00m\n\u001B[1;32m   1091\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_watched_variables \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tape\u001B[38;5;241m.\u001B[39mwatched_variables()\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/eager/imperative_grad.py:67\u001B[0m, in \u001B[0;36mimperative_grad\u001B[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n\u001B[1;32m     64\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m     65\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnknown value for unconnected_gradients: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m unconnected_gradients)\n\u001B[0;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_TapeGradient\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtape\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m     69\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     70\u001B[0m \u001B[43m    \u001B[49m\u001B[43msources\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     71\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_gradients\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[43m    \u001B[49m\u001B[43msources_raw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_str\u001B[49m\u001B[43m(\u001B[49m\u001B[43munconnected_gradients\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py:156\u001B[0m, in \u001B[0;36m_gradient_function\u001B[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001B[0m\n\u001B[1;32m    154\u001B[0m     gradient_name_scope \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m forward_pass_name_scope \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    155\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mname_scope(gradient_name_scope):\n\u001B[0;32m--> 156\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgrad_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmock_op\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mout_grads\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    158\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m grad_fn(mock_op, \u001B[38;5;241m*\u001B[39mout_grads)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/ops/math_grad.py:211\u001B[0m, in \u001B[0;36m_SumGrad\u001B[0;34m(op, grad)\u001B[0m\n\u001B[1;32m    207\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m op\u001B[38;5;241m.\u001B[39mget_attr(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeep_dims\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    208\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mcolocate_with(input_shape):\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;66;03m# TODO(apassos) remove this once device placement for eager ops makes\u001B[39;00m\n\u001B[1;32m    210\u001B[0m     \u001B[38;5;66;03m# more sense.\u001B[39;00m\n\u001B[0;32m--> 211\u001B[0m     output_shape_kept_dims \u001B[38;5;241m=\u001B[39m \u001B[43mmath_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduced_shape\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_shape\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    212\u001B[0m \u001B[43m                                                    \u001B[49m\u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    213\u001B[0m   grad \u001B[38;5;241m=\u001B[39m array_ops\u001B[38;5;241m.\u001B[39mreshape(grad, output_shape_kept_dims)\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [array_ops\u001B[38;5;241m.\u001B[39mbroadcast_to(grad, input_shape), \u001B[38;5;28;01mNone\u001B[39;00m]\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:4495\u001B[0m, in \u001B[0;36mreduced_shape\u001B[0;34m(input_shape, axes)\u001B[0m\n\u001B[1;32m   4482\u001B[0m \u001B[38;5;124;03m\"\"\"Helper function for reduction ops.\u001B[39;00m\n\u001B[1;32m   4483\u001B[0m \n\u001B[1;32m   4484\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4489\u001B[0m \u001B[38;5;124;03m  A 1-D Tensor, the output shape as if keepdims were set to True.\u001B[39;00m\n\u001B[1;32m   4490\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   4491\u001B[0m \u001B[38;5;66;03m# TODO(allenl): Refactor `reduced_shape` to take the tensor corresponding to\u001B[39;00m\n\u001B[1;32m   4492\u001B[0m \u001B[38;5;66;03m# `input_shape` rather than `tf.shape` of it. Then we can check if the shape\u001B[39;00m\n\u001B[1;32m   4493\u001B[0m \u001B[38;5;66;03m# is fully defined here, which may be faster executing eagerly than running\u001B[39;00m\n\u001B[1;32m   4494\u001B[0m \u001B[38;5;66;03m# `tf.shape` and then fetching its constant value.\u001B[39;00m\n\u001B[0;32m-> 4495\u001B[0m constant_input_shape \u001B[38;5;241m=\u001B[39m \u001B[43mtensor_util\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconstant_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_shape\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4496\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m constant_input_shape \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   4497\u001B[0m   constant_axes \u001B[38;5;241m=\u001B[39m tensor_util\u001B[38;5;241m.\u001B[39mconstant_value(axes)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py:869\u001B[0m, in \u001B[0;36mconstant_value\u001B[0;34m(tensor, partial)\u001B[0m\n\u001B[1;32m    867\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(tensor, ops\u001B[38;5;241m.\u001B[39mEagerTensor):\n\u001B[1;32m    868\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 869\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtensor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    870\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m errors_impl\u001B[38;5;241m.\u001B[39mUnimplementedError:\n\u001B[1;32m    871\u001B[0m     \u001B[38;5;66;03m# Some EagerTensors may not implement .numpy/resolve, e.g. parallel\u001B[39;00m\n\u001B[1;32m    872\u001B[0m     \u001B[38;5;66;03m# tensors with multiple components on different devices.\u001B[39;00m\n\u001B[1;32m    873\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1223\u001B[0m, in \u001B[0;36m_EagerTensorBase.numpy\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1200\u001B[0m \u001B[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001B[39;00m\n\u001B[1;32m   1201\u001B[0m \n\u001B[1;32m   1202\u001B[0m \u001B[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1220\u001B[0m \u001B[38;5;124;03m    NumPy dtype.\u001B[39;00m\n\u001B[1;32m   1221\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1222\u001B[0m \u001B[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001B[39;00m\n\u001B[0;32m-> 1223\u001B[0m maybe_arr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_numpy\u001B[49m()  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m   1224\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m maybe_arr\u001B[38;5;241m.\u001B[39mcopy() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(maybe_arr, np\u001B[38;5;241m.\u001B[39mndarray) \u001B[38;5;28;01melse\u001B[39;00m maybe_arr\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = build_hmm_to_fit( states_observable=STATES_ARE_OBSERVABLE )\n",
    "\n",
    "compiler = CompilerInfo(LR_EXPONENTIAL_DECAY)\n",
    "model.compile(\n",
    "    loss = compiler.loss,\n",
    "    optimizer = compiler.optimizer,\n",
    "    run_eagerly = True\n",
    ")\n",
    "\n",
    "fit_model(model, adstock_with_empty, output_with_empty)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 23s 3s/step - loss: 2784.8716\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 21s 3s/step - loss: 2763.0315\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 21s 3s/step - loss: 2741.4041\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 20s 3s/step - loss: 2719.9846\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 20s 3s/step - loss: 2698.7717\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 21s 3s/step - loss: 2677.7610\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 20s 3s/step - loss: 2656.9536\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 20s 2s/step - loss: 2636.3462\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 20s 3s/step - loss: 2615.9375\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 20s 2s/step - loss: 2595.7258\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 21s 3s/step - loss: 2575.7090\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 20s 3s/step - loss: 2555.8848\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 20s 3s/step - loss: 2536.2529\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 20s 3s/step - loss: 2516.8101\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 20s 3s/step - loss: 2497.5549\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 24s 3s/step - loss: 2478.4854\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2459.5996\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2440.8960\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2422.3728\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 18s 2s/step - loss: 2404.0276\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2385.8584\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2367.8640\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2350.0422\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2332.3916\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2314.9094\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2297.5955\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2280.4460\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2263.4614\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2246.6384\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2229.9753\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2213.4709\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2197.1230\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2180.9309\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2164.8911\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2149.0039\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2133.2664\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2118.4656\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2105.5864\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2092.8599\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2080.2278\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2067.6899\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2055.2444\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2042.8907\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2030.6272\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2018.4546\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2006.3710\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1994.3770\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1982.4703\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1970.6523\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1958.9205\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1947.2759\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1935.7164\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1924.2421\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 1228s 175s/step - loss: 1912.8523\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 18s 2s/step - loss: 1901.5459\n",
      "Epoch 56/100\n",
      "1/8 [==>...........................] - ETA: 15s - loss: 1932.6820"
     ]
    }
   ],
   "source": [
    "fit_model(model, adstock_with_empty, output_with_empty)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "[<tf.Variable 'transition_prob_layer_2/mu:0' shape=(4,) dtype=float32, numpy=array([-0.        ,  0.06619387,  0.26603213,  0.27003407], dtype=float32)>,\n <tf.Variable 'transition_prob_layer_2/beta:0' shape=(12,) dtype=float32, numpy=\n array([-0.1619116 , -0.2684288 , -0.2631067 ,  0.04105067,  0.14844477,\n        -0.37556982,  0.17426813, -0.20132601, -0.03317034, -0.29804862,\n        -0.28567052,  0.00739706], dtype=float32)>]"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 30, 3, 3), dtype=float32, numpy=\narray([[[[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]],\n\n        [[3.4060526e-01, 3.4060535e-01, 3.1878936e-01],\n         [3.0295843e-01, 3.9529318e-01, 3.0174839e-01],\n         [1.0000000e-10, 1.0000000e-10, 1.0000000e+00]]]], dtype=float32)>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_transition_matrix(-model.weights[0], model.weights[1], adstock_with_empty[0:1,:,:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[3.2995809e-02, 3.2995809e-02, 9.3400830e-01],\n       [3.1312186e-02, 3.1312186e-02, 9.3737555e-01],\n       [1.0704581e-09, 1.0704581e-09, 1.0000000e+00]], dtype=float32)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = make_transition_matrix(-model.weights[0], model.weights[1], tf.zeros([1, adstock.shape[1], adstock.shape[2]]))\n",
    "np.linalg.matrix_power( a[0,0,:].numpy(), 30 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_with_empty"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}