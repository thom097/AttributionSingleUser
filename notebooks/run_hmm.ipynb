{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# HMM to estimate Funnel position"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import libraries and constants"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import config.CONSTANTS_HMM\n",
    "from config.CONSTANTS_HMM import *\n",
    "from config.execution_parameters import *\n",
    "\n",
    "# Project libraries\n",
    "import src.hmm_package.generate_hmm\n",
    "from src.hmm_package.generate_hmm import *\n",
    "from src.plot_and_print_info.plots_and_print_info import *\n",
    "\n",
    "# Built in libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import distributions as tfd\n",
    "import importlib"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "importlib.reload(src.hmm_package.generate_hmm)\n",
    "from src.hmm_package.generate_hmm import *\n",
    "importlib.reload(config.CONSTANTS_HMM)\n",
    "from config.CONSTANTS_HMM import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compute Observation and Adstock"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To study the behaviour of the Hidden Markov Model, we generate a random exposition of the users to some campaigns. The parameters for the simulation are in config/CONSTANTS_HMM.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# Generate Test observation\n",
    "observation = simulate_observations()\n",
    "\n",
    "# Compute Adstock\n",
    "adstock = compute_adstock(observation=observation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Real HMM to Estimate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# Generate the distributions to build the Real HMM.\n",
    "# The parameter MU, describing the behaviour of a user unexposed, has been fitted in a separate notebook and is considered known.\n",
    "#NB The variable STATES_ARE_OBSERVABLE is set in config/execution_parameters.\n",
    "hmm_distributions = generate_hmm_distributions(states_observable=False, adstock=adstock)\n",
    "\n",
    "# Create Real HMM to fit\n",
    "real_hmm = tfd.HiddenMarkovModel(\n",
    "    initial_distribution=hmm_distributions['initial_distribution'],\n",
    "    transition_distribution=hmm_distributions['transition_distribution'],\n",
    "    observation_distribution=hmm_distributions['observation_distribution'],\n",
    "    time_varying_transition_distribution=True,\n",
    "    num_steps=time+1\n",
    ")\n",
    "\n",
    "# Sample emissions\n",
    "emission_real = real_hmm.sample().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize the Real HMM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of conversion is: 0.2385%.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 2160x72 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count conversions from sampled data\n",
    "# We aim to see a conversion rate around 20/25%.\n",
    "\n",
    "tot_conversions = count_conversions(emission_real, STATES_ARE_OBSERVABLE)\n",
    "plot_sample_emissions(real_hmm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fit model with real parameter for Sanity Check"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta: [array([ 0.7 ,  0.25, -0.3 ,  0.15,  0.4 ,  0.1 , -0.4 ,  0.8 ],\n",
      "      dtype=float32)]\n",
      "Epoch 1/1000\n",
      "40/40 [==============================] - 125s 3s/step - loss: 629.6302\n",
      "Beta: [array([ 0.70874643,  0.2599502 , -0.3084603 ,  0.15474539,  0.39710984,\n",
      "        0.108769  , -0.40210754,  0.80134684], dtype=float32)]\n",
      "Epoch 2/1000\n",
      "40/40 [==============================] - 122s 3s/step - loss: 629.6091\n",
      "Beta: [array([ 0.7091461 ,  0.2652235 , -0.3065142 ,  0.1511763 ,  0.39038163,\n",
      "        0.10672969, -0.39551795,  0.7944408 ], dtype=float32)]\n",
      "Epoch 3/1000\n",
      "40/40 [==============================] - 122s 3s/step - loss: 629.5987\n",
      "Beta: [array([ 0.71796405,  0.26843968, -0.31362367,  0.15692687,  0.38871232,\n",
      "        0.10810819, -0.39689812,  0.79728144], dtype=float32)]\n",
      "Epoch 4/1000\n",
      "40/40 [==============================] - 122s 3s/step - loss: 629.5858\n",
      "Beta: [array([ 0.72198534,  0.27436435, -0.31583813,  0.15610942,  0.38388413,\n",
      "        0.10452782, -0.3928106 ,  0.79484594], dtype=float32)]\n",
      "Epoch 5/1000\n",
      "40/40 [==============================] - 123s 3s/step - loss: 629.5860\n",
      "Beta: [array([ 0.73012304,  0.2794172 , -0.32103416,  0.15686156,  0.38487968,\n",
      "        0.10814724, -0.39476457,  0.7965375 ], dtype=float32)]\n",
      "Epoch 6/1000\n",
      "40/40 [==============================] - 122s 3s/step - loss: 629.5773\n",
      "Beta: [array([ 0.72994417,  0.27824596, -0.31917855,  0.15623261,  0.3787707 ,\n",
      "        0.10539678, -0.38967645,  0.7949402 ], dtype=float32)]\n",
      "Epoch 7/1000\n",
      "40/40 [==============================] - 122s 3s/step - loss: 629.5928\n",
      "Beta: [array([ 0.7357677 ,  0.28635326, -0.32050973,  0.15421951,  0.37756532,\n",
      "        0.10465249, -0.38754064,  0.79254544], dtype=float32)]\n",
      "Epoch 8/1000\n",
      "40/40 [==============================] - 122s 3s/step - loss: 629.5731\n",
      "Beta: [array([ 0.74118054,  0.28742728, -0.32468206,  0.15591764,  0.37509447,\n",
      "        0.1052748 , -0.38780075,  0.7936744 ], dtype=float32)]\n",
      "Epoch 9/1000\n",
      "40/40 [==============================] - 122s 3s/step - loss: 629.5948\n",
      "Beta: [array([ 0.74709386,  0.2951562 , -0.32793167,  0.15516488,  0.37694386,\n",
      "        0.10940057, -0.38987052,  0.7947191 ], dtype=float32)]\n",
      "Epoch 10/1000\n",
      "40/40 [==============================] - 122s 3s/step - loss: 629.5706\n",
      "Beta: [array([ 0.74882734,  0.2963228 , -0.3287638 ,  0.15492879,  0.37193942,\n",
      "        0.10496114, -0.3859877 ,  0.79289293], dtype=float32)]\n",
      "Epoch 11/1000\n",
      "40/40 [==============================] - 121s 3s/step - loss: 629.5590\n",
      "Beta: [array([ 0.75404704,  0.29901937, -0.33155358,  0.15619376,  0.3708917 ,\n",
      "        0.10386697, -0.3857998 ,  0.7935019 ], dtype=float32)]\n",
      "Epoch 12/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5759\n",
      "Beta: [array([ 0.7575768 ,  0.29739127, -0.33229786,  0.15617616,  0.3702034 ,\n",
      "        0.10347118, -0.38708174,  0.7964273 ], dtype=float32)]\n",
      "Epoch 13/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5652\n",
      "Beta: [array([ 0.75929487,  0.30243054, -0.33283967,  0.15498611,  0.36771765,\n",
      "        0.10236987, -0.38387218,  0.79425955], dtype=float32)]\n",
      "Epoch 14/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5566\n",
      "Beta: [array([ 0.7628004 ,  0.30404726, -0.33409816,  0.1543982 ,  0.36668235,\n",
      "        0.10134818, -0.38336304,  0.793437  ], dtype=float32)]\n",
      "Epoch 15/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5499\n",
      "Beta: [array([ 0.7665406 ,  0.30551696, -0.33501723,  0.15371737,  0.36615926,\n",
      "        0.10210177, -0.382417  ,  0.79442394], dtype=float32)]\n",
      "Epoch 16/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5552\n",
      "Beta: [array([ 0.7696337 ,  0.30838257, -0.33584264,  0.15297133,  0.36538348,\n",
      "        0.10282634, -0.38148057,  0.7941475 ], dtype=float32)]\n",
      "Epoch 17/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5502\n",
      "Beta: [array([ 0.77104145,  0.3056667 , -0.33480158,  0.15238008,  0.3607506 ,\n",
      "        0.09947273, -0.37833422,  0.7945095 ], dtype=float32)]\n",
      "Epoch 18/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5496\n",
      "Beta: [array([ 0.77597696,  0.30538815, -0.33872443,  0.15322402,  0.36111987,\n",
      "        0.09727056, -0.37971467,  0.7956304 ], dtype=float32)]\n",
      "Epoch 19/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5410\n",
      "Beta: [array([ 0.7774814 ,  0.3099523 , -0.33823404,  0.15212724,  0.35979295,\n",
      "        0.09881293, -0.3777754 ,  0.7941178 ], dtype=float32)]\n",
      "Epoch 20/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5507\n",
      "Beta: [array([ 0.7794593 ,  0.3098857 , -0.33915767,  0.15331256,  0.35734442,\n",
      "        0.09486435, -0.37699682,  0.7953684 ], dtype=float32)]\n",
      "Epoch 21/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5536\n",
      "Beta: [array([ 0.7828228 ,  0.31284258, -0.3397245 ,  0.15244983,  0.35670266,\n",
      "        0.09459293, -0.37600374,  0.79577005], dtype=float32)]\n",
      "Epoch 22/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5517\n",
      "Beta: [array([ 0.7868845 ,  0.31378877, -0.3415917 ,  0.15187876,  0.35623112,\n",
      "        0.09561028, -0.3761654 ,  0.7953748 ], dtype=float32)]\n",
      "Epoch 23/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5705\n",
      "Beta: [array([ 0.78781843,  0.31376404, -0.34016111,  0.15023695,  0.35472184,\n",
      "        0.0950208 , -0.37428376,  0.79513067], dtype=float32)]\n",
      "Epoch 24/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5469\n",
      "Beta: [array([ 0.7897811 ,  0.3119409 , -0.3422454 ,  0.15095352,  0.35306814,\n",
      "        0.0926079 , -0.37476182,  0.7957273 ], dtype=float32)]\n",
      "Epoch 25/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5712\n",
      "Beta: [array([ 0.7947948 ,  0.31741953, -0.34467548,  0.15267465,  0.3534494 ,\n",
      "        0.09282436, -0.375509  ,  0.7979688 ], dtype=float32)]\n",
      "Epoch 26/1000\n",
      "40/40 [==============================] - 119s 3s/step - loss: 629.5344\n",
      "Beta: [array([ 0.79417944,  0.31288618, -0.34255058,  0.15061069,  0.3502143 ,\n",
      "        0.09207705, -0.370895  ,  0.79476845], dtype=float32)]\n",
      "Epoch 27/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5443\n",
      "Beta: [array([ 0.7967033 ,  0.314177  , -0.34328723,  0.14989774,  0.3501681 ,\n",
      "        0.08873586, -0.37188464,  0.79555744], dtype=float32)]\n",
      "Epoch 28/1000\n",
      "39/40 [============================>.] - ETA: 4s - loss: 628.0529"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [35]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m model_test\u001B[38;5;241m.\u001B[39mcompile(\n\u001B[1;32m      8\u001B[0m     loss \u001B[38;5;241m=\u001B[39m compiler\u001B[38;5;241m.\u001B[39mloss,\n\u001B[1;32m      9\u001B[0m     optimizer \u001B[38;5;241m=\u001B[39m compiler\u001B[38;5;241m.\u001B[39moptimizer,\n\u001B[1;32m     10\u001B[0m     run_eagerly \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     11\u001B[0m )\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m#start @714\u001B[39;00m\n\u001B[0;32m---> 13\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mfit_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madstock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43memission_real\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/AttributionSingleUser/src/hmm_package/generate_hmm.py:333\u001B[0m, in \u001B[0;36mfit_model\u001B[0;34m(model, adstock, emission_real)\u001B[0m\n\u001B[1;32m    331\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit_model\u001B[39m(model, adstock, emission_real):\n\u001B[1;32m    332\u001B[0m     print_weights \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mLambdaCallback(on_epoch_begin\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m batch, logs: \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBeta: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(model\u001B[38;5;241m.\u001B[39mget_weights())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m--> 333\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43madstock\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    334\u001B[0m \u001B[43m                     \u001B[49m\u001B[43memission_real\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    335\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mEPOCHS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    336\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    337\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mprint_weights\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    338\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/engine/training.py:1384\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1377\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1378\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   1379\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   1380\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[1;32m   1381\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m   1382\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m   1383\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1384\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1385\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1386\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/engine/training.py:1021\u001B[0m, in \u001B[0;36mModel.make_train_function.<locals>.train_function\u001B[0;34m(iterator)\u001B[0m\n\u001B[1;32m   1019\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_function\u001B[39m(iterator):\n\u001B[1;32m   1020\u001B[0m   \u001B[38;5;124;03m\"\"\"Runs a training execution with a single step.\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1021\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mstep_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/engine/training.py:1010\u001B[0m, in \u001B[0;36mModel.make_train_function.<locals>.step_function\u001B[0;34m(model, iterator)\u001B[0m\n\u001B[1;32m   1007\u001B[0m   run_step \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mfunction(\n\u001B[1;32m   1008\u001B[0m       run_step, jit_compile\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, experimental_relax_shapes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   1009\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(iterator)\n\u001B[0;32m-> 1010\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistribute_strategy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_step\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1011\u001B[0m outputs \u001B[38;5;241m=\u001B[39m reduce_per_replica(\n\u001B[1;32m   1012\u001B[0m     outputs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistribute_strategy, reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfirst\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m   1013\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1312\u001B[0m, in \u001B[0;36mStrategyBase.run\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m   1307\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscope():\n\u001B[1;32m   1308\u001B[0m   \u001B[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001B[39;00m\n\u001B[1;32m   1309\u001B[0m   \u001B[38;5;66;03m# applied when the caller is also in Eager mode.\u001B[39;00m\n\u001B[1;32m   1310\u001B[0m   fn \u001B[38;5;241m=\u001B[39m autograph\u001B[38;5;241m.\u001B[39mtf_convert(\n\u001B[1;32m   1311\u001B[0m       fn, autograph_ctx\u001B[38;5;241m.\u001B[39mcontrol_status_ctx(), convert_by_default\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m-> 1312\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_extended\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_for_each_replica\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2888\u001B[0m, in \u001B[0;36mStrategyExtendedV1.call_for_each_replica\u001B[0;34m(self, fn, args, kwargs)\u001B[0m\n\u001B[1;32m   2886\u001B[0m   kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m   2887\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_container_strategy()\u001B[38;5;241m.\u001B[39mscope():\n\u001B[0;32m-> 2888\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_for_each_replica\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3689\u001B[0m, in \u001B[0;36m_DefaultDistributionExtended._call_for_each_replica\u001B[0;34m(self, fn, args, kwargs)\u001B[0m\n\u001B[1;32m   3687\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_call_for_each_replica\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn, args, kwargs):\n\u001B[1;32m   3688\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ReplicaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_container_strategy(), replica_id_in_sync_group\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m-> 3689\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:595\u001B[0m, in \u001B[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    593\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    594\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ag_ctx\u001B[38;5;241m.\u001B[39mControlStatusCtx(status\u001B[38;5;241m=\u001B[39mag_ctx\u001B[38;5;241m.\u001B[39mStatus\u001B[38;5;241m.\u001B[39mUNSPECIFIED):\n\u001B[0;32m--> 595\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/engine/training.py:1000\u001B[0m, in \u001B[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m    999\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_step\u001B[39m(data):\n\u001B[0;32m-> 1000\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1001\u001B[0m   \u001B[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001B[39;00m\n\u001B[1;32m   1002\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/engine/training.py:859\u001B[0m, in \u001B[0;36mModel.train_step\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m    857\u001B[0m \u001B[38;5;66;03m# Run forward pass.\u001B[39;00m\n\u001B[1;32m    858\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mGradientTape() \u001B[38;5;28;01mas\u001B[39;00m tape:\n\u001B[0;32m--> 859\u001B[0m   y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    860\u001B[0m   loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss(x, y, y_pred, sample_weight)\n\u001B[1;32m    861\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_target_and_loss(y, loss)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/engine/base_layer.py:1096\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1092\u001B[0m   inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_cast_inputs(inputs, input_list)\n\u001B[1;32m   1094\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m autocast_variable\u001B[38;5;241m.\u001B[39menable_auto_cast_variables(\n\u001B[1;32m   1095\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_dtype_object):\n\u001B[0;32m-> 1096\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mcall_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_activity_regularizer:\n\u001B[1;32m   1099\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:92\u001B[0m, in \u001B[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     90\u001B[0m bound_signature \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     91\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 92\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     94\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_keras_call_info_injected\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m     95\u001B[0m     \u001B[38;5;66;03m# Only inject info for the innermost failing call\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/engine/functional.py:451\u001B[0m, in \u001B[0;36mFunctional.call\u001B[0;34m(self, inputs, training, mask)\u001B[0m\n\u001B[1;32m    432\u001B[0m \u001B[38;5;129m@doc_controls\u001B[39m\u001B[38;5;241m.\u001B[39mdo_not_doc_inheritable\n\u001B[1;32m    433\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, mask\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    434\u001B[0m   \u001B[38;5;124;03m\"\"\"Calls the model on new inputs.\u001B[39;00m\n\u001B[1;32m    435\u001B[0m \n\u001B[1;32m    436\u001B[0m \u001B[38;5;124;03m  In this case `call` just reapplies\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    449\u001B[0m \u001B[38;5;124;03m      a list of tensors if there are more than one outputs.\u001B[39;00m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m--> 451\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_internal_graph\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    452\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmask\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/engine/functional.py:589\u001B[0m, in \u001B[0;36mFunctional._run_internal_graph\u001B[0;34m(self, inputs, training, mask)\u001B[0m\n\u001B[1;32m    586\u001B[0m   \u001B[38;5;28;01mcontinue\u001B[39;00m  \u001B[38;5;66;03m# Node is not computable, try skipping.\u001B[39;00m\n\u001B[1;32m    588\u001B[0m args, kwargs \u001B[38;5;241m=\u001B[39m node\u001B[38;5;241m.\u001B[39mmap_arguments(tensor_dict)\n\u001B[0;32m--> 589\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mnode\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    591\u001B[0m \u001B[38;5;66;03m# Update tensor_dict.\u001B[39;00m\n\u001B[1;32m    592\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x_id, y \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(node\u001B[38;5;241m.\u001B[39mflat_output_ids, tf\u001B[38;5;241m.\u001B[39mnest\u001B[38;5;241m.\u001B[39mflatten(outputs)):\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/engine/base_layer.py:1096\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1092\u001B[0m   inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_cast_inputs(inputs, input_list)\n\u001B[1;32m   1094\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m autocast_variable\u001B[38;5;241m.\u001B[39menable_auto_cast_variables(\n\u001B[1;32m   1095\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_dtype_object):\n\u001B[0;32m-> 1096\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mcall_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_activity_regularizer:\n\u001B[1;32m   1099\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:92\u001B[0m, in \u001B[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     90\u001B[0m bound_signature \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     91\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 92\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     94\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_keras_call_info_injected\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m     95\u001B[0m     \u001B[38;5;66;03m# Only inject info for the innermost failing call\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/AttributionSingleUser/src/hmm_package/generate_hmm.py:254\u001B[0m, in \u001B[0;36mTransitionProbLayerBeta.call\u001B[0;34m(self, adstock)\u001B[0m\n\u001B[1;32m    251\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall\u001B[39m(\u001B[38;5;28mself\u001B[39m, adstock):\n\u001B[1;32m    252\u001B[0m     \u001B[38;5;66;03m# We suppose that the weights mu are all non-positive.\u001B[39;00m\n\u001B[1;32m    253\u001B[0m     \u001B[38;5;66;03m# TODO: remove basis from make_transition_matrix\u001B[39;00m\n\u001B[0;32m--> 254\u001B[0m     Q \u001B[38;5;241m=\u001B[39m \u001B[43mmake_transition_matrix\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmu\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbeta\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madstock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbasis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    256\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mmath\u001B[38;5;241m.\u001B[39mmaximum(Q, basis)\n",
      "File \u001B[0;32m~/PycharmProjects/AttributionSingleUser/src/hmm_package/generate_hmm.py:70\u001B[0m, in \u001B[0;36mmake_transition_matrix\u001B[0;34m(mu, beta, adstock, basis)\u001B[0m\n\u001B[1;32m     64\u001B[0m mu_nosame_states \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mrepeat(mu_nosame_states, execution_duration, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m iterator \u001B[38;5;129;01min\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mrange(batch_shape):\n\u001B[1;32m     67\u001B[0m     \u001B[38;5;66;03m# Compute mu+O'*beta\u001B[39;00m\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# Take time elements. First of adstock is zeros.\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# Adstock = [users, campaigns, time]\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     O_beta \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensordot\u001B[49m\u001B[43m(\u001B[49m\u001B[43madstock\u001B[49m\u001B[43m[\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbeta_no_same_states\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;66;03m# Solve Matrix computation\u001B[39;00m\n\u001B[1;32m     73\u001B[0m     num \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mexp(O_beta \u001B[38;5;241m+\u001B[39m mu_nosame_states)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1082\u001B[0m, in \u001B[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1080\u001B[0m \u001B[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001B[39;00m\n\u001B[1;32m   1081\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1082\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdispatch_target\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1083\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[1;32m   1084\u001B[0m   \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[1;32m   1085\u001B[0m   \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[1;32m   1086\u001B[0m   result \u001B[38;5;241m=\u001B[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:5124\u001B[0m, in \u001B[0;36mtensordot\u001B[0;34m(a, b, axes, name)\u001B[0m\n\u001B[1;32m   5121\u001B[0m a_reshape, a_free_dims, a_free_dims_static \u001B[38;5;241m=\u001B[39m _tensordot_reshape(a, a_axes)\n\u001B[1;32m   5122\u001B[0m b_reshape, b_free_dims, b_free_dims_static \u001B[38;5;241m=\u001B[39m _tensordot_reshape(\n\u001B[1;32m   5123\u001B[0m     b, b_axes, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m-> 5124\u001B[0m ab_matmul \u001B[38;5;241m=\u001B[39m \u001B[43mmatmul\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma_reshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb_reshape\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   5125\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(a_free_dims, \u001B[38;5;28mlist\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(b_free_dims, \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m   5126\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m (ab_matmul\u001B[38;5;241m.\u001B[39mget_shape()\u001B[38;5;241m.\u001B[39mis_fully_defined() \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m   5127\u001B[0m       ab_matmul\u001B[38;5;241m.\u001B[39mget_shape()\u001B[38;5;241m.\u001B[39mas_list() \u001B[38;5;241m==\u001B[39m a_free_dims \u001B[38;5;241m+\u001B[39m b_free_dims):\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1082\u001B[0m, in \u001B[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1080\u001B[0m \u001B[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001B[39;00m\n\u001B[1;32m   1081\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1082\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdispatch_target\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1083\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[1;32m   1084\u001B[0m   \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[1;32m   1085\u001B[0m   \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[1;32m   1086\u001B[0m   result \u001B[38;5;241m=\u001B[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:3713\u001B[0m, in \u001B[0;36mmatmul\u001B[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001B[0m\n\u001B[1;32m   3710\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m gen_math_ops\u001B[38;5;241m.\u001B[39mbatch_mat_mul_v3(\n\u001B[1;32m   3711\u001B[0m       a, b, adj_x\u001B[38;5;241m=\u001B[39madjoint_a, adj_y\u001B[38;5;241m=\u001B[39madjoint_b, Tout\u001B[38;5;241m=\u001B[39moutput_type, name\u001B[38;5;241m=\u001B[39mname)\n\u001B[1;32m   3712\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 3713\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgen_math_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmat_mul\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3714\u001B[0m \u001B[43m      \u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtranspose_a\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtranspose_a\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtranspose_b\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtranspose_b\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py:6013\u001B[0m, in \u001B[0;36mmat_mul\u001B[0;34m(a, b, transpose_a, transpose_b, name)\u001B[0m\n\u001B[1;32m   6011\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[1;32m   6012\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 6013\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   6014\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mMatMul\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtranspose_a\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtranspose_a\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtranspose_b\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   6015\u001B[0m \u001B[43m      \u001B[49m\u001B[43mtranspose_b\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   6016\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[1;32m   6017\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# STATES_ARE_OBSERVABLE is defined in CONSTANTS_HMM\n",
    "# The initializer here is the true parameter. The goal is to compute the optimal loss, and see whether the parameters move away from the optimum.\n",
    "initializer=tf.keras.initializers.Constant(BETA),\n",
    "model_test = build_hmm_to_fit_beta( states_observable=STATES_ARE_OBSERVABLE, mu=MU, initializer=initializer )\n",
    "\n",
    "compiler = CompilerInfoBeta(LR_EXPONENTIAL_DECAY)\n",
    "model_test.compile(\n",
    "    loss = compiler.loss,\n",
    "    optimizer = compiler.optimizer,\n",
    "    run_eagerly = True\n",
    ")\n",
    "\n",
    "history = fit_model(model_test, adstock, emission_real)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see above, the parameters slightly change, although the loss remains the same. Below, you can see the average difference for each transition and each user."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "matrix_diff = lambda usr: tf.reduce_sum(make_transition_matrix(MU, model_test.weights[0], adstock[usr:usr+1]) - make_transition_matrix(MU,BETA, adstock[usr:usr+1]), axis=1)/30\n",
    "avg_diff = sum(matrix_diff(usr) for usr in range(N_users))/N_users"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=\narray([[[-2.1503285e-02,  2.1464450e-02,  3.8931419e-05],\n        [-2.7916392e-03,  2.9183212e-03, -1.2667537e-04],\n        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00]]], dtype=float32)>"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_diff"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build and fit the model starting from a random initializer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta: [array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]\n",
      "Epoch 1/1000\n",
      "40/40 [==============================] - 124s 3s/step - loss: 859.4957\n",
      "Beta: [array([ 0.03995506,  0.0385945 , -0.03967253,  0.04002947,  0.04013599,\n",
      "        0.03899525, -0.0399022 ,  0.04036662], dtype=float32)]\n",
      "Epoch 2/1000\n",
      "40/40 [==============================] - 124s 3s/step - loss: 830.0834\n",
      "Beta: [array([ 0.08223794,  0.07399365, -0.08034635,  0.08256695,  0.08235378,\n",
      "        0.07478173, -0.08050092,  0.08313902], dtype=float32)]\n",
      "Epoch 3/1000\n",
      "40/40 [==============================] - 127s 3s/step - loss: 800.2873\n",
      "Beta: [array([ 0.12582977,  0.10444664, -0.12088638,  0.12711415,  0.1261141 ,\n",
      "        0.10561328, -0.12092919,  0.12788995], dtype=float32)]\n",
      "Epoch 4/1000\n",
      "40/40 [==============================] - 122s 3s/step - loss: 770.6592\n",
      "Beta: [array([ 0.16894858,  0.12857544, -0.15953845,  0.17200804,  0.16966963,\n",
      "        0.13059272, -0.15971546,  0.17349526], dtype=float32)]\n",
      "Epoch 5/1000\n",
      "40/40 [==============================] - 122s 3s/step - loss: 742.5656\n",
      "Beta: [array([ 0.21065974,  0.14703536, -0.19578943,  0.21668255,  0.21244752,\n",
      "        0.15006039, -0.19653946,  0.21943505], dtype=float32)]\n",
      "Epoch 6/1000\n",
      "40/40 [==============================] - 124s 3s/step - loss: 717.1196\n",
      "Beta: [array([ 0.24920444,  0.16034962, -0.22839996,  0.25934622,  0.25236246,\n",
      "        0.16463983, -0.23005868,  0.26425636], dtype=float32)]\n",
      "Epoch 7/1000\n",
      "40/40 [==============================] - 125s 3s/step - loss: 695.3508\n",
      "Beta: [array([ 0.28311527,  0.16951111, -0.2564827 ,  0.2985231 ,  0.2882118 ,\n",
      "        0.17520322, -0.2596364 ,  0.306542  ], dtype=float32)]\n",
      "Epoch 8/1000\n",
      "40/40 [==============================] - 123s 3s/step - loss: 677.9140\n",
      "Beta: [array([ 0.31205264,  0.17574346, -0.2800025 ,  0.3333483 ,  0.31995443,\n",
      "        0.1829049 , -0.28552943,  0.3461555 ], dtype=float32)]\n",
      "Epoch 9/1000\n",
      "40/40 [==============================] - 124s 3s/step - loss: 664.7280\n",
      "Beta: [array([ 0.3358378 ,  0.17976992, -0.29896066,  0.36280927,  0.34702432,\n",
      "        0.18832827, -0.30743542,  0.38208678], dtype=float32)]\n",
      "Epoch 10/1000\n",
      "40/40 [==============================] - 122s 3s/step - loss: 655.4302\n",
      "Beta: [array([ 0.35453853,  0.18245271, -0.3133435 ,  0.38529962,  0.37020805,\n",
      "        0.19260271, -0.3260689 ,  0.41421965], dtype=float32)]\n",
      "Epoch 11/1000\n",
      "40/40 [==============================] - 122s 3s/step - loss: 649.2264\n",
      "Beta: [array([ 0.36847103,  0.18402281, -0.32381666,  0.40168527,  0.38874912,\n",
      "        0.19557872, -0.3411383 ,  0.44218707], dtype=float32)]\n",
      "Epoch 12/1000\n",
      "40/40 [==============================] - 123s 3s/step - loss: 645.2667\n",
      "Beta: [array([ 0.37857723,  0.18490466, -0.33063227,  0.41123813,  0.40454435,\n",
      "        0.19800666, -0.35357085,  0.46638948], dtype=float32)]\n",
      "Epoch 13/1000\n",
      "40/40 [==============================] - 122s 3s/step - loss: 642.7811\n",
      "Beta: [array([ 0.3856552 ,  0.18539044, -0.3349548 ,  0.4156659 ,  0.41762394,\n",
      "        0.19991621, -0.36406305,  0.48777094], dtype=float32)]\n",
      "Epoch 14/1000\n",
      "40/40 [==============================] - 122s 3s/step - loss: 641.0979\n",
      "Beta: [array([ 0.38980576,  0.1854274 , -0.33668113,  0.41454414,  0.4282773 ,\n",
      "        0.20152412, -0.372479  ,  0.50577766], dtype=float32)]\n",
      "Epoch 15/1000\n",
      "40/40 [==============================] - 121s 3s/step - loss: 639.8672\n",
      "Beta: [array([ 0.39267057,  0.18534184, -0.33714   ,  0.41030836,  0.43753722,\n",
      "        0.20281537, -0.37974396,  0.5222732 ], dtype=float32)]\n",
      "Epoch 16/1000\n",
      "40/40 [==============================] - 129s 3s/step - loss: 633.9395\n",
      "Beta: [array([ 0.40001968,  0.18254867, -0.32455632,  0.3396002 ,  0.48967826,\n",
      "        0.20985161, -0.41881728,  0.62010056], dtype=float32)]\n",
      "Epoch 24/1000\n",
      "40/40 [==============================] - 124s 3s/step - loss: 633.4734\n",
      "Beta: [array([ 0.40126285,  0.1822933 , -0.32292065,  0.3310609 ,  0.4949996 ,\n",
      "        0.21055217, -0.42256176,  0.6305815 ], dtype=float32)]\n",
      "Epoch 25/1000\n",
      "40/40 [==============================] - 121s 3s/step - loss: 633.0247\n",
      "Beta: [array([ 0.40251338,  0.18202555, -0.3218502 ,  0.32248747,  0.49902004,\n",
      "        0.211043  , -0.42590973,  0.6396604 ], dtype=float32)]\n",
      "Epoch 26/1000\n",
      "40/40 [==============================] - 119s 3s/step - loss: 632.6452\n",
      "Beta: [array([ 0.4032895 ,  0.18174714, -0.31974846,  0.31306943,  0.5036389 ,\n",
      "        0.21164641, -0.42898163,  0.648516  ], dtype=float32)]\n",
      "Epoch 27/1000\n",
      "40/40 [==============================] - 130s 3s/step - loss: 632.2919\n",
      "Beta: [array([ 0.40494484,  0.18153624, -0.3185774 ,  0.3053123 ,  0.5081186 ,\n",
      "        0.21217142, -0.43219924,  0.6580132 ], dtype=float32)]\n",
      "Epoch 28/1000\n",
      "40/40 [==============================] - 122s 3s/step - loss: 631.9814\n",
      "Beta: [array([ 0.40660414,  0.18132332, -0.3171642 ,  0.29732066,  0.51218194,\n",
      "        0.21266598, -0.43504193,  0.6662548 ], dtype=float32)]\n",
      "Epoch 29/1000\n",
      "40/40 [==============================] - 131s 3s/step - loss: 631.7072\n",
      "Beta: [array([ 0.40787125,  0.18103333, -0.31596404,  0.28964463,  0.5155294 ,\n",
      "        0.21296856, -0.43757263,  0.6740933 ], dtype=float32)]\n",
      "Epoch 30/1000\n",
      "40/40 [==============================] - 127s 3s/step - loss: 631.4645\n",
      "Beta: [array([ 0.41001585,  0.18111612, -0.31485093,  0.28242666,  0.51918006,\n",
      "        0.21345326, -0.4398306 ,  0.68161726], dtype=float32)]\n",
      "Epoch 31/1000\n",
      "40/40 [==============================] - 125s 3s/step - loss: 631.2545\n",
      "Beta: [array([ 0.41213933,  0.1809963 , -0.31424618,  0.27531594,  0.5222556 ,\n",
      "        0.21386321, -0.4421594 ,  0.6882046 ], dtype=float32)]\n",
      "Epoch 32/1000\n",
      "40/40 [==============================] - 127s 3s/step - loss: 631.0694\n",
      "Beta: [array([ 0.41408026,  0.18098234, -0.31297007,  0.26808548,  0.5251417 ,\n",
      "        0.21419853, -0.44403175,  0.69520336], dtype=float32)]\n",
      "Epoch 33/1000\n",
      "40/40 [==============================] - 124s 3s/step - loss: 630.9089\n",
      "Beta: [array([ 0.41618782,  0.18103415, -0.31249583,  0.2620095 ,  0.52756655,\n",
      "        0.2144958 , -0.4458677 ,  0.70107603], dtype=float32)]\n",
      "Epoch 34/1000\n",
      "40/40 [==============================] - 128s 3s/step - loss: 630.7593\n",
      "Beta: [array([ 0.4190153 ,  0.18121026, -0.31224027,  0.25670764,  0.53026336,\n",
      "        0.21483862, -0.44756737,  0.7070817 ], dtype=float32)]\n",
      "Epoch 35/1000\n",
      "40/40 [==============================] - 124s 3s/step - loss: 630.6388\n",
      "Beta: [array([ 0.42167452,  0.18141042, -0.3116915 ,  0.25096068,  0.5325201 ,\n",
      "        0.21516943, -0.44909588,  0.7130372 ], dtype=float32)]\n",
      "Epoch 36/1000\n",
      "40/40 [==============================] - 135s 3s/step - loss: 630.5277\n",
      "Beta: [array([ 0.42355347,  0.18138695, -0.3114041 ,  0.24512257,  0.5339173 ,\n",
      "        0.21537961, -0.45038188,  0.7175457 ], dtype=float32)]\n",
      "Epoch 37/1000\n",
      "40/40 [==============================] - 133s 3s/step - loss: 630.4382\n",
      "Beta: [array([ 0.4263064 ,  0.18184684, -0.31143013,  0.23965195,  0.5355428 ,\n",
      "        0.21564218, -0.45153034,  0.7220334 ], dtype=float32)]\n",
      "Epoch 38/1000\n",
      "40/40 [==============================] - 124s 3s/step - loss: 630.3582\n",
      "Beta: [array([ 0.42958292,  0.18211652, -0.31145546,  0.2350021 ,  0.53760797,\n",
      "        0.21594875, -0.4526621 ,  0.7264643 ], dtype=float32)]\n",
      "Epoch 39/1000\n",
      "40/40 [==============================] - 124s 3s/step - loss: 630.2924\n",
      "Beta: [array([ 0.4324295 ,  0.18242842, -0.3113225 ,  0.23017052,  0.5389351 ,\n",
      "        0.21626808, -0.45355585,  0.73082167], dtype=float32)]\n",
      "Epoch 40/1000\n",
      "40/40 [==============================] - 124s 3s/step - loss: 630.2347\n",
      "Beta: [array([ 0.43520507,  0.18272871, -0.31133008,  0.22548065,  0.5398208 ,\n",
      "        0.2164117 , -0.45428395,  0.73459274], dtype=float32)]\n",
      "Epoch 41/1000\n",
      "40/40 [==============================] - 122s 3s/step - loss: 630.1806\n",
      "Beta: [array([ 0.43818277,  0.1831    , -0.31213075,  0.22181118,  0.54042125,\n",
      "        0.21661656, -0.4548973 ,  0.7380454 ], dtype=float32)]\n",
      "Epoch 42/1000\n",
      "40/40 [==============================] - 123s 3s/step - loss: 630.1443\n",
      "Beta: [array([ 0.4414182 ,  0.18369336, -0.31224772,  0.21752475,  0.5414074 ,\n",
      "        0.21678318, -0.45534626,  0.74107   ], dtype=float32)]\n",
      "Epoch 43/1000\n",
      "40/40 [==============================] - 122s 3s/step - loss: 630.0987\n",
      "Beta: [array([ 0.44477278,  0.18432313, -0.3130617 ,  0.21499649,  0.5420158 ,\n",
      "        0.21705785, -0.45594224,  0.7443465 ], dtype=float32)]\n",
      "Epoch 44/1000\n",
      "40/40 [==============================] - 128s 3s/step - loss: 630.0680\n",
      "Beta: [array([ 0.4484632 ,  0.18481097, -0.3138832 ,  0.21221943,  0.54210275,\n",
      "        0.21724206, -0.45619655,  0.7476105 ], dtype=float32)]\n",
      "Epoch 45/1000\n",
      "40/40 [==============================] - 136s 3s/step - loss: 630.0449\n",
      "Beta: [array([ 0.45085964,  0.185305  , -0.31397727,  0.2073997 ,  0.5419942 ,\n",
      "        0.21725953, -0.4561182 ,  0.7489069 ], dtype=float32)]\n",
      "Epoch 46/1000\n",
      "40/40 [==============================] - 129s 3s/step - loss: 630.0173\n",
      "Beta: [array([ 0.45499045,  0.1860322 , -0.3156794 ,  0.2065702 ,  0.5426716 ,\n",
      "        0.2175044 , -0.45671314,  0.75189483], dtype=float32)]\n",
      "Epoch 47/1000\n",
      "40/40 [==============================] - 126s 3s/step - loss: 629.9952\n",
      "Beta: [array([ 0.45909664,  0.18662903, -0.31622836,  0.20361188,  0.54306287,\n",
      "        0.21764237, -0.4566345 ,  0.7544248 ], dtype=float32)]\n",
      "Epoch 48/1000\n",
      "40/40 [==============================] - 126s 3s/step - loss: 629.9799\n",
      "Beta: [array([ 0.462352  ,  0.18734485, -0.31690884,  0.19972266,  0.541689  ,\n",
      "        0.2176307 , -0.45578355,  0.75442684], dtype=float32)]\n",
      "Epoch 49/1000\n",
      "40/40 [==============================] - 123s 3s/step - loss: 629.9553\n",
      "Beta: [array([ 0.46534625,  0.18790846, -0.31756333,  0.19871143,  0.5419317 ,\n",
      "        0.21778432, -0.45593333,  0.75803155], dtype=float32)]\n",
      "Epoch 50/1000\n",
      "40/40 [==============================] - 122s 3s/step - loss: 629.9418\n",
      "Beta: [array([ 0.46922776,  0.1886287 , -0.31898636,  0.19663747,  0.5409324 ,\n",
      "        0.21778955, -0.45552418,  0.75893545], dtype=float32)]\n",
      "Epoch 51/1000\n",
      "40/40 [==============================] - 122s 3s/step - loss: 629.9299\n",
      "Beta: [array([ 0.47288355,  0.18925162, -0.31948987,  0.19389427,  0.5407383 ,\n",
      "        0.21797131, -0.4551863 ,  0.76083225], dtype=float32)]\n",
      "Epoch 52/1000\n",
      "40/40 [==============================] - 122s 3s/step - loss: 629.9133\n",
      "Beta: [array([ 0.47653544,  0.19028662, -0.32118794,  0.19204609,  0.5396291 ,\n",
      "        0.21810143, -0.454833  ,  0.76173156], dtype=float32)]\n",
      "Epoch 53/1000\n",
      "40/40 [==============================] - 122s 3s/step - loss: 629.9030\n",
      "Beta: [array([ 0.47986054,  0.1908937 , -0.32194328,  0.18937914,  0.5391888 ,\n",
      "        0.2182353 , -0.45439357,  0.7628952 ], dtype=float32)]\n",
      "Epoch 54/1000\n",
      "40/40 [==============================] - 130s 3s/step - loss: 629.8945\n",
      "Beta: [array([ 0.48410556,  0.1919081 , -0.3235166 ,  0.18927236,  0.53751624,\n",
      "        0.21822652, -0.45312104,  0.7630198 ], dtype=float32)]\n",
      "Epoch 55/1000\n",
      "40/40 [==============================] - 127s 3s/step - loss: 629.8914\n",
      "Beta: [array([ 0.4878026 ,  0.19238749, -0.32464904,  0.18814118,  0.5366021 ,\n",
      "        0.21823525, -0.45288202,  0.7650784 ], dtype=float32)]\n",
      "Epoch 56/1000\n",
      "40/40 [==============================] - 126s 3s/step - loss: 629.8715\n",
      "Beta: [array([ 0.4916092 ,  0.19314381, -0.32609785,  0.1858764 ,  0.5352337 ,\n",
      "        0.21832398, -0.4523348 ,  0.7654317 ], dtype=float32)]\n",
      "Epoch 57/1000\n",
      "40/40 [==============================] - 128s 3s/step - loss: 629.8662\n",
      "Beta: [array([ 0.49563777,  0.19423294, -0.32717305,  0.1841399 ,  0.5344803 ,\n",
      "        0.21839689, -0.45155227,  0.76629007], dtype=float32)]\n",
      "Epoch 58/1000\n",
      "40/40 [==============================] - 123s 3s/step - loss: 629.8568\n",
      "Beta: [array([ 0.49957052,  0.19521247, -0.32871154,  0.18367417,  0.53350437,\n",
      "        0.2185255 , -0.45075253,  0.76742214], dtype=float32)]\n",
      "Epoch 59/1000\n",
      "40/40 [==============================] - 124s 3s/step - loss: 629.8547\n",
      "Beta: [array([ 0.50346726,  0.19622582, -0.33029476,  0.1830339 ,  0.5319802 ,\n",
      "        0.21854681, -0.4502112 ,  0.76871175], dtype=float32)]\n",
      "Epoch 60/1000\n",
      "40/40 [==============================] - 119s 3s/step - loss: 629.8379\n",
      "Beta: [array([ 0.50682586,  0.19695893, -0.33122578,  0.1821389 ,  0.53030497,\n",
      "        0.21853249, -0.4489853 ,  0.7693147 ], dtype=float32)]\n",
      "Epoch 61/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.8411\n",
      "Beta: [array([ 0.5103518 ,  0.19766487, -0.33236453,  0.18103166,  0.5282317 ,\n",
      "        0.21834525, -0.4479009 ,  0.769861  ], dtype=float32)]\n",
      "Epoch 62/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.8246\n",
      "Beta: [array([ 0.51404625,  0.19862315, -0.33295938,  0.17941855,  0.52709734,\n",
      "        0.2183634 , -0.4466737 ,  0.7699994 ], dtype=float32)]\n",
      "Epoch 63/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.8222\n",
      "Beta: [array([ 0.5188712 ,  0.1996789 , -0.33549052,  0.1787546 ,  0.5252856 ,\n",
      "        0.21838531, -0.44592997,  0.7704797 ], dtype=float32)]\n",
      "Epoch 64/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.8134\n",
      "Beta: [array([ 0.52178204,  0.20008191, -0.335692  ,  0.17731126,  0.52353704,\n",
      "        0.21815792, -0.44436803,  0.7714158 ], dtype=float32)]\n",
      "Epoch 65/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.8236\n",
      "Beta: [array([ 0.52760726,  0.20137022, -0.33855215,  0.17873494,  0.5221991 ,\n",
      "        0.21831027, -0.4438735 ,  0.77258104], dtype=float32)]\n",
      "Epoch 66/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.8020\n",
      "Beta: [array([ 0.53021574,  0.20221946, -0.3393407 ,  0.17580596,  0.519589  ,\n",
      "        0.2183207 , -0.44227275,  0.77195907], dtype=float32)]\n",
      "Epoch 67/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.7941\n",
      "Beta: [array([ 0.5333387 ,  0.20284694, -0.33981547,  0.17435823,  0.51819384,\n",
      "        0.21828087, -0.44133222,  0.77183914], dtype=float32)]\n",
      "Epoch 68/1000\n",
      "40/40 [==============================] - 122s 3s/step - loss: 629.7820\n",
      "Beta: [array([ 0.5376238 ,  0.20380679, -0.3418095 ,  0.17474528,  0.5157457 ,\n",
      "        0.21819913, -0.4396171 ,  0.77255005], dtype=float32)]\n",
      "Epoch 69/1000\n",
      "40/40 [==============================] - 122s 3s/step - loss: 629.7767\n",
      "Beta: [array([ 0.54103583,  0.20459081, -0.34281552,  0.17346935,  0.51322395,\n",
      "        0.21792774, -0.4383193 ,  0.77267647], dtype=float32)]\n",
      "Epoch 70/1000\n",
      "40/40 [==============================] - 132s 3s/step - loss: 629.7770\n",
      "Beta: [array([ 0.54507565,  0.20555605, -0.34348562,  0.17287374,  0.5119    ,\n",
      "        0.21798296, -0.4368041 ,  0.77323896], dtype=float32)]\n",
      "Epoch 71/1000\n",
      "40/40 [==============================] - 130s 3s/step - loss: 629.7670\n",
      "Beta: [array([ 0.54880625,  0.20633861, -0.34524307,  0.17294504,  0.509017  ,\n",
      "        0.2176568 , -0.43553838,  0.77511364], dtype=float32)]\n",
      "Epoch 72/1000\n",
      "40/40 [==============================] - 124s 3s/step - loss: 629.7646\n",
      "Beta: [array([ 0.55309576,  0.2072876 , -0.3467357 ,  0.17329405,  0.5072867 ,\n",
      "        0.21763721, -0.43437016,  0.77442175], dtype=float32)]\n",
      "Epoch 73/1000\n",
      "40/40 [==============================] - 123s 3s/step - loss: 629.7477\n",
      "Beta: [array([ 0.5565713 ,  0.20847201, -0.34789696,  0.17179939,  0.5046468 ,\n",
      "        0.2176586 , -0.4326905 ,  0.77503335], dtype=float32)]\n",
      "Epoch 74/1000\n",
      "40/40 [==============================] - 123s 3s/step - loss: 629.7537\n",
      "Beta: [array([ 0.560143  ,  0.20915514, -0.349577  ,  0.17085491,  0.50291485,\n",
      "        0.21748237, -0.43202692,  0.7759327 ], dtype=float32)]\n",
      "Epoch 75/1000\n",
      "40/40 [==============================] - 123s 3s/step - loss: 629.7430\n",
      "Beta: [array([ 0.56375843,  0.20993993, -0.35083482,  0.17143595,  0.5002125 ,\n",
      "        0.21704313, -0.43043083,  0.77607244], dtype=float32)]\n",
      "Epoch 76/1000\n",
      "40/40 [==============================] - 124s 3s/step - loss: 629.7307\n",
      "Beta: [array([ 0.5678027 ,  0.21106654, -0.35137478,  0.16938679,  0.4979594 ,\n",
      "        0.21725342, -0.42852178,  0.77550256], dtype=float32)]\n",
      "Epoch 77/1000\n",
      "40/40 [==============================] - 124s 3s/step - loss: 629.7291\n",
      "Beta: [array([ 0.57101214,  0.21203327, -0.3531213 ,  0.16953318,  0.4952519 ,\n",
      "        0.21687539, -0.42709348,  0.7759584 ], dtype=float32)]\n",
      "Epoch 78/1000\n",
      "40/40 [==============================] - 125s 3s/step - loss: 629.7243\n",
      "Beta: [array([ 0.57541716,  0.21249165, -0.35432053,  0.169779  ,  0.49334395,\n",
      "        0.21664341, -0.42557278,  0.776317  ], dtype=float32)]\n",
      "Epoch 79/1000\n",
      "40/40 [==============================] - 124s 3s/step - loss: 629.7375\n",
      "Beta: [array([ 0.57842857,  0.21315028, -0.3550338 ,  0.16878279,  0.49160004,\n",
      "        0.21657453, -0.42456824,  0.77851254], dtype=float32)]\n",
      "Epoch 80/1000\n",
      "40/40 [==============================] - 124s 3s/step - loss: 629.7217\n",
      "Beta: [array([ 0.58256596,  0.21433893, -0.35617033,  0.16796133,  0.4887916 ,\n",
      "        0.2162124 , -0.42247516,  0.7768564 ], dtype=float32)]\n",
      "Epoch 81/1000\n",
      "40/40 [==============================] - 124s 3s/step - loss: 629.7032\n",
      "Beta: [array([ 0.5866878 ,  0.21530235, -0.3568849 ,  0.16700093,  0.48632303,\n",
      "        0.2162017 , -0.4201744 ,  0.7774803 ], dtype=float32)]\n",
      "Epoch 82/1000\n",
      "40/40 [==============================] - 123s 3s/step - loss: 629.7081\n",
      "Beta: [array([ 0.5900157 ,  0.21621706, -0.35832605,  0.16728055,  0.48429808,\n",
      "        0.21604954, -0.4196649 ,  0.7785285 ], dtype=float32)]\n",
      "Epoch 83/1000\n",
      "40/40 [==============================] - 123s 3s/step - loss: 629.7123\n",
      "Beta: [array([ 0.5936501 ,  0.21691826, -0.35952342,  0.167014  ,  0.48250192,\n",
      "        0.21577872, -0.41863534,  0.7802322 ], dtype=float32)]\n",
      "Epoch 84/1000\n",
      "40/40 [==============================] - 124s 3s/step - loss: 629.6876\n",
      "Beta: [array([ 0.596741  ,  0.21771084, -0.3600711 ,  0.16581167,  0.47799507,\n",
      "        0.21529645, -0.41535798,  0.7783656 ], dtype=float32)]\n",
      "Epoch 85/1000\n",
      "40/40 [==============================] - 123s 3s/step - loss: 629.6923\n",
      "Beta: [array([ 0.6011112 ,  0.2187965 , -0.36184907,  0.1664715 ,  0.47523323,\n",
      "        0.21525188, -0.41393352,  0.77989256], dtype=float32)]\n",
      "Epoch 86/1000\n",
      "40/40 [==============================] - 124s 3s/step - loss: 629.6800\n",
      "Beta: [array([ 0.6042512 ,  0.21910377, -0.36261284,  0.16561279,  0.47352624,\n",
      "        0.21452263, -0.41310373,  0.7804323 ], dtype=float32)]\n",
      "Epoch 87/1000\n",
      "40/40 [==============================] - 119s 3s/step - loss: 629.6777\n",
      "Beta: [array([ 0.6067307 ,  0.21989487, -0.3628299 ,  0.1645808 ,  0.46976858,\n",
      "        0.21424444, -0.41030183,  0.77950746], dtype=float32)]\n",
      "Epoch 88/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.6760\n",
      "Beta: [array([ 0.61133814,  0.22076634, -0.36378738,  0.16327448,  0.46808764,\n",
      "        0.21438888, -0.40904397,  0.7805717 ], dtype=float32)]\n",
      "Epoch 89/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.6695\n",
      "Beta: [array([ 0.6152221 ,  0.22177736, -0.36573493,  0.16455284,  0.4659566 ,\n",
      "        0.21414013, -0.40828642,  0.78180104], dtype=float32)]\n",
      "Epoch 90/1000\n",
      "40/40 [==============================] - 122s 3s/step - loss: 629.6769\n",
      "Beta: [array([ 0.619912  ,  0.22266915, -0.36678246,  0.16410968,  0.46495268,\n",
      "        0.21411121, -0.40683866,  0.7825182 ], dtype=float32)]\n",
      "Epoch 91/1000\n",
      "40/40 [==============================] - 124s 3s/step - loss: 629.6757\n",
      "Beta: [array([ 0.62299806,  0.22390541, -0.36770496,  0.16364363,  0.46136048,\n",
      "        0.2133621 , -0.40473545,  0.78236204], dtype=float32)]\n",
      "Epoch 92/1000\n",
      "40/40 [==============================] - 123s 3s/step - loss: 629.6577\n",
      "Beta: [array([ 0.6253786 ,  0.22433777, -0.36701864,  0.16130315,  0.45765266,\n",
      "        0.21333745, -0.40151942,  0.78105503], dtype=float32)]\n",
      "Epoch 93/1000\n",
      "40/40 [==============================] - 123s 3s/step - loss: 629.6517\n",
      "Beta: [array([ 0.6291884 ,  0.22504316, -0.3696778 ,  0.16261846,  0.45641273,\n",
      "        0.21300805, -0.40178233,  0.7830002 ], dtype=float32)]\n",
      "Epoch 94/1000\n",
      "40/40 [==============================] - 123s 3s/step - loss: 629.6548\n",
      "Beta: [array([ 0.634179  ,  0.22648823, -0.37114346,  0.16246444,  0.45377743,\n",
      "        0.2125262 , -0.4004551 ,  0.78381985], dtype=float32)]\n",
      "Epoch 95/1000\n",
      "40/40 [==============================] - 123s 3s/step - loss: 629.6445\n",
      "Beta: [array([ 0.6367194 ,  0.22659999, -0.3715522 ,  0.1630919 ,  0.4502952 ,\n",
      "        0.21201292, -0.39843616,  0.78404665], dtype=float32)]\n",
      "Epoch 96/1000\n",
      "40/40 [==============================] - 123s 3s/step - loss: 629.6329\n",
      "Beta: [array([ 0.6392441 ,  0.22758216, -0.37083688,  0.16063073,  0.4471523 ,\n",
      "        0.21158096, -0.39531487,  0.7838065 ], dtype=float32)]\n",
      "Epoch 97/1000\n",
      "40/40 [==============================] - 123s 3s/step - loss: 629.6351\n",
      "Beta: [array([ 0.64105284,  0.22796367, -0.37145913,  0.1596299 ,  0.44479   ,\n",
      "        0.21144967, -0.39366624,  0.782696  ], dtype=float32)]\n",
      "Epoch 98/1000\n",
      "40/40 [==============================] - 123s 3s/step - loss: 629.6311\n",
      "Beta: [array([ 0.64688015,  0.22894661, -0.37282225,  0.16023216,  0.4436629 ,\n",
      "        0.21097445, -0.39284366,  0.78492945], dtype=float32)]\n",
      "Epoch 99/1000\n",
      "40/40 [==============================] - 123s 3s/step - loss: 629.6343\n",
      "Beta: [array([ 0.6494037 ,  0.22982538, -0.37426564,  0.1598269 ,  0.44099808,\n",
      "        0.21039718, -0.39160034,  0.78449893], dtype=float32)]\n",
      "Epoch 100/1000\n",
      "40/40 [==============================] - 123s 3s/step - loss: 629.6218\n",
      "Beta: [array([ 0.6530102 ,  0.23079503, -0.3749739 ,  0.16081697,  0.43904117,\n",
      "        0.21002102, -0.39007854,  0.7866229 ], dtype=float32)]\n",
      "Epoch 101/1000\n",
      "40/40 [==============================] - 122s 3s/step - loss: 629.6329\n",
      "Beta: [array([ 0.65668505,  0.23140818, -0.37604362,  0.1605921 ,  0.4368956 ,\n",
      "        0.20994043, -0.38884804,  0.78682774], dtype=float32)]\n",
      "Epoch 102/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.6205\n",
      "Beta: [array([ 0.66005373,  0.23219906, -0.37610647,  0.15968375,  0.434908  ,\n",
      "        0.2094731 , -0.38663906,  0.78646976], dtype=float32)]\n",
      "Epoch 103/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.6130\n",
      "Beta: [array([ 0.66225433,  0.23255323, -0.37592518,  0.1568372 ,  0.43069628,\n",
      "        0.20880203, -0.38414606,  0.7856949 ], dtype=float32)]\n",
      "Epoch 104/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.6042\n",
      "Beta: [array([ 0.6667008 ,  0.2330195 , -0.37741876,  0.15839036,  0.42851022,\n",
      "        0.2082728 , -0.38281804,  0.78687674], dtype=float32)]\n",
      "Epoch 105/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.6030\n",
      "Beta: [array([ 0.6707335 ,  0.23418103, -0.37851757,  0.15814002,  0.4286507 ,\n",
      "        0.20800912, -0.38319027,  0.78800195], dtype=float32)]\n",
      "Epoch 106/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.6234\n",
      "Beta: [array([ 0.6717528 ,  0.2342452 , -0.37815285,  0.15781334,  0.4235075 ,\n",
      "        0.20708555, -0.37978724,  0.7886012 ], dtype=float32)]\n",
      "Epoch 107/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.6003\n",
      "Beta: [array([ 0.6749582 ,  0.23547277, -0.37899435,  0.15614706,  0.42170674,\n",
      "        0.20705651, -0.37846026,  0.78773874], dtype=float32)]\n",
      "Epoch 108/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.6036\n",
      "Beta: [array([ 0.6792708 ,  0.2364234 , -0.38056183,  0.1574065 ,  0.41971517,\n",
      "        0.20629942, -0.37728125,  0.7883226 ], dtype=float32)]\n",
      "Epoch 109/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5999\n",
      "Beta: [array([ 0.6807385 ,  0.23682836, -0.37867835,  0.15390421,  0.41737536,\n",
      "        0.20532212, -0.37517095,  0.7880958 ], dtype=float32)]\n",
      "Epoch 110/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.6061\n",
      "Beta: [array([ 0.68364406,  0.23684272, -0.3798339 ,  0.15541422,  0.41525182,\n",
      "        0.20503192, -0.3744508 ,  0.78921956], dtype=float32)]\n",
      "Epoch 111/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5908\n",
      "Beta: [array([ 0.68807745,  0.2382426 , -0.38076222,  0.15430741,  0.41306734,\n",
      "        0.20512383, -0.37181517,  0.7875698 ], dtype=float32)]\n",
      "Epoch 112/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5894\n",
      "Beta: [array([ 0.6919792 ,  0.23900914, -0.38216215,  0.15550838,  0.41168198,\n",
      "        0.20477693, -0.37159982,  0.79037756], dtype=float32)]\n",
      "Epoch 113/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5897\n",
      "Beta: [array([ 0.6939679 ,  0.23963825, -0.38290623,  0.1559482 ,  0.4104366 ,\n",
      "        0.20421334, -0.37099797,  0.79008925], dtype=float32)]\n",
      "Epoch 114/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5850\n",
      "Beta: [array([ 0.69756997,  0.24036688, -0.38251692,  0.15544267,  0.40862146,\n",
      "        0.20357038, -0.36832544,  0.7907675 ], dtype=float32)]\n",
      "Epoch 115/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5862\n",
      "Beta: [array([ 0.7020208 ,  0.24024357, -0.38265127,  0.15404876,  0.40700707,\n",
      "        0.20267709, -0.36712945,  0.7913478 ], dtype=float32)]\n",
      "Epoch 116/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5754\n",
      "Beta: [array([ 0.70338064,  0.2410266 , -0.38381475,  0.15339568,  0.4040859 ,\n",
      "        0.20226529, -0.36654365,  0.79268616], dtype=float32)]\n",
      "Epoch 117/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5931\n",
      "Beta: [array([ 0.7060311 ,  0.24228905, -0.38449985,  0.15318836,  0.40124184,\n",
      "        0.2018916 , -0.36434722,  0.7893175 ], dtype=float32)]\n",
      "Epoch 118/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5975\n",
      "Beta: [array([ 0.7074125 ,  0.24253763, -0.38360947,  0.15269898,  0.39847046,\n",
      "        0.20067199, -0.36247844,  0.79031295], dtype=float32)]\n",
      "Epoch 119/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5778\n",
      "Beta: [array([ 0.7111992 ,  0.24256337, -0.38422415,  0.15217943,  0.39841488,\n",
      "        0.20009755, -0.36192408,  0.7929464 ], dtype=float32)]\n",
      "Epoch 120/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5745\n",
      "Beta: [array([ 0.7135828 ,  0.24338931, -0.38441733,  0.15292096,  0.39511067,\n",
      "        0.19947441, -0.3604982 ,  0.79278386], dtype=float32)]\n",
      "Epoch 121/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5837\n",
      "Beta: [array([ 0.71744037,  0.24482772, -0.3862157 ,  0.15328273,  0.39480758,\n",
      "        0.19964135, -0.3602975 ,  0.7916289 ], dtype=float32)]\n",
      "Epoch 122/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5737\n",
      "Beta: [array([ 0.71939504,  0.2452152 , -0.38556126,  0.15244685,  0.3925958 ,\n",
      "        0.19858359, -0.35832468,  0.79280406], dtype=float32)]\n",
      "Epoch 123/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5897\n",
      "Beta: [array([ 0.72487694,  0.24697882, -0.3881112 ,  0.15433052,  0.39215326,\n",
      "        0.19875327, -0.35843006,  0.7951255 ], dtype=float32)]\n",
      "Epoch 124/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5693\n",
      "Beta: [array([ 0.7260906 ,  0.24668443, -0.38591957,  0.15165007,  0.3902517 ,\n",
      "        0.19751571, -0.35610723,  0.79313004], dtype=float32)]\n",
      "Epoch 125/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5667\n",
      "Beta: [array([ 0.72867596,  0.24697936, -0.3869587 ,  0.15073194,  0.38869664,\n",
      "        0.19713368, -0.35606945,  0.7942176 ], dtype=float32)]\n",
      "Epoch 126/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5572\n",
      "Beta: [array([ 0.7324168 ,  0.2477616 , -0.38741785,  0.15087658,  0.3853641 ,\n",
      "        0.19613622, -0.35408556,  0.7950781 ], dtype=float32)]\n",
      "Epoch 127/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5585\n",
      "Beta: [array([ 0.7334635 ,  0.2479153 , -0.3871197 ,  0.15080804,  0.383679  ,\n",
      "        0.19511673, -0.35192463,  0.79403555], dtype=float32)]\n",
      "Epoch 128/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5569\n",
      "Beta: [array([ 0.7348752 ,  0.24842937, -0.38646683,  0.15032731,  0.38153377,\n",
      "        0.19471629, -0.35111555,  0.7941049 ], dtype=float32)]\n",
      "Epoch 129/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5570\n",
      "Beta: [array([ 0.7404456 ,  0.25006646, -0.38796803,  0.14988615,  0.38398534,\n",
      "        0.1941233 , -0.351928  ,  0.79516155], dtype=float32)]\n",
      "Epoch 130/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5715\n",
      "Beta: [array([ 0.7421375 ,  0.25025642, -0.38843694,  0.15123437,  0.38002685,\n",
      "        0.1936127 , -0.3500027 ,  0.79611844], dtype=float32)]\n",
      "Epoch 131/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5618\n",
      "Beta: [array([ 0.745127  ,  0.25055403, -0.3901097 ,  0.15155666,  0.3786013 ,\n",
      "        0.19269435, -0.34960228,  0.7957965 ], dtype=float32)]\n",
      "Epoch 132/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5519\n",
      "Beta: [array([ 0.74743754,  0.25006714, -0.3876299 ,  0.14860334,  0.37831584,\n",
      "        0.1912711 , -0.3480051 ,  0.7958407 ], dtype=float32)]\n",
      "Epoch 133/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5607\n",
      "Beta: [array([ 0.7490247 ,  0.25079343, -0.3870248 ,  0.1486188 ,  0.37710798,\n",
      "        0.19100884, -0.34703916,  0.79587215], dtype=float32)]\n",
      "Epoch 134/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5615\n",
      "Beta: [array([ 0.7492302 ,  0.251157  , -0.38668796,  0.14940198,  0.37155938,\n",
      "        0.18986729, -0.34305322,  0.79430616], dtype=float32)]\n",
      "Epoch 135/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5564\n",
      "Beta: [array([ 0.75156224,  0.25196788, -0.3863497 ,  0.1478322 ,  0.37051088,\n",
      "        0.18942092, -0.34246734,  0.7941427 ], dtype=float32)]\n",
      "Epoch 136/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5504\n",
      "Beta: [array([ 0.75656116,  0.25309512, -0.38864434,  0.14957005,  0.37127918,\n",
      "        0.18914497, -0.34479114,  0.79785705], dtype=float32)]\n",
      "Epoch 137/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5740\n",
      "Beta: [array([ 0.7597017 ,  0.25328547, -0.3895006 ,  0.15053563,  0.37022883,\n",
      "        0.18764138, -0.34359086,  0.7980106 ], dtype=float32)]\n",
      "Epoch 138/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5541\n",
      "Beta: [array([ 0.76202005,  0.2537818 , -0.38949996,  0.1490026 ,  0.36926916,\n",
      "        0.1874963 , -0.34294674,  0.7971141 ], dtype=float32)]\n",
      "Epoch 139/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5491\n",
      "Beta: [array([ 0.7640731 ,  0.25467134, -0.3892256 ,  0.14843078,  0.3703929 ,\n",
      "        0.18697059, -0.343062  ,  0.79721653], dtype=float32)]\n",
      "Epoch 140/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5550\n",
      "Beta: [array([ 0.7652003 ,  0.25398606, -0.38961187,  0.14967331,  0.3687713 ,\n",
      "        0.18548436, -0.3428375 ,  0.7995545 ], dtype=float32)]\n",
      "Epoch 141/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5475\n",
      "Beta: [array([ 0.76626045,  0.2541237 , -0.38802788,  0.14759193,  0.36620417,\n",
      "        0.18495092, -0.34040153,  0.79733884], dtype=float32)]\n",
      "Epoch 142/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5444\n",
      "Beta: [array([ 0.76905847,  0.25589883, -0.38902506,  0.1470732 ,  0.36383224,\n",
      "        0.18409714, -0.33894598,  0.7968586 ], dtype=float32)]\n",
      "Epoch 143/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5464\n",
      "Beta: [array([ 0.77084833,  0.2548908 , -0.38824445,  0.14821482,  0.365603  ,\n",
      "        0.18326026, -0.339134  ,  0.7979593 ], dtype=float32)]\n",
      "Epoch 144/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5521\n",
      "Beta: [array([ 0.7715638 ,  0.25627807, -0.38837096,  0.14621146,  0.36143696,\n",
      "        0.18208452, -0.33813915,  0.79691863], dtype=float32)]\n",
      "Epoch 145/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5519\n",
      "Beta: [array([ 0.7759418 ,  0.25714204, -0.38812846,  0.14800094,  0.36216667,\n",
      "        0.1815554 , -0.33692154,  0.7979709 ], dtype=float32)]\n",
      "Epoch 146/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5521\n",
      "Beta: [array([ 0.7764407 ,  0.25611994, -0.38730824,  0.14558424,  0.36227632,\n",
      "        0.18085147, -0.33842483,  0.7981378 ], dtype=float32)]\n",
      "Epoch 147/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5444\n",
      "Beta: [array([ 0.778644  ,  0.25779957, -0.3891208 ,  0.14731126,  0.36090967,\n",
      "        0.1806666 , -0.33740443,  0.7996077 ], dtype=float32)]\n",
      "Epoch 148/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5490\n",
      "Beta: [array([ 0.7794047 ,  0.2573021 , -0.3883433 ,  0.14644723,  0.3584585 ,\n",
      "        0.17905731, -0.33523297,  0.79807305], dtype=float32)]\n",
      "Epoch 149/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5422\n",
      "Beta: [array([ 0.78248656,  0.2589054 , -0.3891023 ,  0.14585845,  0.35866314,\n",
      "        0.17824471, -0.33555013,  0.7975136 ], dtype=float32)]\n",
      "Epoch 150/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5388\n",
      "Beta: [array([ 0.7851772 ,  0.25816312, -0.38810995,  0.14700502,  0.35890815,\n",
      "        0.17692682, -0.3357151 ,  0.7997135 ], dtype=float32)]\n",
      "Epoch 151/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5426\n",
      "Beta: [array([ 0.78639746,  0.25866377, -0.3874402 ,  0.146455  ,  0.3576825 ,\n",
      "        0.17603843, -0.3347579 ,  0.7995351 ], dtype=float32)]\n",
      "Epoch 152/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5391\n",
      "Beta: [array([ 0.7871752 ,  0.2589422 , -0.38698557,  0.14519976,  0.3563699 ,\n",
      "        0.17516   , -0.3338546 ,  0.79892683], dtype=float32)]\n",
      "Epoch 153/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5389\n",
      "Beta: [array([ 0.7888152 ,  0.25851962, -0.3871903 ,  0.14632268,  0.35639605,\n",
      "        0.17462723, -0.33354977,  0.79974335], dtype=float32)]\n",
      "Epoch 154/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5608\n",
      "Beta: [array([ 0.789785  ,  0.2603037 , -0.3867455 ,  0.14568865,  0.35273135,\n",
      "        0.17285515, -0.3314305 ,  0.79780126], dtype=float32)]\n",
      "Epoch 155/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5735\n",
      "Beta: [array([ 0.7947883 ,  0.2611294 , -0.38964182,  0.14742407,  0.35397783,\n",
      "        0.17294507, -0.33345678,  0.801395  ], dtype=float32)]\n",
      "Epoch 156/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5471\n",
      "Beta: [array([ 0.79612494,  0.2606346 , -0.38806054,  0.1454126 ,  0.3556479 ,\n",
      "        0.1725877 , -0.33377227,  0.79954803], dtype=float32)]\n",
      "Epoch 157/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5633\n",
      "Beta: [array([ 0.7976393 ,  0.26145828, -0.38891187,  0.1471485 ,  0.35489285,\n",
      "        0.17120372, -0.3333538 ,  0.80097806], dtype=float32)]\n",
      "Epoch 158/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5442\n",
      "Beta: [array([ 0.7963775 ,  0.26006293, -0.38736   ,  0.1453691 ,  0.34903964,\n",
      "        0.16854535, -0.3295983 ,  0.79771787], dtype=float32)]\n",
      "Epoch 159/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5358\n",
      "Beta: [array([ 0.80009127,  0.26283845, -0.3898463 ,  0.14735267,  0.3520125 ,\n",
      "        0.17050552, -0.33397555,  0.80185336], dtype=float32)]\n",
      "Epoch 160/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5475\n",
      "Beta: [array([ 0.79980546,  0.26288068, -0.38681084,  0.1454223 ,  0.34994328,\n",
      "        0.1675782 , -0.3302834 ,  0.7999781 ], dtype=float32)]\n",
      "Epoch 161/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5643\n",
      "Beta: [array([ 0.80120194,  0.2635644 , -0.3858552 ,  0.14406766,  0.3472129 ,\n",
      "        0.16608989, -0.32837301,  0.79831743], dtype=float32)]\n",
      "Epoch 162/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5827\n",
      "Beta: [array([ 0.8027937 ,  0.26217353, -0.38590428,  0.14254636,  0.34909245,\n",
      "        0.16667202, -0.33109254,  0.7994153 ], dtype=float32)]\n",
      "Epoch 163/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5401\n",
      "Beta: [array([ 0.8053881 ,  0.264614  , -0.38709936,  0.14507915,  0.35043183,\n",
      "        0.16635692, -0.3311759 ,  0.8002588 ], dtype=float32)]\n",
      "Epoch 164/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5488\n",
      "Beta: [array([ 0.807965  ,  0.2630928 , -0.38735533,  0.14526576,  0.3467359 ,\n",
      "        0.1634178 , -0.3286514 ,  0.7999538 ], dtype=float32)]\n",
      "Epoch 165/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5639\n",
      "Beta: [array([ 0.8091985 ,  0.26426128, -0.38891974,  0.1457425 ,  0.34946066,\n",
      "        0.16471869, -0.33063138,  0.8009298 ], dtype=float32)]\n",
      "Epoch 166/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5319\n",
      "Beta: [array([ 0.80832565,  0.2636316 , -0.38446683,  0.14287956,  0.34718665,\n",
      "        0.16323555, -0.32753444,  0.7982807 ], dtype=float32)]\n",
      "Epoch 167/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5523\n",
      "Beta: [array([ 0.8095826 ,  0.2636033 , -0.38511655,  0.14317563,  0.34648445,\n",
      "        0.16165192, -0.32954413,  0.80120265], dtype=float32)]\n",
      "Epoch 168/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5386\n",
      "Beta: [array([ 0.8114172 ,  0.26346448, -0.38512287,  0.14461385,  0.34445542,\n",
      "        0.15898122, -0.32761097,  0.79869896], dtype=float32)]\n",
      "Epoch 169/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5665\n",
      "Beta: [array([ 0.81308824,  0.26487154, -0.38501534,  0.145209  ,  0.34429723,\n",
      "        0.15904877, -0.32692093,  0.80033076], dtype=float32)]\n",
      "Epoch 170/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5376\n",
      "Beta: [array([ 0.8154166 ,  0.2641839 , -0.38564643,  0.14505115,  0.34482086,\n",
      "        0.15956576, -0.32809913,  0.8013966 ], dtype=float32)]\n",
      "Epoch 171/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5472\n",
      "Beta: [array([ 0.8150876 ,  0.2655308 , -0.3847453 ,  0.14525157,  0.34549794,\n",
      "        0.15826596, -0.3282657 ,  0.8022725 ], dtype=float32)]\n",
      "Epoch 172/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5419\n",
      "Beta: [array([ 0.8157957 ,  0.2641558 , -0.38297737,  0.14307861,  0.34379914,\n",
      "        0.15616076, -0.32597175,  0.7992257 ], dtype=float32)]\n",
      "Epoch 173/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5652\n",
      "Beta: [array([ 0.81869936,  0.26639265, -0.3855327 ,  0.14436382,  0.3428397 ,\n",
      "        0.15594125, -0.32715958,  0.80113417], dtype=float32)]\n",
      "Epoch 174/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5623\n",
      "Beta: [array([ 0.8191161 ,  0.2658548 , -0.38386282,  0.14359356,  0.3427696 ,\n",
      "        0.1538822 , -0.32726336,  0.8003132 ], dtype=float32)]\n",
      "Epoch 175/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5482\n",
      "Beta: [array([ 0.8200819 ,  0.2665389 , -0.38349578,  0.14378645,  0.34165287,\n",
      "        0.15286806, -0.3264716 ,  0.7993947 ], dtype=float32)]\n",
      "Epoch 176/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5397\n",
      "Beta: [array([ 0.82304597,  0.26808453, -0.38450807,  0.14416116,  0.34384885,\n",
      "        0.15302561, -0.3269983 ,  0.80002594], dtype=float32)]\n",
      "Epoch 177/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5304\n",
      "Beta: [array([ 0.82255405,  0.2667522 , -0.38282454,  0.14336881,  0.34214282,\n",
      "        0.14986342, -0.32609186,  0.8005459 ], dtype=float32)]\n",
      "Epoch 178/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5502\n",
      "Beta: [array([ 0.8234741 ,  0.2678609 , -0.38267952,  0.14366873,  0.3406859 ,\n",
      "        0.14996998, -0.32540762,  0.7998047 ], dtype=float32)]\n",
      "Epoch 179/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5426\n",
      "Beta: [array([ 0.82301366,  0.26548076, -0.38146803,  0.14222217,  0.3409882 ,\n",
      "        0.14936654, -0.32643852,  0.80063653], dtype=float32)]\n",
      "Epoch 180/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5613\n",
      "Beta: [array([ 0.82728344,  0.26831833, -0.3839678 ,  0.14585859,  0.34319925,\n",
      "        0.1491655 , -0.32790878,  0.80255544], dtype=float32)]\n",
      "Epoch 181/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5189\n",
      "Beta: [array([ 0.8257555 ,  0.26755685, -0.3819983 ,  0.14261928,  0.3396506 ,\n",
      "        0.146533  , -0.32603326,  0.80032665], dtype=float32)]\n",
      "Epoch 182/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5380\n",
      "Beta: [array([ 0.8272886 ,  0.26849675, -0.38234407,  0.14464831,  0.34070876,\n",
      "        0.14559743, -0.32751277,  0.8024011 ], dtype=float32)]\n",
      "Epoch 183/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5527\n",
      "Beta: [array([ 0.8270034 ,  0.2678625 , -0.3807618 ,  0.14289932,  0.3377041 ,\n",
      "        0.1442102 , -0.32452136,  0.8000103 ], dtype=float32)]\n",
      "Epoch 184/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5491\n",
      "Beta: [array([ 0.8309343 ,  0.26903826, -0.38221878,  0.14389956,  0.34077984,\n",
      "        0.14486213, -0.32619464,  0.8017068 ], dtype=float32)]\n",
      "Epoch 185/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5394\n",
      "Beta: [array([ 0.83083266,  0.26692045, -0.38072905,  0.14377387,  0.3393906 ,\n",
      "        0.1436006 , -0.32642195,  0.8023013 ], dtype=float32)]\n",
      "Epoch 186/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5394\n",
      "Beta: [array([ 0.8315661 ,  0.27028337, -0.3819517 ,  0.14305542,  0.3392514 ,\n",
      "        0.14299038, -0.32673717,  0.8011613 ], dtype=float32)]\n",
      "Epoch 187/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5302\n",
      "Beta: [array([ 0.83339375,  0.27046874, -0.38257524,  0.14400089,  0.33940268,\n",
      "        0.14228322, -0.32634377,  0.8010983 ], dtype=float32)]\n",
      "Epoch 188/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5296\n",
      "Beta: [array([ 0.8344628 ,  0.27148297, -0.38186064,  0.14368233,  0.33973327,\n",
      "        0.14034173, -0.32667962,  0.8011991 ], dtype=float32)]\n",
      "Epoch 189/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5330\n",
      "Beta: [array([ 0.83403915,  0.26920632, -0.3805881 ,  0.14436015,  0.3384888 ,\n",
      "        0.13779186, -0.3260875 ,  0.8012448 ], dtype=float32)]\n",
      "Epoch 190/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5487\n",
      "Beta: [array([ 0.83292025,  0.26880106, -0.378728  ,  0.14374882,  0.33739114,\n",
      "        0.13754848, -0.32577205,  0.8011257 ], dtype=float32)]\n",
      "Epoch 191/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5366\n",
      "Beta: [array([ 0.8362137 ,  0.27034676, -0.37957355,  0.14367081,  0.33740914,\n",
      "        0.13749424, -0.3257182 ,  0.8018562 ], dtype=float32)]\n",
      "Epoch 192/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5360\n",
      "Beta: [array([ 0.83720815,  0.2683278 , -0.38047823,  0.14437307,  0.33818528,\n",
      "        0.13568433, -0.32722712,  0.8022313 ], dtype=float32)]\n",
      "Epoch 193/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5474\n",
      "Beta: [array([ 0.8387386 ,  0.2717906 , -0.38093853,  0.14361395,  0.338194  ,\n",
      "        0.13587205, -0.326975  ,  0.8007417 ], dtype=float32)]\n",
      "Epoch 194/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5460\n",
      "Beta: [array([ 0.8373405 ,  0.27106753, -0.37826216,  0.14168194,  0.33417493,\n",
      "        0.13354596, -0.32400408,  0.8001676 ], dtype=float32)]\n",
      "Epoch 195/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5364\n",
      "Beta: [array([ 0.84052277,  0.27205867, -0.38117197,  0.14598149,  0.33739924,\n",
      "        0.1333434 , -0.326918  ,  0.80300474], dtype=float32)]\n",
      "Epoch 196/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5396\n",
      "Beta: [array([ 0.8387457 ,  0.2694226 , -0.37774706,  0.14279741,  0.33588365,\n",
      "        0.13127244, -0.3258279 ,  0.80172586], dtype=float32)]\n",
      "Epoch 197/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5314\n",
      "Beta: [array([ 0.84079486,  0.27036852, -0.37923765,  0.14358436,  0.3358502 ,\n",
      "        0.13153556, -0.32727724,  0.80251515], dtype=float32)]\n",
      "Epoch 198/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5344\n",
      "Beta: [array([ 0.8423508 ,  0.2752046 , -0.3793703 ,  0.14569448,  0.33536312,\n",
      "        0.1308914 , -0.3247578 ,  0.8012403 ], dtype=float32)]\n",
      "Epoch 199/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5432\n",
      "Beta: [array([ 0.84129876,  0.27325627, -0.379642  ,  0.14402989,  0.33294573,\n",
      "        0.12715252, -0.3250045 ,  0.7994177 ], dtype=float32)]\n",
      "Epoch 200/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5289\n",
      "Beta: [array([ 0.84597534,  0.27309188, -0.3803111 ,  0.14416666,  0.3370173 ,\n",
      "        0.12903972, -0.32829767,  0.8034877 ], dtype=float32)]\n",
      "Epoch 201/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5535\n",
      "Beta: [array([ 0.843155  ,  0.27230975, -0.37775958,  0.14400828,  0.33573294,\n",
      "        0.12664261, -0.3266773 ,  0.80262226], dtype=float32)]\n",
      "Epoch 202/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5443\n",
      "Beta: [array([ 0.8436697 ,  0.27296713, -0.37754264,  0.14385253,  0.3354675 ,\n",
      "        0.12614872, -0.32597592,  0.8017303 ], dtype=float32)]\n",
      "Epoch 203/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5303\n",
      "Beta: [array([ 0.84361845,  0.27341694, -0.37627554,  0.14379734,  0.33383754,\n",
      "        0.12557591, -0.32499638,  0.801225  ], dtype=float32)]\n",
      "Epoch 204/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5289\n",
      "Beta: [array([ 0.8448346 ,  0.2730994 , -0.37607324,  0.14318764,  0.33324498,\n",
      "        0.12303995, -0.32562807,  0.8015838 ], dtype=float32)]\n",
      "Epoch 205/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5450\n",
      "Beta: [array([ 0.84556496,  0.27383682, -0.3758797 ,  0.14328906,  0.3325913 ,\n",
      "        0.12218887, -0.32537347,  0.80147004], dtype=float32)]\n",
      "Epoch 206/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5424\n",
      "Beta: [array([ 0.8465468 ,  0.274897  , -0.37732235,  0.14220876,  0.33373886,\n",
      "        0.12442292, -0.3283269 ,  0.80267775], dtype=float32)]\n",
      "Epoch 207/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5399\n",
      "Beta: [array([ 0.84578526,  0.27328023, -0.37590298,  0.14243375,  0.33323494,\n",
      "        0.12164558, -0.32567585,  0.80050516], dtype=float32)]\n",
      "Epoch 208/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5398\n",
      "Beta: [array([ 0.8450272 ,  0.27277252, -0.37422574,  0.14209677,  0.3314304 ,\n",
      "        0.11886875, -0.32446107,  0.80022866], dtype=float32)]\n",
      "Epoch 209/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5345\n",
      "Beta: [array([ 0.84799254,  0.2758637 , -0.37616962,  0.14545953,  0.33077204,\n",
      "        0.11986192, -0.32496035,  0.8015461 ], dtype=float32)]\n",
      "Epoch 210/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5356\n",
      "Beta: [array([ 0.85083944,  0.2764758 , -0.37577236,  0.14245036,  0.33502254,\n",
      "        0.12114097, -0.328131  ,  0.8025057 ], dtype=float32)]\n",
      "Epoch 211/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5292\n",
      "Beta: [array([ 0.8502447 ,  0.27748567, -0.3756486 ,  0.14313875,  0.33454186,\n",
      "        0.11940254, -0.327573  ,  0.8013136 ], dtype=float32)]\n",
      "Epoch 212/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5438\n",
      "Beta: [array([ 0.848953  ,  0.27604473, -0.37499774,  0.14240202,  0.33187306,\n",
      "        0.11751012, -0.32630354,  0.80127984], dtype=float32)]\n",
      "Epoch 213/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5372\n",
      "Beta: [array([ 0.8503808 ,  0.27614945, -0.37470016,  0.14428973,  0.3345075 ,\n",
      "        0.11696386, -0.32882792,  0.80390406], dtype=float32)]\n",
      "Epoch 214/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5382\n",
      "Beta: [array([ 0.8520799 ,  0.2762744 , -0.37571865,  0.14507204,  0.33243507,\n",
      "        0.11567507, -0.3265647 ,  0.8017482 ], dtype=float32)]\n",
      "Epoch 215/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5377\n",
      "Beta: [array([ 0.85099113,  0.2760595 , -0.3752311 ,  0.14483917,  0.33159024,\n",
      "        0.11469316, -0.32672548,  0.8016041 ], dtype=float32)]\n",
      "Epoch 216/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5284\n",
      "Beta: [array([ 0.8512821 ,  0.27553737, -0.37458348,  0.14340769,  0.33240506,\n",
      "        0.11470908, -0.32736906,  0.80215234], dtype=float32)]\n",
      "Epoch 217/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5295\n",
      "Beta: [array([ 0.85209674,  0.27821898, -0.374366  ,  0.14454512,  0.33209738,\n",
      "        0.11225942, -0.3269747 ,  0.80237556], dtype=float32)]\n",
      "Epoch 218/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5330\n",
      "Beta: [array([ 0.8536351 ,  0.27670747, -0.37382302,  0.14402814,  0.332894  ,\n",
      "        0.111182  , -0.32767847,  0.8023262 ], dtype=float32)]\n",
      "Epoch 219/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5394\n",
      "Beta: [array([ 0.8511002 ,  0.27573112, -0.3728125 ,  0.14452654,  0.33095887,\n",
      "        0.11194617, -0.32785228,  0.8031736 ], dtype=float32)]\n",
      "Epoch 220/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5413\n",
      "Beta: [array([ 0.85531443,  0.27918184, -0.37528196,  0.14527348,  0.3330064 ,\n",
      "        0.11047968, -0.32873097,  0.80182236], dtype=float32)]\n",
      "Epoch 221/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5358\n",
      "Beta: [array([ 0.85403275,  0.27746287, -0.37394363,  0.14378487,  0.3321904 ,\n",
      "        0.10866756, -0.32914457,  0.8033258 ], dtype=float32)]\n",
      "Epoch 222/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5278\n",
      "Beta: [array([ 0.8536771 ,  0.2780889 , -0.3721013 ,  0.14345735,  0.33123296,\n",
      "        0.10945499, -0.3265738 ,  0.8005243 ], dtype=float32)]\n",
      "Epoch 223/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5383\n",
      "Beta: [array([ 0.8549369 ,  0.2783202 , -0.37130314,  0.14395855,  0.33057055,\n",
      "        0.10833493, -0.32703245,  0.80159324], dtype=float32)]\n",
      "Epoch 224/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5311\n",
      "Beta: [array([ 0.8568051 ,  0.27807692, -0.37384447,  0.14380439,  0.3320977 ,\n",
      "        0.10992621, -0.329174  ,  0.8023064 ], dtype=float32)]\n",
      "Epoch 225/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5362\n",
      "Beta: [array([ 0.85491824,  0.28092855, -0.3717304 ,  0.14333875,  0.33147672,\n",
      "        0.10883956, -0.3279324 ,  0.8017881 ], dtype=float32)]\n",
      "Epoch 226/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5325\n",
      "Beta: [array([ 0.856287  ,  0.28153053, -0.3722143 ,  0.1432691 ,  0.3311755 ,\n",
      "        0.10475269, -0.3290313 ,  0.80291384], dtype=float32)]\n",
      "Epoch 227/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5433\n",
      "Beta: [array([ 0.85866755,  0.27981842, -0.3741966 ,  0.1463893 ,  0.33165407,\n",
      "        0.10474543, -0.33006686,  0.80435735], dtype=float32)]\n",
      "Epoch 228/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5295\n",
      "Beta: [array([ 0.85688263,  0.28225788, -0.3709822 ,  0.14388637,  0.33099627,\n",
      "        0.10706805, -0.32843736,  0.8012586 ], dtype=float32)]\n",
      "Epoch 229/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5281\n",
      "Beta: [array([ 0.8575319 ,  0.28132153, -0.371558  ,  0.14411005,  0.3318077 ,\n",
      "        0.10497857, -0.3293779 ,  0.8024256 ], dtype=float32)]\n",
      "Epoch 230/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5361\n",
      "Beta: [array([ 0.8568211 ,  0.28133455, -0.36974445,  0.14242846,  0.33104247,\n",
      "        0.10345434, -0.32866958,  0.8018029 ], dtype=float32)]\n",
      "Epoch 231/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5377\n",
      "Beta: [array([ 0.8589707 ,  0.28246653, -0.37102604,  0.14482671,  0.33055162,\n",
      "        0.10237622, -0.3284076 ,  0.80315024], dtype=float32)]\n",
      "Epoch 232/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5544\n",
      "Beta: [array([ 0.85827565,  0.2832885 , -0.37019596,  0.1444285 ,  0.3267754 ,\n",
      "        0.10032143, -0.32600483,  0.80079097], dtype=float32)]\n",
      "Epoch 233/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5369\n",
      "Beta: [array([ 0.85909814,  0.28269216, -0.37120005,  0.14485867,  0.3295854 ,\n",
      "        0.10102692, -0.32852033,  0.80138713], dtype=float32)]\n",
      "Epoch 234/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5695\n",
      "Beta: [array([ 0.8623344 ,  0.28237516, -0.37202975,  0.14513609,  0.3323121 ,\n",
      "        0.10213979, -0.33183655,  0.8039884 ], dtype=float32)]\n",
      "Epoch 235/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5273\n",
      "Beta: [array([ 0.8588864 ,  0.28314668, -0.36903915,  0.14144915,  0.3299124 ,\n",
      "        0.10080681, -0.32897964,  0.80082166], dtype=float32)]\n",
      "Epoch 236/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5360\n",
      "Beta: [array([ 0.85975605,  0.28335157, -0.36960354,  0.14436549,  0.32823685,\n",
      "        0.09865224, -0.32882288,  0.8030681 ], dtype=float32)]\n",
      "Epoch 237/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5377\n",
      "Beta: [array([ 0.8595602 ,  0.2833851 , -0.3685461 ,  0.142076  ,  0.32809708,\n",
      "        0.09795254, -0.32748774,  0.8003814 ], dtype=float32)]\n",
      "Epoch 238/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5362\n",
      "Beta: [array([ 0.85962546,  0.28220966, -0.3705066 ,  0.14425185,  0.32756907,\n",
      "        0.09747808, -0.3297797 ,  0.8026553 ], dtype=float32)]\n",
      "Epoch 239/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5284\n",
      "Beta: [array([ 0.8611155 ,  0.2852063 , -0.36832342,  0.14321691,  0.33012837,\n",
      "        0.09901616, -0.32888278,  0.80232   ], dtype=float32)]\n",
      "Epoch 240/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5415\n",
      "Beta: [array([ 0.8602889 ,  0.28464335, -0.36806014,  0.14301126,  0.32683212,\n",
      "        0.09828401, -0.3281149 ,  0.80052674], dtype=float32)]\n",
      "Epoch 241/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5331\n",
      "Beta: [array([ 0.8608433 ,  0.28208405, -0.36812243,  0.14193372,  0.32749557,\n",
      "        0.09590227, -0.32845503,  0.8001234 ], dtype=float32)]\n",
      "Epoch 242/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5413\n",
      "Beta: [array([ 0.8608252 ,  0.28098798, -0.3672902 ,  0.1426018 ,  0.32851183,\n",
      "        0.09347595, -0.33036703,  0.8015474 ], dtype=float32)]\n",
      "Epoch 243/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5320\n",
      "Beta: [array([ 0.86123484,  0.2839002 , -0.36808375,  0.14491527,  0.32880962,\n",
      "        0.09481097, -0.3292963 ,  0.80219966], dtype=float32)]\n",
      "Epoch 244/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5273\n",
      "Beta: [array([ 0.8601636 ,  0.28203946, -0.36797118,  0.14320093,  0.32640204,\n",
      "        0.09313012, -0.32968158,  0.8019476 ], dtype=float32)]\n",
      "Epoch 245/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5349\n",
      "Beta: [array([ 0.86299723,  0.28583008, -0.36861277,  0.14358899,  0.32709152,\n",
      "        0.09524389, -0.3300657 ,  0.80087584], dtype=float32)]\n",
      "Epoch 246/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5401\n",
      "Beta: [array([ 0.8626459 ,  0.28512296, -0.36630636,  0.14150164,  0.3273851 ,\n",
      "        0.09371576, -0.32996175,  0.80202305], dtype=float32)]\n",
      "Epoch 247/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5383\n",
      "Beta: [array([ 0.862104  ,  0.2855578 , -0.36653686,  0.14173825,  0.3262992 ,\n",
      "        0.09194648, -0.32871267,  0.80021465], dtype=float32)]\n",
      "Epoch 248/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5326\n",
      "Beta: [array([ 0.8633313 ,  0.2867647 , -0.36789855,  0.14446945,  0.32838374,\n",
      "        0.09338683, -0.3315335 ,  0.80301994], dtype=float32)]\n",
      "Epoch 249/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5296\n",
      "Beta: [array([ 0.8627494 ,  0.2890259 , -0.36854932,  0.14488184,  0.3273286 ,\n",
      "        0.09236896, -0.33156475,  0.8022945 ], dtype=float32)]\n",
      "Epoch 250/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5350\n",
      "Beta: [array([ 0.8633993 ,  0.28472263, -0.36537582,  0.14202058,  0.3279123 ,\n",
      "        0.08909563, -0.33044893,  0.80152243], dtype=float32)]\n",
      "Epoch 251/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5363\n",
      "Beta: [array([ 0.8654544 ,  0.28659567, -0.36750302,  0.14413446,  0.3301851 ,\n",
      "        0.0894995 , -0.33235377,  0.80351543], dtype=float32)]\n",
      "Epoch 252/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5569\n",
      "Beta: [array([ 0.86282253,  0.28729108, -0.36707965,  0.14456557,  0.32800964,\n",
      "        0.09132489, -0.33126628,  0.80254614], dtype=float32)]\n",
      "Epoch 253/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5300\n",
      "Beta: [array([ 0.8637281 ,  0.28635037, -0.36587065,  0.14449346,  0.327724  ,\n",
      "        0.08716389, -0.33074048,  0.80297047], dtype=float32)]\n",
      "Epoch 254/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5564\n",
      "Beta: [array([ 0.86587614,  0.2833721 , -0.36635208,  0.14376393,  0.32887214,\n",
      "        0.08897822, -0.33217576,  0.8034487 ], dtype=float32)]\n",
      "Epoch 255/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5532\n",
      "Beta: [array([ 0.86593187,  0.28817785, -0.3673911 ,  0.14609359,  0.32883722,\n",
      "        0.08781619, -0.33309412,  0.8034967 ], dtype=float32)]\n",
      "Epoch 256/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5327\n",
      "Beta: [array([ 0.86406213,  0.2873006 , -0.36531565,  0.1422098 ,  0.32688946,\n",
      "        0.08882347, -0.3320321 ,  0.80046076], dtype=float32)]\n",
      "Epoch 257/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5348\n",
      "Beta: [array([ 0.8653831 ,  0.28715426, -0.36505425,  0.14294879,  0.32748678,\n",
      "        0.08607688, -0.33186716,  0.80250204], dtype=float32)]\n",
      "Epoch 258/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5305\n",
      "Beta: [array([ 0.86461246,  0.28542027, -0.36514544,  0.14451297,  0.32734713,\n",
      "        0.08387335, -0.33108845,  0.8029133 ], dtype=float32)]\n",
      "Epoch 259/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5305\n",
      "Beta: [array([ 0.86378133,  0.288412  , -0.36443704,  0.14183827,  0.32523787,\n",
      "        0.08351383, -0.33151278,  0.80047137], dtype=float32)]\n",
      "Epoch 260/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5313\n",
      "Beta: [array([ 0.8649654 ,  0.28875223, -0.36484838,  0.14311746,  0.325016  ,\n",
      "        0.08515187, -0.3308502 ,  0.799644  ], dtype=float32)]\n",
      "Epoch 261/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5261\n",
      "Beta: [array([ 0.86624235,  0.2884896 , -0.36519632,  0.14412127,  0.32667413,\n",
      "        0.08870957, -0.33207315,  0.80188227], dtype=float32)]\n",
      "Epoch 262/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5266\n",
      "Beta: [array([ 0.8669206 ,  0.28932145, -0.36515447,  0.14407964,  0.3274316 ,\n",
      "        0.08658392, -0.33285683,  0.8024068 ], dtype=float32)]\n",
      "Epoch 263/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5248\n",
      "Beta: [array([ 0.86633426,  0.29113668, -0.3635905 ,  0.14386156,  0.3265684 ,\n",
      "        0.08520208, -0.33223525,  0.8024565 ], dtype=float32)]\n",
      "Epoch 264/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5436\n",
      "Beta: [array([ 0.86668986,  0.29154965, -0.3636168 ,  0.14168213,  0.32813957,\n",
      "        0.08528865, -0.332196  ,  0.7992292 ], dtype=float32)]\n",
      "Epoch 265/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5441\n",
      "Beta: [array([ 0.86578995,  0.28948256, -0.36267465,  0.14270636,  0.32658368,\n",
      "        0.08617093, -0.33265296,  0.8015008 ], dtype=float32)]\n",
      "Epoch 266/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5457\n",
      "Beta: [array([ 0.86830515,  0.2917527 , -0.365052  ,  0.14410901,  0.3261236 ,\n",
      "        0.08299864, -0.3332395 ,  0.8015261 ], dtype=float32)]\n",
      "Epoch 267/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5258\n",
      "Beta: [array([ 0.8665237 ,  0.29217252, -0.36446592,  0.14368519,  0.32629484,\n",
      "        0.0841608 , -0.33377266,  0.8029087 ], dtype=float32)]\n",
      "Epoch 268/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5419\n",
      "Beta: [array([ 0.867598  ,  0.2896978 , -0.3654147 ,  0.14546807,  0.32523108,\n",
      "        0.08220636, -0.33339128,  0.8030208 ], dtype=float32)]\n",
      "Epoch 269/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5292\n",
      "Beta: [array([ 0.8691186 ,  0.2930638 , -0.36496308,  0.1451308 ,  0.32549718,\n",
      "        0.08190972, -0.33289748,  0.80287796], dtype=float32)]\n",
      "Epoch 270/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5505\n",
      "Beta: [array([ 0.8674322 ,  0.29158053, -0.36410573,  0.14357583,  0.32479367,\n",
      "        0.08115494, -0.33299795,  0.8029246 ], dtype=float32)]\n",
      "Epoch 271/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5555\n",
      "Beta: [array([ 0.8667919 ,  0.2913947 , -0.36216873,  0.14306608,  0.32471076,\n",
      "        0.08059693, -0.33175448,  0.8006003 ], dtype=float32)]\n",
      "Epoch 272/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5344\n",
      "Beta: [array([ 0.8683968 ,  0.29160836, -0.36294317,  0.14445381,  0.3263249 ,\n",
      "        0.07882001, -0.33311966,  0.80122566], dtype=float32)]\n",
      "Epoch 273/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5300\n",
      "Beta: [array([ 0.86900973,  0.2928399 , -0.36300007,  0.14355439,  0.3265268 ,\n",
      "        0.08272251, -0.33425412,  0.80146116], dtype=float32)]\n",
      "Epoch 274/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5275\n",
      "Beta: [array([ 0.86760664,  0.29113257, -0.3614589 ,  0.1426248 ,  0.32585946,\n",
      "        0.08123005, -0.33325717,  0.8018686 ], dtype=float32)]\n",
      "Epoch 275/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5352\n",
      "Beta: [array([ 0.86823833,  0.29298002, -0.36334428,  0.14504457,  0.32472476,\n",
      "        0.08068407, -0.33451915,  0.8026104 ], dtype=float32)]\n",
      "Epoch 276/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5363\n",
      "Beta: [array([ 0.8677759 ,  0.2911949 , -0.36155242,  0.14378801,  0.32457894,\n",
      "        0.07795556, -0.33289775,  0.8013633 ], dtype=float32)]\n",
      "Epoch 277/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5292\n",
      "Beta: [array([ 0.86982656,  0.293199  , -0.3629691 ,  0.1445897 ,  0.32640254,\n",
      "        0.07945762, -0.3347863 ,  0.8028074 ], dtype=float32)]\n",
      "Epoch 278/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5332\n",
      "Beta: [array([ 0.86930215,  0.29273036, -0.36031792,  0.14312246,  0.32591176,\n",
      "        0.07723823, -0.33275786,  0.8014883 ], dtype=float32)]\n",
      "Epoch 279/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5344\n",
      "Beta: [array([ 0.8684573 ,  0.29442784, -0.3617066 ,  0.14405273,  0.32418105,\n",
      "        0.07975631, -0.33384693,  0.8010536 ], dtype=float32)]\n",
      "Epoch 280/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5411\n",
      "Beta: [array([ 0.8698381 ,  0.2944188 , -0.36215982,  0.14303143,  0.32321522,\n",
      "        0.07705398, -0.33341265,  0.80012274], dtype=float32)]\n",
      "Epoch 281/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5370\n",
      "Beta: [array([ 0.8702124 ,  0.29310182, -0.36164513,  0.14318417,  0.32557526,\n",
      "        0.07829401, -0.33507505,  0.8018855 ], dtype=float32)]\n",
      "Epoch 282/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5506\n",
      "Beta: [array([ 0.8704388 ,  0.29319754, -0.36256555,  0.14456442,  0.32476005,\n",
      "        0.07836557, -0.33528697,  0.8031924 ], dtype=float32)]\n",
      "Epoch 283/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5255\n",
      "Beta: [array([ 0.8686967 ,  0.29463387, -0.3598398 ,  0.14240791,  0.32463259,\n",
      "        0.07812873, -0.33414754,  0.80131155], dtype=float32)]\n",
      "Epoch 284/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5383\n",
      "Beta: [array([ 0.8693305 ,  0.2949063 , -0.361521  ,  0.14455867,  0.32472193,\n",
      "        0.07471769, -0.33551252,  0.80275035], dtype=float32)]\n",
      "Epoch 285/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5311\n",
      "Beta: [array([ 0.8707159 ,  0.29737496, -0.36001912,  0.14176527,  0.3269978 ,\n",
      "        0.07940086, -0.33506435,  0.8015187 ], dtype=float32)]\n",
      "Epoch 286/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5306\n",
      "Beta: [array([ 0.87101966,  0.29511887, -0.361322  ,  0.14359024,  0.32499197,\n",
      "        0.07853977, -0.33494106,  0.8010498 ], dtype=float32)]\n",
      "Epoch 287/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5427\n",
      "Beta: [array([ 0.8690247 ,  0.29607102, -0.35933188,  0.14120664,  0.3244176 ,\n",
      "        0.07577622, -0.33418977,  0.79975647], dtype=float32)]\n",
      "Epoch 288/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5351\n",
      "Beta: [array([ 0.86825293,  0.2924528 , -0.35920876,  0.14358652,  0.3232798 ,\n",
      "        0.07753583, -0.33464384,  0.8017686 ], dtype=float32)]\n",
      "Epoch 289/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5354\n",
      "Beta: [array([ 0.8706146 ,  0.29648694, -0.36066988,  0.14519104,  0.32387665,\n",
      "        0.07254861, -0.33384988,  0.8015402 ], dtype=float32)]\n",
      "Epoch 290/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5292\n",
      "Beta: [array([ 0.87110496,  0.29537776, -0.36009344,  0.14329475,  0.32268193,\n",
      "        0.07564896, -0.3352663 ,  0.8012847 ], dtype=float32)]\n",
      "Epoch 291/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5513\n",
      "Beta: [array([ 0.87003225,  0.29534808, -0.35923398,  0.14369218,  0.32440546,\n",
      "        0.07514531, -0.33448732,  0.8012862 ], dtype=float32)]\n",
      "Epoch 292/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5370\n",
      "Beta: [array([ 0.8708056 ,  0.2967315 , -0.35924807,  0.14354815,  0.32479686,\n",
      "        0.07417984, -0.33490047,  0.8017745 ], dtype=float32)]\n",
      "Epoch 293/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5331\n",
      "Beta: [array([ 0.87026906,  0.29684082, -0.35926282,  0.14433216,  0.32359916,\n",
      "        0.07558303, -0.33529192,  0.8012607 ], dtype=float32)]\n",
      "Epoch 294/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5328\n",
      "Beta: [array([ 0.8708725 ,  0.2985444 , -0.3591167 ,  0.14253469,  0.32410923,\n",
      "        0.07416964, -0.3348571 ,  0.79944235], dtype=float32)]\n",
      "Epoch 295/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5340\n",
      "Beta: [array([ 0.8712372 ,  0.2953286 , -0.35826173,  0.14310914,  0.3259811 ,\n",
      "        0.07514495, -0.3360964 ,  0.8025291 ], dtype=float32)]\n",
      "Epoch 296/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5319\n",
      "Beta: [array([ 0.8726122 ,  0.296052  , -0.36087477,  0.14541556,  0.3245023 ,\n",
      "        0.0762215 , -0.3364687 ,  0.8021301 ], dtype=float32)]\n",
      "Epoch 297/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5328\n",
      "Beta: [array([ 0.8709165 ,  0.29698274, -0.35822588,  0.14309065,  0.32379636,\n",
      "        0.07344472, -0.33463463,  0.80057794], dtype=float32)]\n",
      "Epoch 298/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5242\n",
      "Beta: [array([ 0.87045544,  0.2963227 , -0.35852033,  0.14371642,  0.32377246,\n",
      "        0.0732777 , -0.33593923,  0.8024177 ], dtype=float32)]\n",
      "Epoch 299/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5320\n",
      "Beta: [array([ 0.8702115 ,  0.2963633 , -0.35796416,  0.14347   ,  0.32326493,\n",
      "        0.0728813 , -0.33486405,  0.8002079 ], dtype=float32)]\n",
      "Epoch 300/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5338\n",
      "Beta: [array([ 0.87184757,  0.29664615, -0.35967836,  0.14389881,  0.3237203 ,\n",
      "        0.0735672 , -0.33714697,  0.80279136], dtype=float32)]\n",
      "Epoch 301/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5286\n",
      "Beta: [array([ 0.8700369 ,  0.2969474 , -0.35837525,  0.14421387,  0.32311484,\n",
      "        0.07209799, -0.33649683,  0.8009275 ], dtype=float32)]\n",
      "Epoch 302/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5389\n",
      "Beta: [array([ 0.8726691 ,  0.29816887, -0.3590698 ,  0.14553046,  0.32555482,\n",
      "        0.07312067, -0.3377027 ,  0.8032481 ], dtype=float32)]\n",
      "Epoch 303/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5305\n",
      "Beta: [array([ 0.8706763 ,  0.29664108, -0.35571554,  0.14380908,  0.32305405,\n",
      "        0.071612  , -0.33429515,  0.8002539 ], dtype=float32)]\n",
      "Epoch 304/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5284\n",
      "Beta: [array([ 0.8708725 ,  0.29547173, -0.35610077,  0.14314085,  0.3240998 ,\n",
      "        0.07269366, -0.33576402,  0.8014776 ], dtype=float32)]\n",
      "Epoch 305/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5284\n",
      "Beta: [array([ 0.86973494,  0.2979411 , -0.35797587,  0.14418484,  0.32288495,\n",
      "        0.07171589, -0.33736768,  0.8027251 ], dtype=float32)]\n",
      "Epoch 306/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5313\n",
      "Beta: [array([ 0.87176   ,  0.29617324, -0.35787174,  0.14437805,  0.32219833,\n",
      "        0.07149693, -0.33633366,  0.8014773 ], dtype=float32)]\n",
      "Epoch 307/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5342\n",
      "Beta: [array([ 0.87361735,  0.29804966, -0.35850412,  0.14243442,  0.3243811 ,\n",
      "        0.07049958, -0.3374167 ,  0.80086005], dtype=float32)]\n",
      "Epoch 308/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5507\n",
      "Beta: [array([ 0.87033594,  0.29972994, -0.3569481 ,  0.1409481 ,  0.31988835,\n",
      "        0.06973593, -0.33521336,  0.7984849 ], dtype=float32)]\n",
      "Epoch 309/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5515\n",
      "Beta: [array([ 0.8722306 ,  0.29691234, -0.358581  ,  0.14570601,  0.3250755 ,\n",
      "        0.06955313, -0.33944535,  0.804061  ], dtype=float32)]\n",
      "Epoch 310/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5214\n",
      "Beta: [array([ 0.8698596 ,  0.29909164, -0.35673138,  0.14326027,  0.319206  ,\n",
      "        0.06946915, -0.3347973 ,  0.7995721 ], dtype=float32)]\n",
      "Epoch 311/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5411\n",
      "Beta: [array([ 0.8741784 ,  0.29988497, -0.35847008,  0.14492077,  0.3257136 ,\n",
      "        0.07112034, -0.33855242,  0.8032797 ], dtype=float32)]\n",
      "Epoch 312/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5306\n",
      "Beta: [array([ 0.87198025,  0.2973085 , -0.35744315,  0.14503603,  0.32500896,\n",
      "        0.07059796, -0.3394695 ,  0.8024984 ], dtype=float32)]\n",
      "Epoch 313/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5350\n",
      "Beta: [array([ 0.8715704 ,  0.30001003, -0.35745403,  0.14452419,  0.32394198,\n",
      "        0.06742776, -0.3387937 ,  0.8026936 ], dtype=float32)]\n",
      "Epoch 314/1000\n",
      "40/40 [==============================] - 117s 3s/step - loss: 629.5403\n",
      "Beta: [array([ 0.87182605,  0.29925415, -0.35568702,  0.14288838,  0.3210201 ,\n",
      "        0.06971096, -0.33479753,  0.7984711 ], dtype=float32)]\n",
      "Epoch 315/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5372\n",
      "Beta: [array([ 0.8732247 ,  0.29841915, -0.3558577 ,  0.14391544,  0.32358795,\n",
      "        0.07261471, -0.33778527,  0.80224425], dtype=float32)]\n",
      "Epoch 316/1000\n",
      "40/40 [==============================] - 118s 3s/step - loss: 629.5298\n",
      "Beta: [array([ 0.8722856 ,  0.30095047, -0.35709932,  0.14479922,  0.3233504 ,\n",
      "        0.07083055, -0.33907497,  0.8023615 ], dtype=float32)]\n",
      "Epoch 317/1000\n",
      " 2/40 [>.............................] - ETA: 3:45 - loss: 704.0593     "
     ]
    }
   ],
   "source": [
    "# Now try to fit the model sampled from the real parameters.\n",
    "initializer = tf.keras.initializers.Constant([ 0.,  0., 0.,  0., 0., 0., 0., 0.]),\n",
    "model = build_hmm_to_fit_beta( states_observable=STATES_ARE_OBSERVABLE, mu=MU, initializer=initializer )\n",
    "\n",
    "compiler = CompilerInfoBeta(LR_EXPONENTIAL_DECAY)\n",
    "model.compile(\n",
    "    loss = compiler.loss,\n",
    "    optimizer = compiler.optimizer,\n",
    "    run_eagerly = True\n",
    ")\n",
    "\n",
    "history = fit_model(model, adstock, emission_real)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Supponiamo che il vettore fittato dal modello sia: #camp1: [ 0.8700186 ,  0.29879373, -0.35601237,  0.14475204,                                                     #camp2:   0.32184145,  0.06852179, -0.33719164,  0.80015075]\n",
    "Dal punto di vista teorico, i valori sono in linea con quelli sperati. Per interpetare i parametri, si tenga conto che: abbiamo 8 valori, di cui 4 per campagna: per ogni campagna il parametro 0  linfluenza della campagna a passare da stato 0->1, il parametro 1  linfluenza 0->2, il terzo  linfluenza 1->0 (quindi ci aspettiamo che sia negativo), e il quarto  l'influenza 1->2.\n",
    "Se compariamo i valori, partendo dalla tupla reale, lobiettivo  osservare che la prima campagna influenzi il passaggio da stato 0 a stato 1 pi della seconda campagna, mentre la seconda campagna dovrebbe avere leffetto opposto, ovvero di influenzare pi il passaggio da stato 1 a conversione.\n",
    "Dai valori dei parametri fittati partendo da inizializzazione di zeri, osserviamo alcune cose:\n",
    "1) Alcuni valori sembrano essere stati fittati correttamente. In particolare i valori di transizione da stato 1->2, ovvero 0.15 e 0.8.\n",
    "2) Gli altri pesi attribuiti sono coerenti con quelli reali. La campagna 1 mostra influenze piu alte nello stato zero (peso transizione 0->1 = 0.87, 0->2 = 0.3) rispetto alla campagna 2 (peso transizione 0->1 = 0.32, 0->2 = 0.07), mentre la campagna due mostra peso di transizione da stato intermedio a conversione pi alto (1->2 = 0.8, vs campagna 1: 1->2 = 0.14). Pertanto, seppur i valori non siano esattamente quelli reali, viene catturata l'idea di avere campagne con influenze diverse in stati diversi, principale obiettivo del problema di attribution.\n",
    "3) Nel caso di sanity check partendo da parametri esatti, si  osservato che il vettore cambia nonostante la loss rimanga costante. Il vettore fittato da inizializzazione di zeri, sembrerebbe avvicinarsi a questa versione modificata del vettore reale. Comprendere per quale motivo ci si discosta dal vettore reale forse permetterebbe di risolvere questa discrepanza.\n",
    "\n",
    "Sotto, osserviamo anche la differenza media tra matrici di transizione ottenute con i parametri reali e quelli fittati dal modello."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "matrix_diff = lambda usr: tf.reduce_sum(make_transition_matrix(MU, model_test.weights[0], adstock[usr:usr+1]) - make_transition_matrix(MU,BETA, adstock[usr:usr+1]), axis=1)/30\n",
    "avg_diff = sum(matrix_diff(usr) for usr in range(N_users))/N_users"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=\narray([[[-2.1503285e-02,  2.1464450e-02,  3.8931419e-05],\n        [-2.7916392e-03,  2.9183212e-03, -1.2667537e-04],\n        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00]]], dtype=float32)>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_diff"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}