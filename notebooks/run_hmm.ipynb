{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# HMM to estimate Funnel position"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import libraries and constants"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import config.CONSTANTS_HMM\n",
    "from config.CONSTANTS_HMM import *\n",
    "from config.execution_parameters import *\n",
    "\n",
    "# Project libraries\n",
    "import src.hmm_package.generate_hmm\n",
    "from src.hmm_package.generate_hmm import *\n",
    "from src.plot_and_print_info.plots_and_print_info import *\n",
    "\n",
    "# Built in libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import distributions as tfd\n",
    "import importlib"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "importlib.reload(src.hmm_package.generate_hmm)\n",
    "from src.hmm_package.generate_hmm import *\n",
    "importlib.reload(config.CONSTANTS_HMM)\n",
    "from config.CONSTANTS_HMM import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compute Observation and Adstock"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 09:11:16.444276: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Generate Test observation\n",
    "observation = simulate_observations()\n",
    "\n",
    "# Compute Adstock\n",
    "adstock = compute_adstock(observation=observation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Real HMM to Estimate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Generate the distributions to build the Real HMM\n",
    "#NB The variable STATES_ARE_OBSERVABLE is set in config/execution_parameters.\n",
    "hmm_distributions = generate_hmm_distributions(states_observable=False, adstock=adstock)\n",
    "\n",
    "# Create Real HMM to fit\n",
    "real_hmm = tfd.HiddenMarkovModel(\n",
    "    initial_distribution=hmm_distributions['initial_distribution'],\n",
    "    transition_distribution=hmm_distributions['transition_distribution'],\n",
    "    observation_distribution=hmm_distributions['observation_distribution'],\n",
    "    time_varying_transition_distribution=True,\n",
    "    num_steps=time+1\n",
    ")\n",
    "\n",
    "# Sample emissions\n",
    "emission_real = real_hmm.sample().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sing_dist = generate_hmm_distributions(states_observable=False, adstock=adstock[0:1])\n",
    "\n",
    "# Create Real HMM to fit\n",
    "single = tfd.HiddenMarkovModel(\n",
    "    initial_distribution=sing_dist['initial_distribution'],\n",
    "    transition_distribution=sing_dist['transition_distribution'],\n",
    "    observation_distribution=sing_dist['observation_distribution'],\n",
    "    time_varying_transition_distribution=True,\n",
    "    num_steps=time+1\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = single.sample()\n",
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_function(a,single)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.reduce_sum(tf.math.multiply(tf.exp(single.posterior_marginals(a).logits),tf.exp(single.prior_marginals().logits)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "single.prior_marginals().logits[:, :, -1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prior_probs = tf.exp(single.prior_marginals().logits[:, :, -1])\n",
    "tf.reduce_sum(1 - prior_probs[tf.math.equal(a,1)]) + tf.reduce_sum(prior_probs[a == 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize the Real HMM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5097\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 2160x72 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count conversions from sampled data\n",
    "tot_conversions = count_conversions(emission_real, STATES_ARE_OBSERVABLE)\n",
    "\n",
    "plot_sample_emissions(real_hmm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build model to fit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 09:12:02.877783: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "# STATES_ARE_OBSERVABLE is defined in CONSTANTS_HMM\n",
    "model = build_hmm_to_fit_beta( states_observable=STATES_ARE_OBSERVABLE, mu=MU )\n",
    "\n",
    "compiler = CompilerInfoBeta(LR_EXPONENTIAL_DECAY)\n",
    "model.compile(\n",
    "    loss = compiler.loss,\n",
    "    optimizer = compiler.optimizer,\n",
    "    run_eagerly = True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fit the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta: [array([ 1. ,  0.5, -0.5,  0.5,  0.5,  0.5, -0.5,  1. ], dtype=float32)]\n",
      "Epoch 1/1000\n",
      "40/40 [==============================] - 70s 2s/step - loss: 2521.9929\n",
      "Beta: [array([ 0.96875405,  0.5027109 , -0.49212813,  0.48933432,  0.4684948 ,\n",
      "        0.49776706, -0.4920853 ,  0.98868746], dtype=float32)]\n",
      "Epoch 2/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 2484.6792\n",
      "Beta: [array([ 0.95312434,  0.508482  , -0.4838513 ,  0.47934026,  0.44853368,\n",
      "        0.5022312 , -0.4840446 ,  0.9787639 ], dtype=float32)]\n",
      "Epoch 3/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 2456.4485\n",
      "Beta: [array([ 0.9374098 ,  0.5140682 , -0.47750312,  0.47145194,  0.42875928,\n",
      "        0.50628877, -0.4774911 ,  0.97087646], dtype=float32)]\n",
      "Epoch 4/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 2422.4978\n",
      "Beta: [array([ 0.91986376,  0.51734906, -0.46923214,  0.46207637,  0.40857574,\n",
      "        0.5064704 , -0.46878752,  0.96123344], dtype=float32)]\n",
      "Epoch 5/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 2389.0049\n",
      "Beta: [array([ 0.90406454,  0.524887  , -0.462448  ,  0.45374313,  0.39004698,\n",
      "        0.51708776, -0.46188784,  0.95287454], dtype=float32)]\n",
      "Epoch 6/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 2355.5569\n",
      "Beta: [array([ 0.8891247 ,  0.53591174, -0.45593572,  0.44599473,  0.37287363,\n",
      "        0.52672654, -0.4555819 ,  0.9450132 ], dtype=float32)]\n",
      "Epoch 7/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 2334.0269\n",
      "Beta: [array([ 0.8706504 ,  0.54637194, -0.4499103 ,  0.43944794,  0.35190028,\n",
      "        0.53818035, -0.44890997,  0.9382327 ], dtype=float32)]\n",
      "Epoch 8/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 2300.5127\n",
      "Beta: [array([ 0.85232985,  0.5523747 , -0.44223705,  0.43137866,  0.33161852,\n",
      "        0.54585594, -0.44117182,  0.9301351 ], dtype=float32)]\n",
      "Epoch 9/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 2276.6528\n",
      "Beta: [array([ 0.8352565 ,  0.56413287, -0.43664935,  0.42577547,  0.31254026,\n",
      "        0.5594177 , -0.43486884,  0.92431736], dtype=float32)]\n",
      "Epoch 10/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 2240.2896\n",
      "Beta: [array([ 0.8153048 ,  0.5710876 , -0.42760664,  0.41800275,  0.2901908 ,\n",
      "        0.5695414 , -0.42524916,  0.9164945 ], dtype=float32)]\n",
      "Epoch 11/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 2224.0647\n",
      "Beta: [array([ 0.79668   ,  0.585032  , -0.42376524,  0.4142242 ,  0.26911664,\n",
      "        0.585227  , -0.42110395,  0.91273713], dtype=float32)]\n",
      "Epoch 12/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 2189.7783\n",
      "Beta: [array([ 0.7710011 ,  0.59574634, -0.41495827,  0.40705198,  0.24229977,\n",
      "        0.59539044, -0.41134468,  0.90518975], dtype=float32)]\n",
      "Epoch 13/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 2174.3584\n",
      "Beta: [array([ 0.7474745 ,  0.6093073 , -0.41237816,  0.4045812 ,  0.2135907 ,\n",
      "        0.61552554, -0.40832087,  0.90278196], dtype=float32)]\n",
      "Epoch 14/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 2150.5310\n",
      "Beta: [array([ 0.72273135,  0.6171812 , -0.40621382,  0.39996773,  0.18605992,\n",
      "        0.62510777, -0.4014498 ,  0.8980675 ], dtype=float32)]\n",
      "Epoch 15/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 2127.2615\n",
      "Beta: [array([ 0.7017236 ,  0.62261504, -0.39772615,  0.3949286 ,  0.15934364,\n",
      "        0.6379701 , -0.39235866,  0.89295006], dtype=float32)]\n",
      "Epoch 16/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 2096.1377\n",
      "Beta: [array([ 0.6716825 ,  0.6423293 , -0.3855422 ,  0.3878694 ,  0.12442043,\n",
      "        0.6635953 , -0.37985387,  0.8860851 ], dtype=float32)]\n",
      "Epoch 17/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 2074.4133\n",
      "Beta: [array([ 0.65368235,  0.6512624 , -0.37812397,  0.38359326,  0.10149987,\n",
      "        0.67761683, -0.37182233,  0.88179976], dtype=float32)]\n",
      "Epoch 18/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 2056.6111\n",
      "Beta: [array([ 0.62989986,  0.67072725, -0.37113473,  0.38016164,  0.0744708 ,\n",
      "        0.70084035, -0.36453322,  0.8784461 ], dtype=float32)]\n",
      "Epoch 19/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 2037.7582\n",
      "Beta: [array([ 0.6149239 ,  0.6797558 , -0.3630459 ,  0.37611115,  0.05619328,\n",
      "        0.7135075 , -0.35579085,  0.87429935], dtype=float32)]\n",
      "Epoch 20/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 2030.5070\n",
      "Beta: [array([ 0.6016275 ,  0.6910072 , -0.3621391 ,  0.3753374 ,  0.03925432,\n",
      "        0.72879744, -0.3546433 ,  0.87362784], dtype=float32)]\n",
      "Epoch 21/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 2022.0728\n",
      "Beta: [array([ 0.5883027 ,  0.70224565, -0.35507873,  0.3709371 ,  0.02339059,\n",
      "        0.7438001 , -0.3472011 ,  0.8691564 ], dtype=float32)]\n",
      "Epoch 22/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 2008.3478\n",
      "Beta: [array([ 0.5874047 ,  0.7011062 , -0.34873202,  0.36662805,  0.01671043,\n",
      "        0.7495998 , -0.3409641 ,  0.8651628 ], dtype=float32)]\n",
      "Epoch 23/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1993.2710\n",
      "Beta: [array([ 0.57672375,  0.7106202 , -0.34380072,  0.3632681 ,  0.00228173,\n",
      "        0.76377016, -0.3357819 ,  0.86175066], dtype=float32)]\n",
      "Epoch 24/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1993.8184\n",
      "Beta: [array([ 5.6771791e-01,  7.1920687e-01, -3.4394294e-01,  3.6333501e-01,\n",
      "        8.4403157e-04,  7.7554512e-01, -3.3563685e-01,  8.6176562e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 25/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1979.4966\n",
      "Beta: [array([ 0.5643126 ,  0.72114533, -0.33732826,  0.35749322, -0.        ,\n",
      "        0.78348345, -0.32912663,  0.85606027], dtype=float32)]\n",
      "Epoch 26/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1978.7992\n",
      "Beta: [array([ 0.5616995 ,  0.72351146, -0.33712322,  0.35715172,  0.00120425,\n",
      "        0.7912598 , -0.3289617 ,  0.85586625], dtype=float32)]\n",
      "Epoch 27/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1967.2058\n",
      "Beta: [array([ 5.5572248e-01,  7.2841114e-01, -3.3210158e-01,  3.5224923e-01,\n",
      "        2.4292123e-04,  7.9899859e-01, -3.2383865e-01,  8.5086334e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 28/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1961.1780\n",
      "Beta: [array([ 5.5644357e-01,  7.2684789e-01, -3.2939547e-01,  3.4944972e-01,\n",
      "        5.2812550e-04,  8.0406904e-01, -3.2145482e-01,  8.4834576e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 29/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1950.4336\n",
      "Beta: [array([ 0.5591194 ,  0.72382253, -0.32701787,  0.3469582 , -0.        ,\n",
      "        0.8069319 , -0.31927064,  0.84597456], dtype=float32)]\n",
      "Epoch 30/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1953.3376\n",
      "Beta: [array([ 0.55289435,  0.7298584 , -0.32729122,  0.34734428,  0.00092066,\n",
      "        0.81810904, -0.31960928,  0.8464775 ], dtype=float32)]\n",
      "Epoch 31/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1946.8634\n",
      "Beta: [array([ 0.5525369 ,  0.72986734, -0.3234095 ,  0.34252724,  0.00136951,\n",
      "        0.8232363 , -0.316142  ,  0.84192675], dtype=float32)]\n",
      "Epoch 32/1000\n",
      "40/40 [==============================] - 70s 2s/step - loss: 1939.1228\n",
      "Beta: [array([ 0.5524759 ,  0.7294568 , -0.32265988,  0.34173182, -0.        ,\n",
      "        0.8275383 , -0.3155965 ,  0.8412702 ], dtype=float32)]\n",
      "Epoch 33/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1935.9467\n",
      "Beta: [array([ 0.5524544 ,  0.72943056, -0.32181963,  0.34043968, -0.        ,\n",
      "        0.8321974 , -0.31477198,  0.8398952 ], dtype=float32)]\n",
      "Epoch 34/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1926.1595\n",
      "Beta: [array([ 0.55226105,  0.7291223 , -0.31833687,  0.33620214,  0.0014181 ,\n",
      "        0.83734596, -0.3116926 ,  0.83584666], dtype=float32)]\n",
      "Epoch 35/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1917.8876\n",
      "Beta: [array([ 0.5528808 ,  0.7283078 , -0.31657976,  0.3342591 , -0.        ,\n",
      "        0.84227794, -0.31035298,  0.8341163 ], dtype=float32)]\n",
      "Epoch 36/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1918.1586\n",
      "Beta: [array([ 0.5526984 ,  0.72872734, -0.31611773,  0.33310345, -0.        ,\n",
      "        0.8454097 , -0.30991507,  0.8328967 ], dtype=float32)]\n",
      "Epoch 37/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1911.9406\n",
      "Beta: [array([ 5.5356359e-01,  7.2744441e-01, -3.1395563e-01,  3.3075389e-01,\n",
      "        4.5767963e-05,  8.5229033e-01, -3.0858520e-01,  8.3105034e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 38/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1908.0044\n",
      "Beta: [array([ 0.5563849 ,  0.72445196, -0.31318802,  0.3301227 , -0.        ,\n",
      "        0.85403454, -0.30811885,  0.8305692 ], dtype=float32)]\n",
      "Epoch 39/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1904.6786\n",
      "Beta: [array([ 5.5351937e-01,  7.2720236e-01, -3.1101856e-01,  3.2711965e-01,\n",
      "        5.2482635e-04,  8.6139494e-01, -3.0642822e-01,  8.2784748e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 40/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1898.0236\n",
      "Beta: [array([ 5.5607384e-01,  7.2436166e-01, -3.0950031e-01,  3.2553235e-01,\n",
      "        2.8075334e-05,  8.6493349e-01, -3.0549195e-01,  8.2643312e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 41/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1892.3286\n",
      "Beta: [array([ 0.557203  ,  0.7231236 , -0.30804363,  0.3238776 , -0.        ,\n",
      "        0.86836857, -0.30439705,  0.82492477], dtype=float32)]\n",
      "Epoch 42/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1887.5388\n",
      "Beta: [array([ 5.5803508e-01,  7.2207737e-01, -3.0671591e-01,  3.2234877e-01,\n",
      "        4.3161916e-05,  8.7286860e-01, -3.0381206e-01,  8.2373327e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 43/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1886.7607\n",
      "Beta: [array([ 5.5944371e-01,  7.2054487e-01, -3.0535984e-01,  3.2100219e-01,\n",
      "        2.0987313e-04,  8.7684089e-01, -3.0309618e-01,  8.2270938e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 44/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1884.0912\n",
      "Beta: [array([ 5.5878276e-01,  7.2117400e-01, -3.0449301e-01,  3.1985399e-01,\n",
      "        8.4976421e-04,  8.8126290e-01, -3.0253130e-01,  8.2159323e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 45/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1882.9832\n",
      "Beta: [array([ 0.5575691 ,  0.7222545 , -0.30385706,  0.31888092,  0.00096768,\n",
      "        0.887071  , -0.30239305,  0.8208103 ], dtype=float32)]\n",
      "Epoch 46/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1874.0038\n",
      "Beta: [array([ 0.5642329 ,  0.715582  , -0.3012347 ,  0.31596807,  0.00238656,\n",
      "        0.88655293, -0.30101943,  0.81858927], dtype=float32)]\n",
      "Epoch 47/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1864.9220\n",
      "Beta: [array([ 0.56433153,  0.7151786 , -0.29955345,  0.31485903, -0.        ,\n",
      "        0.89235204, -0.30017325,  0.81782335], dtype=float32)]\n",
      "Epoch 48/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1869.0618\n",
      "Beta: [array([ 5.6571865e-01,  7.1368992e-01, -2.9933462e-01,  3.1482768e-01,\n",
      "        5.1850150e-04,  8.9549571e-01, -3.0047923e-01,  8.1796390e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 49/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1868.1304\n",
      "Beta: [array([ 5.6396627e-01,  7.1547008e-01, -2.9874232e-01,  3.1372249e-01,\n",
      "        2.0994198e-04,  9.0108198e-01, -3.0032283e-01,  8.1693858e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 50/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1866.7048\n",
      "Beta: [array([ 5.6232226e-01,  7.1689820e-01, -2.9884881e-01,  3.1414738e-01,\n",
      "        3.3291904e-04,  9.0663588e-01, -3.0079347e-01,  8.1751466e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 51/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1858.7842\n",
      "Beta: [array([ 5.6684017e-01,  7.1233380e-01, -2.9550073e-01,  3.1024393e-01,\n",
      "        5.0231232e-04,  9.0827501e-01, -2.9875439e-01,  8.1421173e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 52/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1853.3608\n",
      "Beta: [array([ 0.5701678 ,  0.708766  , -0.29326135,  0.30886814, -0.        ,\n",
      "        0.9110933 , -0.29792836,  0.81349766], dtype=float32)]\n",
      "Epoch 53/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1853.3738\n",
      "Beta: [array([ 0.57098   ,  0.707898  , -0.29298943,  0.30916402, -0.        ,\n",
      "        0.9154381 , -0.29851228,  0.8141156 ], dtype=float32)]\n",
      "Epoch 54/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1849.9120\n",
      "Beta: [array([ 0.56966007,  0.7091576 , -0.2916562 ,  0.30712846,  0.00121289,\n",
      "        0.9203946 , -0.29759386,  0.8121743 ], dtype=float32)]\n",
      "Epoch 55/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1847.1622\n",
      "Beta: [array([ 5.7352734e-01,  7.0513427e-01, -2.8900614e-01,  3.0558702e-01,\n",
      "        4.8769540e-05,  9.2259789e-01, -2.9672557e-01,  8.1154281e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 56/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1839.8386\n",
      "Beta: [array([ 0.57517385,  0.70345134, -0.2877653 ,  0.30432335, -0.        ,\n",
      "        0.9256138 , -0.29633912,  0.81055695], dtype=float32)]\n",
      "Epoch 57/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1841.7122\n",
      "Beta: [array([ 0.57578796,  0.7025494 , -0.28639978,  0.30330926, -0.        ,\n",
      "        0.9282325 , -0.29571038,  0.809891  ], dtype=float32)]\n",
      "Epoch 58/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1836.0648\n",
      "Beta: [array([ 0.5788973 ,  0.6997251 , -0.2854242 ,  0.30230072,  0.0010368 ,\n",
      "        0.9302161 , -0.29585204,  0.80919605], dtype=float32)]\n",
      "Epoch 59/1000\n",
      "40/40 [==============================] - 70s 2s/step - loss: 1835.9786\n",
      "Beta: [array([ 5.7486331e-01,  7.0351887e-01, -2.8545278e-01,  3.0255741e-01,\n",
      "        3.9355250e-04,  9.3868172e-01, -2.9645193e-01,  8.0961072e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 60/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1831.4468\n",
      "Beta: [array([ 0.5793152 ,  0.6988586 , -0.2820228 ,  0.30053684, -0.        ,\n",
      "        0.94063246, -0.29511672,  0.8086169 ], dtype=float32)]\n",
      "Epoch 61/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1835.3782\n",
      "Beta: [array([ 0.5800471 ,  0.69815725, -0.2818167 ,  0.30060622, -0.        ,\n",
      "        0.94363886, -0.29569325,  0.8089039 ], dtype=float32)]\n",
      "Epoch 62/1000\n",
      "40/40 [==============================] - 70s 2s/step - loss: 1828.9242\n",
      "Beta: [array([ 0.5822542 ,  0.69578445, -0.27930552,  0.29901075, -0.        ,\n",
      "        0.9467445 , -0.29473355,  0.8079536 ], dtype=float32)]\n",
      "Epoch 63/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1830.9098\n",
      "Beta: [array([ 0.58205587,  0.6958514 , -0.27822033,  0.29872113, -0.        ,\n",
      "        0.95203316, -0.29491282,  0.8081617 ], dtype=float32)]\n",
      "Epoch 64/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1826.2994\n",
      "Beta: [array([ 5.8366460e-01,  6.9422978e-01, -2.7678046e-01,  2.9736286e-01,\n",
      "        1.2786055e-05,  9.5401496e-01, -2.9451412e-01,  8.0714971e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 65/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1824.7148\n",
      "Beta: [array([ 0.5847993 ,  0.6929824 , -0.27506596,  0.29669756, -0.        ,\n",
      "        0.9585103 , -0.2944974 ,  0.8071742 ], dtype=float32)]\n",
      "Epoch 66/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1821.5413\n",
      "Beta: [array([ 0.5855508 ,  0.69213754, -0.27334994,  0.29598665, -0.        ,\n",
      "        0.9628582 , -0.29438597,  0.8071103 ], dtype=float32)]\n",
      "Epoch 67/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1822.7030\n",
      "Beta: [array([ 5.8804941e-01,  6.8963218e-01, -2.7160767e-01,  2.9501656e-01,\n",
      "        1.9194451e-04,  9.6441680e-01, -2.9403812e-01,  8.0663580e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 68/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1818.0164\n",
      "Beta: [array([ 0.58824164,  0.6892965 , -0.2697477 ,  0.29426822, -0.        ,\n",
      "        0.9690845 , -0.29369858,  0.80648714], dtype=float32)]\n",
      "Epoch 69/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1825.6534\n",
      "Beta: [array([ 0.5865177 ,  0.69080985, -0.2695436 ,  0.2944    ,  0.00108092,\n",
      "        0.97487104, -0.29441357,  0.80694526], dtype=float32)]\n",
      "Epoch 70/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1821.5378\n",
      "Beta: [array([ 0.5872398 ,  0.69020605, -0.2688309 ,  0.29352474, -0.        ,\n",
      "        0.9774658 , -0.294681  ,  0.80632174], dtype=float32)]\n",
      "Epoch 71/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1821.0374\n",
      "Beta: [array([ 5.8909863e-01,  6.8816972e-01, -2.6593593e-01,  2.9267073e-01,\n",
      "        9.4814890e-04,  9.8205316e-01, -2.9433593e-01,  8.0657423e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 72/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1819.7852\n",
      "Beta: [array([ 5.8879316e-01,  6.8847483e-01, -2.6620519e-01,  2.9303613e-01,\n",
      "        1.2716135e-05,  9.8505974e-01, -2.9530311e-01,  8.0714148e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 73/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1816.1326\n",
      "Beta: [array([ 0.5928057 ,  0.6842793 , -0.26144543,  0.29082906, -0.        ,\n",
      "        0.9879587 , -0.29357952,  0.80620205], dtype=float32)]\n",
      "Epoch 74/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1810.1823\n",
      "Beta: [array([ 0.59421915,  0.6828054 , -0.25948775,  0.28984156, -0.        ,\n",
      "        0.9907948 , -0.29339743,  0.8058696 ], dtype=float32)]\n",
      "Epoch 75/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1814.4600\n",
      "Beta: [array([ 0.59519464,  0.68178064, -0.25764564,  0.28942367, -0.        ,\n",
      "        0.99473304, -0.29358518,  0.806177  ], dtype=float32)]\n",
      "Epoch 76/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1812.8348\n",
      "Beta: [array([ 0.5956027 ,  0.6811485 , -0.25636825,  0.2891663 , -0.        ,\n",
      "        0.99807155, -0.29369026,  0.8063668 ], dtype=float32)]\n",
      "Epoch 77/1000\n",
      "40/40 [==============================] - 70s 2s/step - loss: 1807.9614\n",
      "Beta: [array([ 0.5973506 ,  0.67934203, -0.25340512,  0.28761548, -0.        ,\n",
      "        1.0004582 , -0.29276958,  0.8056822 ], dtype=float32)]\n",
      "Epoch 78/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1806.4427\n",
      "Beta: [array([ 0.5988896 ,  0.6778933 , -0.2518765 ,  0.2873506 , -0.        ,\n",
      "        1.004052  , -0.29337248,  0.8061031 ], dtype=float32)]\n",
      "Epoch 79/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1815.8522\n",
      "Beta: [array([ 0.59522545,  0.68151754, -0.2547495 ,  0.28968588, -0.        ,\n",
      "        1.0105835 , -0.2967519 ,  0.80848855], dtype=float32)]\n",
      "Epoch 80/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1817.7488\n",
      "Beta: [array([ 0.59600955,  0.68055177, -0.25026286,  0.2871056 ,  0.00129207,\n",
      "        1.0155784 , -0.29509324,  0.8071487 ], dtype=float32)]\n",
      "Epoch 81/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1812.2396\n",
      "Beta: [array([ 6.0013902e-01,  6.7622596e-01, -2.4626784e-01,  2.8608146e-01,\n",
      "        5.2293047e-04,  1.0163685e+00, -2.9383498e-01,  8.0707914e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 82/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1809.3123\n",
      "Beta: [array([ 0.6026473 ,  0.6737502 , -0.24443096,  0.28489378,  0.00135516,\n",
      "        1.0161315 , -0.29315677,  0.80622196], dtype=float32)]\n",
      "Epoch 83/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1808.0658\n",
      "Beta: [array([ 0.6026691 ,  0.6736199 , -0.24220915,  0.28530234, -0.        ,\n",
      "        1.022836  , -0.29450095,  0.8079625 ], dtype=float32)]\n",
      "Epoch 84/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1811.2325\n",
      "Beta: [array([ 6.0216784e-01,  6.7407346e-01, -2.4107267e-01,  2.8479654e-01,\n",
      "        5.1757826e-05,  1.0277890e+00, -2.9510784e-01,  8.0807483e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 85/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1808.9904\n",
      "Beta: [array([ 0.60443544,  0.6717377 , -0.23794842,  0.28381994, -0.        ,\n",
      "        1.0300579 , -0.29468915,  0.808104  ], dtype=float32)]\n",
      "Epoch 86/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1809.5768\n",
      "Beta: [array([ 6.0462373e-01,  6.7149490e-01, -2.3595448e-01,  2.8334373e-01,\n",
      "        4.2576788e-04,  1.0345945e+00, -2.9496089e-01,  8.0841058e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 87/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1802.7756\n",
      "Beta: [array([ 0.6068567 ,  0.6692442 , -0.23336993,  0.28247744, -0.        ,\n",
      "        1.0368418 , -0.29512504,  0.8085112 ], dtype=float32)]\n",
      "Epoch 88/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1813.2134\n",
      "Beta: [array([ 0.60503656,  0.670893  , -0.23255372,  0.28298375,  0.00212161,\n",
      "        1.0428892 , -0.29641545,  0.8097763 ], dtype=float32)]\n",
      "Epoch 89/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1806.6484\n",
      "Beta: [array([ 6.0772020e-01,  6.6813135e-01, -2.2865877e-01,  2.8168502e-01,\n",
      "        2.8309377e-04,  1.0450532e+00, -2.9558697e-01,  8.0961609e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 90/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1809.5662\n",
      "Beta: [array([ 6.0834551e-01,  6.6740716e-01, -2.2696725e-01,  2.8201228e-01,\n",
      "        3.6344054e-04,  1.0487875e+00, -2.9639399e-01,  8.1080610e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 91/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1808.5201\n",
      "Beta: [array([ 6.0969770e-01,  6.6611826e-01, -2.2597057e-01,  2.8108430e-01,\n",
      "        4.6709852e-04,  1.0498575e+00, -2.9670453e-01,  8.1018287e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 92/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1809.6234\n",
      "Beta: [array([ 0.60953623,  0.6661536 , -0.22347556,  0.28070644,  0.00157623,\n",
      "        1.055647  , -0.29731804,  0.81090695], dtype=float32)]\n",
      "Epoch 93/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1813.4058\n",
      "Beta: [array([ 0.6098782 ,  0.66567314, -0.22098832,  0.28040287,  0.0022621 ,\n",
      "        1.0601075 , -0.2976742 ,  0.81160283], dtype=float32)]\n",
      "Epoch 94/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1803.1407\n",
      "Beta: [array([ 0.61281335,  0.66268516, -0.21666089,  0.27881536,  0.00107192,\n",
      "        1.0616767 , -0.29649094,  0.8112715 ], dtype=float32)]\n",
      "Epoch 95/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1796.1008\n",
      "Beta: [array([ 0.61512107,  0.66043085, -0.21344611,  0.27753997, -0.        ,\n",
      "        1.0633228 , -0.29626042,  0.8110192 ], dtype=float32)]\n",
      "Epoch 96/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1810.5664\n",
      "Beta: [array([ 6.0920775e-01,  6.6612595e-01, -2.1752156e-01,  2.8072330e-01,\n",
      "        3.1903619e-04,  1.0728650e+00, -3.0167010e-01,  8.1446314e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 97/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1811.5078\n",
      "Beta: [array([ 0.6150188 ,  0.66027045, -0.21002373,  0.27806172,  0.00217781,\n",
      "        1.0724713 , -0.29851192,  0.8136084 ], dtype=float32)]\n",
      "Epoch 98/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1808.6500\n",
      "Beta: [array([ 0.6150516 ,  0.6600958 , -0.20731428,  0.2773115 ,  0.00224651,\n",
      "        1.0769694 , -0.29866287,  0.8138354 ], dtype=float32)]\n",
      "Epoch 99/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1804.4888\n",
      "Beta: [array([ 0.61750424,  0.65762514, -0.20455249,  0.27729627,  0.0012443 ,\n",
      "        1.0783967 , -0.29896817,  0.8148587 ], dtype=float32)]\n",
      "Epoch 100/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1813.6232\n",
      "Beta: [array([ 0.6145101 ,  0.6604775 , -0.2052181 ,  0.2778369 ,  0.00141476,\n",
      "        1.0853437 , -0.30153412,  0.81596565], dtype=float32)]\n",
      "Epoch 101/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1797.8105\n",
      "Beta: [array([ 0.61893076,  0.6560242 , -0.1976147 ,  0.2745108 ,  0.00153866,\n",
      "        1.0856087 , -0.29796916,  0.81441116], dtype=float32)]\n",
      "Epoch 102/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1807.7325\n",
      "Beta: [array([ 6.1766809e-01,  6.5708119e-01, -1.9832650e-01,  2.7604085e-01,\n",
      "        1.7482671e-05,  1.0904959e+00, -3.0074909e-01,  8.1652182e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 103/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1805.5106\n",
      "Beta: [array([ 6.2168610e-01,  6.5319955e-01, -1.9433254e-01,  2.7526662e-01,\n",
      "        5.5703422e-04,  1.0907555e+00, -3.0054697e-01,  8.1715751e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 104/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1804.7845\n",
      "Beta: [array([ 0.6203304 ,  0.6543437 , -0.19163874,  0.2746356 , -0.        ,\n",
      "        1.0968709 , -0.30089146,  0.81764287], dtype=float32)]\n",
      "Epoch 105/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1803.5616\n",
      "Beta: [array([ 0.62107664,  0.65355873, -0.18700325,  0.27292028, -0.        ,\n",
      "        1.1002496 , -0.2995589 ,  0.8173505 ], dtype=float32)]\n",
      "Epoch 106/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1809.1884\n",
      "Beta: [array([ 6.2115985e-01,  6.5328366e-01, -1.8521005e-01,  2.7397230e-01,\n",
      "        4.6563084e-04,  1.1047494e+00, -3.0126932e-01,  8.1971294e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 107/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1809.8528\n",
      "Beta: [array([ 0.6224709 ,  0.65197575, -0.1837978 ,  0.27371433, -0.        ,\n",
      "        1.1070421 , -0.30245805,  0.8201645 ], dtype=float32)]\n",
      "Epoch 108/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1812.5046\n",
      "Beta: [array([ 6.2012219e-01,  6.5424120e-01, -1.8408601e-01,  2.7493048e-01,\n",
      "        7.9255487e-04,  1.1133488e+00, -3.0556574e-01,  8.2242358e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 109/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1805.4882\n",
      "Beta: [array([ 0.625411  ,  0.6489613 , -0.17688216,  0.2716986 ,  0.00188569,\n",
      "        1.1127464 , -0.30231896,  0.82077914], dtype=float32)]\n",
      "Epoch 110/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1810.8412\n",
      "Beta: [array([ 0.6230734 ,  0.65125525, -0.17915684,  0.2735676 , -0.        ,\n",
      "        1.1177102 , -0.30631658,  0.8230486 ], dtype=float32)]\n",
      "Epoch 111/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1812.2582\n",
      "Beta: [array([ 0.6250155 ,  0.6489981 , -0.17211589,  0.27187166,  0.00143463,\n",
      "        1.1214329 , -0.3037208 ,  0.8231942 ], dtype=float32)]\n",
      "Epoch 112/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1809.9626\n",
      "Beta: [array([ 6.2615442e-01,  6.4797753e-01, -1.6967793e-01,  2.7148917e-01,\n",
      "        3.0568300e-04,  1.1249117e+00, -3.0521420e-01,  8.2435471e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 113/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1813.8647\n",
      "Beta: [array([ 6.2620449e-01,  6.4783484e-01, -1.6805905e-01,  2.7172601e-01,\n",
      "        3.3579927e-04,  1.1288979e+00, -3.0671138e-01,  8.2569915e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 114/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1814.6130\n",
      "Beta: [array([ 0.62585264,  0.64799565, -0.16557029,  0.2720602 ,  0.00117318,\n",
      "        1.133004  , -0.30729625,  0.82729584], dtype=float32)]\n",
      "Epoch 115/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1808.6826\n",
      "Beta: [array([ 0.62878186,  0.6451038 , -0.16040722,  0.26927298,  0.00131311,\n",
      "        1.1333269 , -0.30455995,  0.8255555 ], dtype=float32)]\n",
      "Epoch 116/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1821.4019\n",
      "Beta: [array([ 6.2501258e-01,  6.4875072e-01, -1.6377331e-01,  2.7275866e-01,\n",
      "        3.2340246e-04,  1.1417719e+00, -3.1206998e-01,  8.3003867e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 117/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1815.3710\n",
      "Beta: [array([ 6.3023865e-01,  6.4343238e-01, -1.5411146e-01,  2.6950470e-01,\n",
      "        1.8888760e-04,  1.1421958e+00, -3.0728126e-01,  8.2930428e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 118/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1809.2231\n",
      "Beta: [array([ 0.62962985,  0.6440456 , -0.15493159,  0.26906034, -0.        ,\n",
      "        1.144142  , -0.30870023,  0.82873887], dtype=float32)]\n",
      "Epoch 119/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1811.8656\n",
      "Beta: [array([ 6.3170069e-01,  6.4182317e-01, -1.4804462e-01,  2.6871359e-01,\n",
      "        1.6609270e-05,  1.1490269e+00, -3.0830669e-01,  8.3136916e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 120/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1811.6874\n",
      "Beta: [array([ 0.63230276,  0.6410622 , -0.14466903,  0.26766708, -0.        ,\n",
      "        1.1517932 , -0.30742726,  0.8312972 ], dtype=float32)]\n",
      "Epoch 121/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1811.3315\n",
      "Beta: [array([ 6.3408184e-01,  6.3932824e-01, -1.4054592e-01,  2.6685190e-01,\n",
      "        3.5970879e-04,  1.1541722e+00, -3.0726871e-01,  8.3234173e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 122/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1814.4116\n",
      "Beta: [array([ 0.6332696 ,  0.64007443, -0.14075592,  0.26734102, -0.        ,\n",
      "        1.1580192 , -0.30982447,  0.8335717 ], dtype=float32)]\n",
      "Epoch 123/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1819.8070\n",
      "Beta: [array([ 6.3170636e-01,  6.4155978e-01, -1.4176573e-01,  2.6897264e-01,\n",
      "        2.8232183e-05,  1.1632499e+00, -3.1412873e-01,  8.3608949e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 124/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1813.6617\n",
      "Beta: [array([ 0.63499844,  0.63807887, -0.13215931,  0.2657574 , -0.        ,\n",
      "        1.165797  , -0.3094154 ,  0.8355246 ], dtype=float32)]\n",
      "Epoch 125/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1811.3276\n",
      "Beta: [array([ 6.3639903e-01,  6.3660103e-01, -1.2988713e-01,  2.6518419e-01,\n",
      "        1.5339434e-04,  1.1670718e+00, -3.0929768e-01,  8.3578110e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 126/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1817.4496\n",
      "Beta: [array([ 0.63574475,  0.6371996 , -0.12623784,  0.26484302,  0.0015764 ,\n",
      "        1.1731703 , -0.31063646,  0.83780414], dtype=float32)]\n",
      "Epoch 127/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1807.5548\n",
      "Beta: [array([ 0.63760245,  0.63517976, -0.12108587,  0.2635633 , -0.        ,\n",
      "        1.1749663 , -0.3087996 ,  0.83806926], dtype=float32)]\n",
      "Epoch 128/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1812.7356\n",
      "Beta: [array([ 0.63783425,  0.6348883 , -0.11953799,  0.26432094, -0.        ,\n",
      "        1.1791544 , -0.31165034,  0.8404366 ], dtype=float32)]\n",
      "Epoch 129/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1812.2769\n",
      "Beta: [array([ 0.63873756,  0.6339755 , -0.11614769,  0.2633601 , -0.        ,\n",
      "        1.1822904 , -0.31198183,  0.8410903 ], dtype=float32)]\n",
      "Epoch 130/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1827.2458\n",
      "Beta: [array([ 6.36516571e-01,  6.36058211e-01, -1.19401164e-01,  2.67065823e-01,\n",
      "        9.64792096e-04,  1.18777668e+00, -3.18839937e-01,  8.45833242e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 131/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1819.4934\n",
      "Beta: [array([ 0.6414095 ,  0.631174  , -0.11099127,  0.26306358,  0.00197901,\n",
      "        1.1871595 , -0.31373218,  0.84377265], dtype=float32)]\n",
      "Epoch 132/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1823.2692\n",
      "Beta: [array([ 6.3998765e-01,  6.3244784e-01, -1.0955447e-01,  2.6473197e-01,\n",
      "        4.8417496e-05,  1.1934874e+00, -3.1711870e-01,  8.4759647e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 133/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1825.4562\n",
      "Beta: [array([ 6.4086163e-01,  6.3149893e-01, -1.0532753e-01,  2.6274663e-01,\n",
      "        4.2497314e-04,  1.1966715e+00, -3.1588453e-01,  8.4711742e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 134/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1819.4130\n",
      "Beta: [array([ 0.64239836,  0.62991995, -0.10285356,  0.2630696 , -0.        ,\n",
      "        1.1987678 , -0.31725943,  0.8490989 ], dtype=float32)]\n",
      "Epoch 135/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1824.6003\n",
      "Beta: [array([ 0.6420991 ,  0.6300902 , -0.0991573 ,  0.26187268, -0.        ,\n",
      "        1.2034794 , -0.3169443 ,  0.84963477], dtype=float32)]\n",
      "Epoch 136/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1818.6400\n",
      "Beta: [array([ 0.6427617 ,  0.6293736 , -0.0955462 ,  0.26061133, -0.        ,\n",
      "        1.2068238 , -0.31672463,  0.8499528 ], dtype=float32)]\n",
      "Epoch 137/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1816.0242\n",
      "Beta: [array([ 0.6463445 ,  0.6257708 , -0.09093679,  0.2589329 ,  0.00124953,\n",
      "        1.2058517 , -0.31434548,  0.8495629 ], dtype=float32)]\n",
      "Epoch 138/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1819.3809\n",
      "Beta: [array([ 6.4598465e-01,  6.2606734e-01, -8.8599235e-02,  2.5904584e-01,\n",
      "        4.1186242e-04,  1.2103418e+00, -3.1594619e-01,  8.5156345e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 139/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1822.4108\n",
      "Beta: [array([ 0.6446732 ,  0.62712836, -0.08572719,  0.25905344, -0.        ,\n",
      "        1.216783  , -0.31768772,  0.8537117 ], dtype=float32)]\n",
      "Epoch 140/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1828.1582\n",
      "Beta: [array([ 6.4224684e-01,  6.2947947e-01, -8.7598987e-02,  2.6075900e-01,\n",
      "        3.6748903e-04,  1.2213974e+00, -3.2169592e-01,  8.5606760e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 141/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1817.7841\n",
      "Beta: [array([ 6.4729464e-01,  6.2436563e-01, -7.9437315e-02,  2.5726965e-01,\n",
      "        6.3834136e-04,  1.2214800e+00, -3.1799868e-01,  8.5506546e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 142/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1814.5328\n",
      "Beta: [array([ 0.6481563 ,  0.6234528 , -0.07590879,  0.2566602 , -0.        ,\n",
      "        1.2248337 , -0.31854406,  0.8566297 ], dtype=float32)]\n",
      "Epoch 143/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1821.0972\n",
      "Beta: [array([ 0.6473727 ,  0.6240862 , -0.07215008,  0.25629514, -0.        ,\n",
      "        1.2300155 , -0.3188541 ,  0.85843444], dtype=float32)]\n",
      "Epoch 144/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1825.7365\n",
      "Beta: [array([ 0.6459564 ,  0.6255132 , -0.07653602,  0.25858402, -0.        ,\n",
      "        1.2330931 , -0.3247255 ,  0.8608131 ], dtype=float32)]\n",
      "Epoch 145/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1829.2657\n",
      "Beta: [array([ 6.4862537e-01,  6.2265629e-01, -6.8762064e-02,  2.5693116e-01,\n",
      "        1.0216055e-04,  1.2364442e+00, -3.2263926e-01,  8.6244911e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 146/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1818.6030\n",
      "Beta: [array([ 6.5187705e-01,  6.1937362e-01, -6.3947134e-02,  2.5463831e-01,\n",
      "        7.0661801e-04,  1.2361207e+00, -3.2025340e-01,  8.6153847e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 147/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1827.9301\n",
      "Beta: [array([ 0.6501602 ,  0.62088406, -0.06284028,  0.255793  , -0.        ,\n",
      "        1.2423416 , -0.32363626,  0.86478865], dtype=float32)]\n",
      "Epoch 148/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1816.9406\n",
      "Beta: [array([ 0.65195465,  0.6190582 , -0.05680786,  0.25288135, -0.        ,\n",
      "        1.2441387 , -0.320548  ,  0.8638918 ], dtype=float32)]\n",
      "Epoch 149/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1826.3998\n",
      "Beta: [array([ 6.5178430e-01,  6.1920398e-01, -5.6753773e-02,  2.5378010e-01,\n",
      "        4.5332965e-04,  1.2474840e+00, -3.2377595e-01,  8.6620426e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 150/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1832.9490\n",
      "Beta: [array([ 6.5159577e-01,  6.1917400e-01, -5.3945307e-02,  2.5405067e-01,\n",
      "        8.5551437e-04,  1.2522832e+00, -3.2538238e-01,  8.6882794e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 151/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1837.3114\n",
      "Beta: [array([ 6.5072626e-01,  6.1988658e-01, -5.5533066e-02,  2.5552836e-01,\n",
      "        8.7135303e-04,  1.2554926e+00, -3.2928768e-01,  8.7082863e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 152/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1822.2114\n",
      "Beta: [array([ 0.6557737 ,  0.6148305 , -0.04762463,  0.2514878 ,  0.00212454,\n",
      "        1.2546151 , -0.3245507 ,  0.86923903], dtype=float32)]\n",
      "Epoch 153/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1834.5964\n",
      "Beta: [array([ 0.6531309 ,  0.617386  , -0.04710151,  0.25292858,  0.00129095,\n",
      "        1.2620085 , -0.32867268,  0.87316686], dtype=float32)]\n",
      "Epoch 154/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1840.6689\n",
      "Beta: [array([ 0.6526183 ,  0.61780965, -0.04731138,  0.25393686,  0.00126841,\n",
      "        1.2656312 , -0.33177516,  0.8755214 ], dtype=float32)]\n",
      "Epoch 155/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1837.3344\n",
      "Beta: [array([ 6.5559489e-01,  6.1469507e-01, -4.1775357e-02,  2.5257981e-01,\n",
      "        2.5443648e-04,  1.2667357e+00, -3.3002013e-01,  8.7654430e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 156/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1837.0972\n",
      "Beta: [array([ 6.5622699e-01,  6.1399317e-01, -3.8201321e-02,  2.5186738e-01,\n",
      "        1.9438207e-04,  1.2702790e+00, -3.3017772e-01,  8.7817931e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 157/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1839.1801\n",
      "Beta: [array([ 6.5413868e-01,  6.1597162e-01, -3.9658733e-02,  2.5239536e-01,\n",
      "        6.8257243e-04,  1.2746983e+00, -3.3343771e-01,  8.7924320e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 158/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1827.7126\n",
      "Beta: [array([ 6.5833515e-01,  6.1169529e-01, -3.2102887e-02,  2.5034663e-01,\n",
      "        1.7871178e-05,  1.2756083e+00, -3.3088282e-01,  8.8075823e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 159/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1833.6018\n",
      "Beta: [array([ 6.5805048e-01,  6.1177874e-01, -2.8773254e-02,  2.4832794e-01,\n",
      "        3.9944414e-04,  1.2790070e+00, -3.2981321e-01,  8.7974542e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 160/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1836.3405\n",
      "Beta: [array([ 6.5922683e-01,  6.1057872e-01, -2.7396776e-02,  2.4858575e-01,\n",
      "        6.7049358e-04,  1.2816318e+00, -3.3198917e-01,  8.8221097e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 161/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1832.0428\n",
      "Beta: [array([ 6.5980607e-01,  6.0985470e-01, -2.3833090e-02,  2.4777336e-01,\n",
      "        1.9801756e-04,  1.2851034e+00, -3.3231196e-01,  8.8366556e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 162/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1823.2922\n",
      "Beta: [array([ 6.6261554e-01,  6.0700047e-01, -1.9068163e-02,  2.4554735e-01,\n",
      "        3.7114363e-04,  1.2851684e+00, -3.2992941e-01,  8.8316137e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 163/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1833.4318\n",
      "Beta: [array([ 0.6609295 ,  0.6085244 , -0.01693444,  0.24610518, -0.        ,\n",
      "        1.2911934 , -0.33208048,  0.8862609 ], dtype=float32)]\n",
      "Epoch 164/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1840.3499\n",
      "Beta: [array([ 6.5773314e-01,  6.1160785e-01, -2.1447457e-02,  2.4928504e-01,\n",
      "        2.3992863e-04,  1.2963732e+00, -3.3884165e-01,  8.9001167e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 165/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1839.2306\n",
      "Beta: [array([ 0.6640729 ,  0.6052585 , -0.01333755,  0.24450368,  0.00336382,\n",
      "        1.2935481 , -0.33340958,  0.8872713 ], dtype=float32)]\n",
      "Epoch 166/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1837.3610\n",
      "Beta: [array([ 0.6626691 ,  0.60647714, -0.01098014,  0.245652  , -0.        ,\n",
      "        1.300068  , -0.3361656 ,  0.8915323 ], dtype=float32)]\n",
      "Epoch 167/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1831.9982\n",
      "Beta: [array([ 6.6545773e-01,  6.0365283e-01, -5.6972792e-03,  2.4267468e-01,\n",
      "        4.2379866e-04,  1.3000443e+00, -3.3309141e-01,  8.9024341e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 168/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1826.4030\n",
      "Beta: [array([ 0.66569114,  0.6032769 , -0.00354855,  0.24261773, -0.        ,\n",
      "        1.3037015 , -0.33496904,  0.8924174 ], dtype=float32)]\n",
      "Epoch 169/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1824.4333\n",
      "Beta: [array([ 0.6659687 ,  0.60282534, -0.00220642,  0.24234061, -0.        ,\n",
      "        1.3068514 , -0.33554235,  0.8941484 ], dtype=float32)]\n",
      "Epoch 170/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1829.9078\n",
      "Beta: [array([ 0.66556376,  0.6031531 , -0.0017692 ,  0.24197745, -0.        ,\n",
      "        1.3114531 , -0.3359677 ,  0.8966969 ], dtype=float32)]\n",
      "Epoch 171/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1843.3564\n",
      "Beta: [array([ 0.6655452 ,  0.6030501 , -0.00256742,  0.24395375, -0.        ,\n",
      "        1.314621  , -0.34032542,  0.90046114], dtype=float32)]\n",
      "Epoch 172/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1856.7236\n",
      "Beta: [array([ 6.6309237e-01,  6.0535038e-01, -3.2985024e-03,  2.4468790e-01,\n",
      "        1.2505529e-03,  1.3200737e+00, -3.4368339e-01,  9.0254903e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 173/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1843.2954\n",
      "Beta: [array([ 6.6659647e-01,  6.0172033e-01, -1.1132946e-03,  2.4107671e-01,\n",
      "        5.3182396e-04,  1.3208617e+00, -3.3994129e-01,  9.0165722e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 174/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1841.3912\n",
      "Beta: [array([ 6.67431414e-01,  6.00767434e-01, -1.43608995e-05,  2.40440384e-01,\n",
      "       -0.00000000e+00,  1.32332802e+00, -3.40662509e-01,  9.02954519e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 175/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1844.1816\n",
      "Beta: [array([ 6.6780126e-01,  6.0031080e-01, -1.2861964e-03,  2.3970370e-01,\n",
      "        3.5026871e-05,  1.3265402e+00, -3.4071115e-01,  9.0448660e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 176/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1845.6234\n",
      "Beta: [array([ 6.6853547e-01,  5.9944117e-01, -8.6822937e-04,  2.4038438e-01,\n",
      "       -0.0000000e+00,  1.3291669e+00, -3.4202555e-01,  9.0756410e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 177/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1846.3854\n",
      "Beta: [array([ 0.669704  ,  0.5982217 ,  0.        ,  0.23870704, -0.        ,\n",
      "        1.3306178 , -0.34207466,  0.90709275], dtype=float32)]\n",
      "Epoch 178/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1848.3173\n",
      "Beta: [array([ 6.7006844e-01,  5.9762949e-01, -7.5954471e-05,  2.3775925e-01,\n",
      "       -0.0000000e+00,  1.3341596e+00, -3.4185824e-01,  9.0842766e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 179/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1850.2654\n",
      "Beta: [array([ 6.7067486e-01,  5.9700233e-01, -9.4254757e-04,  2.3842575e-01,\n",
      "       -0.0000000e+00,  1.3374885e+00, -3.4326947e-01,  9.1209298e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 180/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1852.5880\n",
      "Beta: [array([ 6.7012709e-01,  5.9744650e-01, -1.5686973e-04,  2.3688795e-01,\n",
      "        7.7387172e-04,  1.3413085e+00, -3.4262720e-01,  9.1247159e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 181/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1848.5336\n",
      "Beta: [array([ 6.7257911e-01,  5.9483886e-01, -2.6703181e-04,  2.3534895e-01,\n",
      "        1.5224577e-03,  1.3419952e+00, -3.4263057e-01,  9.1252649e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 182/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1846.9388\n",
      "Beta: [array([ 0.6724392 ,  0.59484774,  0.        ,  0.2353534 , -0.        ,\n",
      "        1.3454189 , -0.343374  ,  0.9146985 ], dtype=float32)]\n",
      "Epoch 183/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1849.5114\n",
      "Beta: [array([ 6.7312491e-01,  5.9405982e-01, -5.1829952e-04,  2.3392658e-01,\n",
      "        7.3331170e-04,  1.3485847e+00, -3.4259054e-01,  9.1592622e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 184/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1853.5808\n",
      "Beta: [array([ 6.7237872e-01,  5.9460372e-01, -1.8614841e-03,  2.3548497e-01,\n",
      "        1.1306454e-03,  1.3514402e+00, -3.4589306e-01,  9.1820878e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 185/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1857.6870\n",
      "Beta: [array([ 6.7334259e-01,  5.9355909e-01,  0.0000000e+00,  2.3449147e-01,\n",
      "        1.0878465e-03,  1.3541913e+00, -3.4553662e-01,  9.2014462e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 186/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1848.1754\n",
      "Beta: [array([ 0.6755503 ,  0.59123015, -0.00168273,  0.23247263, -0.        ,\n",
      "        1.3559183 , -0.3444797 ,  0.9206236 ], dtype=float32)]\n",
      "Epoch 187/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1859.6876\n",
      "Beta: [array([ 6.7381728e-01,  5.9286398e-01, -2.5567766e-03,  2.3373559e-01,\n",
      "        1.1391639e-03,  1.3603039e+00, -3.4759480e-01,  9.2324650e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 188/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1859.5846\n",
      "Beta: [array([ 6.7301708e-01,  5.9350282e-01, -1.5111999e-03,  2.3412827e-01,\n",
      "        7.8563089e-04,  1.3639208e+00, -3.4852344e-01,  9.2525327e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 189/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1854.9950\n",
      "Beta: [array([ 6.7715281e-01,  5.8929181e-01,  0.0000000e+00,  2.3044120e-01,\n",
      "        1.3631070e-03,  1.3635997e+00, -3.4552687e-01,  9.2446220e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 190/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1849.0758\n",
      "Beta: [array([ 6.7868876e-01,  5.8762121e-01, -9.6448150e-04,  2.2880004e-01,\n",
      "       -0.0000000e+00,  1.3656396e+00, -3.4469727e-01,  9.2518848e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 191/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1850.3870\n",
      "Beta: [array([ 6.7928964e-01,  5.8687997e-01, -4.0078969e-04,  2.2873335e-01,\n",
      "       -0.0000000e+00,  1.3682362e+00, -3.4497380e-01,  9.2727917e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 192/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1864.5248\n",
      "Beta: [array([ 6.7629957e-01,  5.8971155e-01, -1.2664816e-03,  2.3022521e-01,\n",
      "        1.1929527e-03,  1.3744475e+00, -3.4850931e-01,  9.3062866e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 193/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1860.4478\n",
      "Beta: [array([ 6.7873907e-01,  5.8716226e-01, -3.9640910e-04,  2.2779837e-01,\n",
      "        2.1143345e-04,  1.3760477e+00, -3.4641424e-01,  9.3122190e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 194/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1861.5906\n",
      "Beta: [array([ 6.7937195e-01,  5.8638209e-01, -9.4668905e-04,  2.2730026e-01,\n",
      "        4.3913955e-04,  1.3787409e+00, -3.4659529e-01,  9.3298304e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 195/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1863.0323\n",
      "Beta: [array([ 0.67994964,  0.58571726,  0.        ,  0.2264896 ,  0.00145179,\n",
      "        1.3807409 , -0.34673944,  0.93374443], dtype=float32)]\n",
      "Epoch 196/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1860.3390\n",
      "Beta: [array([ 6.7949545e-01,  5.8607531e-01, -4.8410700e-04,  2.2667298e-01,\n",
      "        1.0727829e-03,  1.3840479e+00, -3.4888685e-01,  9.3556976e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 197/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1853.0120\n",
      "Beta: [array([ 0.6817244 ,  0.58363795, -0.00182534,  0.22410363, -0.        ,\n",
      "        1.3859286 , -0.3463552 ,  0.93608904], dtype=float32)]\n",
      "Epoch 198/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1859.2061\n",
      "Beta: [array([ 6.8139195e-01,  5.8385044e-01, -1.2341585e-03,  2.2460368e-01,\n",
      "       -0.0000000e+00,  1.3890339e+00, -3.4806517e-01,  9.3836379e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 199/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1868.6692\n",
      "Beta: [array([ 0.6819281 ,  0.5831393 ,  0.        ,  0.22383983,  0.00146311,\n",
      "        1.3919078 , -0.34807786,  0.9398207 ], dtype=float32)]\n",
      "Epoch 200/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1876.4980\n",
      "Beta: [array([ 6.7902434e-01,  5.8599174e-01, -2.5998880e-03,  2.2715147e-01,\n",
      "        6.5188663e-04,  1.3970339e+00, -3.5302666e-01,  9.4467914e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 201/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1868.9760\n",
      "Beta: [array([ 6.8132097e-01,  5.8354402e-01, -7.1370770e-04,  2.2388890e-01,\n",
      "        3.6112184e-04,  1.3978149e+00, -3.5108066e-01,  9.4328582e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 202/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1864.0028\n",
      "Beta: [array([ 6.8447924e-01,  5.8027852e-01,  0.0000000e+00,  2.2073735e-01,\n",
      "        1.6855451e-04,  1.3992751e+00, -3.4852985e-01,  9.4352210e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 203/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1862.2155\n",
      "Beta: [array([ 6.8721139e-01,  5.7745349e-01, -7.7962155e-05,  2.1925804e-01,\n",
      "        1.2152131e-03,  1.3986194e+00, -3.4724227e-01,  9.4374722e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 204/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1863.5385\n",
      "Beta: [array([ 6.8522698e-01,  5.7926089e-01, -6.1190367e-06,  2.1989556e-01,\n",
      "        6.0622984e-05,  1.4049838e+00, -3.4885693e-01,  9.4732702e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 205/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1862.7502\n",
      "Beta: [array([ 6.8614477e-01,  5.7818413e-01, -1.1468676e-03,  2.1892916e-01,\n",
      "       -0.0000000e+00,  1.4069787e+00, -3.4879777e-01,  9.4840741e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 206/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1859.4272\n",
      "Beta: [array([ 0.68679214,  0.5773121 , -0.00156407,  0.21730115, -0.        ,\n",
      "        1.4093169 , -0.34805176,  0.94851816], dtype=float32)]\n",
      "Epoch 207/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1865.9332\n",
      "Beta: [array([ 6.8652320e-01,  5.7747567e-01, -5.9751055e-04,  2.1791331e-01,\n",
      "       -0.0000000e+00,  1.4131544e+00, -3.4957600e-01,  9.5198655e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 208/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1870.2504\n",
      "Beta: [array([ 6.8679160e-01,  5.7701957e-01, -3.8212453e-04,  2.1749438e-01,\n",
      "        2.3033872e-04,  1.4157727e+00, -3.4930530e-01,  9.5351642e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 209/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1866.6949\n",
      "Beta: [array([ 6.9056982e-01,  5.7320851e-01, -7.3474548e-05,  2.1532483e-01,\n",
      "        2.2302675e-03,  1.4138986e+00, -3.4818721e-01,  9.5278364e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 210/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1871.1403\n",
      "Beta: [array([ 6.8743551e-01,  5.7609433e-01, -1.2969610e-07,  2.1553372e-01,\n",
      "        8.2472514e-04,  1.4207805e+00, -3.4924909e-01,  9.5530957e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 211/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1865.5824\n",
      "Beta: [array([ 6.8957555e-01,  5.7386649e-01, -6.2046997e-04,  2.1382967e-01,\n",
      "       -0.0000000e+00,  1.4217454e+00, -3.4854519e-01,  9.5628595e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 212/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1863.5577\n",
      "Beta: [array([ 6.9213605e-01,  5.7120585e-01, -1.7198986e-04,  2.1252233e-01,\n",
      "       -0.0000000e+00,  1.4220926e+00, -3.4799117e-01,  9.5717388e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 213/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1879.4390\n",
      "Beta: [array([ 6.8592918e-01,  5.7722992e-01, -4.0992610e-03,  2.1756721e-01,\n",
      "        1.6210388e-04,  1.4308541e+00, -3.5452151e-01,  9.6371013e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 214/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1887.0760\n",
      "Beta: [array([ 0.6892467 ,  0.5737332 ,  0.        ,  0.2141688 ,  0.0019811 ,\n",
      "        1.4319044 , -0.35148337,  0.9637721 ], dtype=float32)]\n",
      "Epoch 215/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1874.7786\n",
      "Beta: [array([ 0.69093055,  0.57194644,  0.        ,  0.21158339,  0.00152081,\n",
      "        1.4323621 , -0.35056794,  0.9623502 ], dtype=float32)]\n",
      "Epoch 216/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1871.3154\n",
      "Beta: [array([ 0.6914529 ,  0.57122225,  0.        ,  0.21087487, -0.        ,\n",
      "        1.4342706 , -0.35042894,  0.96309   ], dtype=float32)]\n",
      "Epoch 217/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1879.3328\n",
      "Beta: [array([ 6.9030637e-01,  5.7223004e-01,  0.0000000e+00,  2.1120533e-01,\n",
      "        8.9081150e-04,  1.4392684e+00, -3.5100743e-01,  9.6670872e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 218/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1872.4368\n",
      "Beta: [array([ 6.9274646e-01,  5.6960678e-01, -9.4737910e-04,  2.1041389e-01,\n",
      "       -0.0000000e+00,  1.4406124e+00, -3.5113928e-01,  9.6899712e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 219/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1876.9908\n",
      "Beta: [array([ 6.9335872e-01,  5.6886435e-01,  0.0000000e+00,  2.0891812e-01,\n",
      "        2.2869445e-04,  1.4421076e+00, -3.5056934e-01,  9.6861362e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 220/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1885.2140\n",
      "Beta: [array([ 6.9278228e-01,  5.6926495e-01,  0.0000000e+00,  2.0926592e-01,\n",
      "        9.5119659e-04,  1.4466233e+00, -3.5194933e-01,  9.7216576e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 221/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1880.7212\n",
      "Beta: [array([ 6.9088119e-01,  5.7100832e-01, -2.1886602e-03,  2.1002698e-01,\n",
      "        3.7170562e-04,  1.4500515e+00, -3.5439178e-01,  9.7354364e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 222/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1865.9120\n",
      "Beta: [array([ 6.9672704e-01,  5.6503451e-01, -9.9304598e-04,  2.0447215e-01,\n",
      "        2.5199507e-03,  1.4478385e+00, -3.4950981e-01,  9.7078323e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 223/1000\n",
      "40/40 [==============================] - 70s 2s/step - loss: 1879.6595\n",
      "Beta: [array([ 6.9452602e-01,  5.6701541e-01,  0.0000000e+00,  2.0634508e-01,\n",
      "        5.5119174e-04,  1.4536914e+00, -3.5179046e-01,  9.7584277e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 224/1000\n",
      "40/40 [==============================] - 71s 2s/step - loss: 1870.7742\n",
      "Beta: [array([ 0.69602084,  0.5653572 , -0.00162181,  0.2042345 , -0.        ,\n",
      "        1.4549452 , -0.35107282,  0.9755613 ], dtype=float32)]\n",
      "Epoch 225/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1884.3704\n",
      "Beta: [array([ 6.9545531e-01,  5.6570989e-01, -6.3644678e-05,  2.0522285e-01,\n",
      "        7.0737267e-04,  1.4585156e+00, -3.5205412e-01,  9.7868806e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 226/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1882.2848\n",
      "Beta: [array([ 6.9560570e-01,  5.6546420e-01, -1.5950305e-05,  2.0288627e-01,\n",
      "        1.5118383e-03,  1.4610246e+00, -3.5150546e-01,  9.7849745e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 227/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1873.7885\n",
      "Beta: [array([ 6.9704551e-01,  5.6383616e-01, -1.0183115e-03,  2.0257148e-01,\n",
      "       -0.0000000e+00,  1.4625586e+00, -3.5155675e-01,  9.8004681e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 228/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1887.6992\n",
      "Beta: [array([ 6.9638073e-01,  5.6433088e-01,  0.0000000e+00,  2.0357254e-01,\n",
      "        9.6868345e-04,  1.4662951e+00, -3.5272247e-01,  9.8381567e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 229/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1883.9338\n",
      "Beta: [array([ 6.9683105e-01,  5.6372637e-01,  0.0000000e+00,  2.0197248e-01,\n",
      "        9.5158233e-04,  1.4679857e+00, -3.5283402e-01,  9.8343498e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 230/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1893.1490\n",
      "Beta: [array([ 0.6969579 ,  0.563472  ,  0.        ,  0.2031792 ,  0.00210426,\n",
      "        1.4712301 , -0.35365072,  0.98802567], dtype=float32)]\n",
      "Epoch 231/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1887.7668\n",
      "Beta: [array([ 6.9841385e-01,  5.6183720e-01,  0.0000000e+00,  2.0044604e-01,\n",
      "        1.2462576e-03,  1.4720476e+00, -3.5353339e-01,  9.8623717e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 232/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1878.0172\n",
      "Beta: [array([ 7.0258838e-01,  5.5757743e-01, -1.9527352e-04,  1.9726172e-01,\n",
      "        3.1284364e-03,  1.4701501e+00, -3.5047680e-01,  9.8512596e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 233/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1871.9540\n",
      "Beta: [array([ 0.70034593,  0.55959284, -0.0023533 ,  0.19869468, -0.        ,\n",
      "        1.4762297 , -0.3521245 ,  0.9895749 ], dtype=float32)]\n",
      "Epoch 234/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1881.9216\n",
      "Beta: [array([ 7.0322901e-01,  5.5662715e-01, -2.9830064e-04,  1.9624469e-01,\n",
      "        1.7944786e-03,  1.4755875e+00, -3.5100982e-01,  9.8873448e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 235/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1882.9386\n",
      "Beta: [array([ 7.0040244e-01,  5.5914068e-01, -1.4101031e-04,  1.9755359e-01,\n",
      "       -0.0000000e+00,  1.4818398e+00, -3.5283282e-01,  9.9239433e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 236/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1885.2640\n",
      "Beta: [array([ 7.0198202e-01,  5.5750835e-01,  0.0000000e+00,  1.9595909e-01,\n",
      "        3.2333678e-04,  1.4820555e+00, -3.5249591e-01,  9.9238878e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 237/1000\n",
      "40/40 [==============================] - 70s 2s/step - loss: 1881.4650\n",
      "Beta: [array([ 0.7020215 ,  0.55724305, -0.00187735,  0.1964507 , -0.        ,\n",
      "        1.4859238 , -0.3527285 ,  0.99633205], dtype=float32)]\n",
      "Epoch 238/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1897.4866\n",
      "Beta: [array([ 7.0014274e-01,  5.5894536e-01, -2.4689324e-03,  1.9790407e-01,\n",
      "        1.4255189e-03,  1.4901303e+00, -3.5555238e-01,  9.9920553e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 239/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1883.1656\n",
      "Beta: [array([ 7.0237124e-01,  5.5656528e-01, -1.8484894e-03,  1.9368324e-01,\n",
      "        3.9586317e-04,  1.4910735e+00, -3.5290948e-01,  9.9709833e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 240/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1890.6890\n",
      "Beta: [array([ 7.0478594e-01,  5.5403847e-01, -9.7476121e-05,  1.9252290e-01,\n",
      "        2.1435753e-03,  1.4904505e+00, -3.5239890e-01,  9.9752027e-01],\n",
      "      dtype=float32)]\n",
      "Epoch 241/1000\n",
      "40/40 [==============================] - 71s 2s/step - loss: 1880.1576\n",
      "Beta: [array([ 0.7034827 ,  0.5550809 , -0.00214925,  0.19280255, -0.        ,\n",
      "        1.4953715 , -0.35350806,  1.0005834 ], dtype=float32)]\n",
      "Epoch 242/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1888.4036\n",
      "Beta: [array([ 7.0338309e-01,  5.5510122e-01, -1.3653892e-03,  1.9250824e-01,\n",
      "       -0.0000000e+00,  1.4972258e+00, -3.5421863e-01,  1.0015402e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 243/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1885.2574\n",
      "Beta: [array([ 7.0572019e-01,  5.5253035e-01, -6.7901571e-04,  1.9067462e-01,\n",
      "       -0.0000000e+00,  1.4980407e+00, -3.5269058e-01,  1.0023588e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 244/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1884.3038\n",
      "Beta: [array([ 7.0524031e-01,  5.5280840e-01, -9.1558206e-04,  1.9040333e-01,\n",
      "       -0.0000000e+00,  1.5011137e+00, -3.5312048e-01,  1.0039730e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 245/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1896.8898\n",
      "Beta: [array([ 7.0433336e-01,  5.5350405e-01, -3.1132321e-04,  1.9084525e-01,\n",
      "        9.0096315e-04,  1.5052978e+00, -3.5396329e-01,  1.0072925e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 246/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1897.8486\n",
      "Beta: [array([ 7.0483804e-01,  5.5284512e-01, -3.6694331e-05,  1.8999773e-01,\n",
      "        1.3703986e-03,  1.5074426e+00, -3.5444924e-01,  1.0081367e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 247/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1892.6548\n",
      "Beta: [array([ 7.0621824e-01,  5.5130124e-01, -7.1310863e-04,  1.8935689e-01,\n",
      "       -0.0000000e+00,  1.5087430e+00, -3.5448375e-01,  1.0097171e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 248/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1891.6212\n",
      "Beta: [array([ 7.0658529e-01,  5.5075002e-01, -1.3153900e-04,  1.8766753e-01,\n",
      "       -0.0000000e+00,  1.5108504e+00, -3.5333279e-01,  1.0101907e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 249/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1893.9868\n",
      "Beta: [array([ 7.0684212e-01,  5.5032974e-01,  0.0000000e+00,  1.8809001e-01,\n",
      "        6.8581539e-05,  1.5128024e+00, -3.5458812e-01,  1.0120907e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 250/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1897.3176\n",
      "Beta: [array([ 0.707085  ,  0.5499341 ,  0.        ,  0.18787003, -0.        ,\n",
      "        1.5149454 , -0.35538018,  1.0135798 ], dtype=float32)]\n",
      "Epoch 251/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1898.0538\n",
      "Beta: [array([ 7.0777339e-01,  5.4902095e-01, -5.1803097e-05,  1.8681601e-01,\n",
      "        8.3949635e-05,  1.5175660e+00, -3.5480508e-01,  1.0154310e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 252/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1895.2102\n",
      "Beta: [array([ 7.0608294e-01,  5.5054665e-01, -1.8193356e-03,  1.8794830e-01,\n",
      "        1.0294844e-04,  1.5198104e+00, -3.5718188e-01,  1.0162067e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 253/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1902.9304\n",
      "Beta: [array([ 0.7091798 ,  0.5472862 ,  0.        ,  0.18484046,  0.00199929,\n",
      "        1.5209502 , -0.35497844,  1.0170662 ], dtype=float32)]\n",
      "Epoch 254/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1896.4728\n",
      "Beta: [array([ 7.1022099e-01,  5.4603350e-01, -8.6202647e-04,  1.8457317e-01,\n",
      "        9.1075455e-04,  1.5227325e+00, -3.5462460e-01,  1.0191045e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 255/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1897.7742\n",
      "Beta: [array([ 7.0913231e-01,  5.4693091e-01,  0.0000000e+00,  1.8451636e-01,\n",
      "        2.4579305e-04,  1.5258299e+00, -3.5555792e-01,  1.0206320e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 256/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1892.8256\n",
      "Beta: [array([ 7.1064335e-01,  5.4516554e-01, -4.3548018e-04,  1.8215020e-01,\n",
      "       -0.0000000e+00,  1.5272961e+00, -3.5392833e-01,  1.0201454e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 257/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1903.2842\n",
      "Beta: [array([ 7.0917058e-01,  5.4651701e-01, -1.1102021e-03,  1.8375245e-01,\n",
      "        8.8188733e-04,  1.5307876e+00, -3.5691652e-01,  1.0235559e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 258/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1899.9166\n",
      "Beta: [array([ 7.1264690e-01,  5.4289293e-01, -1.0024946e-05,  1.8031496e-01,\n",
      "        1.9381639e-03,  1.5306613e+00, -3.5455754e-01,  1.0227827e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 259/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1889.4602\n",
      "Beta: [array([ 0.7128093 ,  0.54251   , -0.00157113,  0.17931996, -0.        ,\n",
      "        1.5329438 , -0.35408866,  1.0238771 ], dtype=float32)]\n",
      "Epoch 260/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1890.4872\n",
      "Beta: [array([ 7.1300268e-01,  5.4210329e-01, -1.1172693e-03,  1.7863838e-01,\n",
      "       -0.0000000e+00,  1.5354290e+00, -3.5396340e-01,  1.0255307e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 261/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1899.1882\n",
      "Beta: [array([ 0.7131225 ,  0.5418424 ,  0.        ,  0.17952688, -0.        ,\n",
      "        1.5377719 , -0.35487416,  1.028624  ], dtype=float32)]\n",
      "Epoch 262/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1899.0858\n",
      "Beta: [array([ 7.1318001e-01,  5.4149199e-01, -5.0532224e-05,  1.7761998e-01,\n",
      "        3.6132734e-04,  1.5401909e+00, -3.5426918e-01,  1.0280514e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 263/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1901.7076\n",
      "Beta: [array([ 7.1275574e-01,  5.4177880e-01,  0.0000000e+00,  1.7884198e-01,\n",
      "        4.9993291e-04,  1.5435411e+00, -3.5568261e-01,  1.0321028e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 264/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1907.3292\n",
      "Beta: [array([ 7.1142989e-01,  5.4285067e-01, -1.0768251e-03,  1.7923528e-01,\n",
      "        7.0275477e-04,  1.5458474e+00, -3.5755223e-01,  1.0326182e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 265/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1907.0844\n",
      "Beta: [array([ 7.1431851e-01,  5.3982252e-01, -7.6594646e-05,  1.7647921e-01,\n",
      "        1.3951515e-03,  1.5470310e+00, -3.5509548e-01,  1.0337998e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 266/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1902.8816\n",
      "Beta: [array([ 7.1439016e-01,  5.3958225e-01,  0.0000000e+00,  1.7613260e-01,\n",
      "        4.7650083e-04,  1.5485069e+00, -3.5644150e-01,  1.0343246e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 267/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1899.9260\n",
      "Beta: [array([ 0.71563673,  0.53811914,  0.        ,  0.17474993, -0.        ,\n",
      "        1.5497142 , -0.35553595,  1.0350062 ], dtype=float32)]\n",
      "Epoch 268/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1900.3854\n",
      "Beta: [array([ 0.7156715 ,  0.5379208 ,  0.        ,  0.17433012, -0.        ,\n",
      "        1.5525436 , -0.35562238,  1.0369688 ], dtype=float32)]\n",
      "Epoch 269/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1903.9946\n",
      "Beta: [array([ 7.1686304e-01,  5.3647417e-01,  0.0000000e+00,  1.7424616e-01,\n",
      "        8.1113380e-05,  1.5540160e+00, -3.5571009e-01,  1.0393770e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 270/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1897.2296\n",
      "Beta: [array([ 7.1717763e-01,  5.3594494e-01, -1.0902645e-03,  1.7215477e-01,\n",
      "       -0.0000000e+00,  1.5559670e+00, -3.5446766e-01,  1.0388312e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 271/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1898.6848\n",
      "Beta: [array([ 7.1979642e-01,  5.3320140e-01, -1.9131716e-04,  1.7027004e-01,\n",
      "        1.1780877e-03,  1.5553122e+00, -3.5269222e-01,  1.0385405e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 272/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1910.6140\n",
      "Beta: [array([ 7.1519601e-01,  5.3757524e-01, -1.0106228e-03,  1.7308937e-01,\n",
      "        2.0642392e-03,  1.5628543e+00, -3.5691130e-01,  1.0438558e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 273/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1900.4574\n",
      "Beta: [array([ 7.1748346e-01,  5.3513777e-01, -1.9883376e-03,  1.7187186e-01,\n",
      "        1.2312687e-03,  1.5634403e+00, -3.5587046e-01,  1.0452316e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 274/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1907.7863\n",
      "Beta: [array([ 7.1867371e-01,  5.3364974e-01, -6.0755311e-04,  1.7108287e-01,\n",
      "        5.1476888e-04,  1.5636948e+00, -3.5609826e-01,  1.0454369e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 275/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1898.4189\n",
      "Beta: [array([ 0.71915925,  0.53293043, -0.00170748,  0.16878374, -0.        ,\n",
      "        1.5660733 , -0.35487854,  1.0452907 ], dtype=float32)]\n",
      "Epoch 276/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1901.2174\n",
      "Beta: [array([ 0.7187036 ,  0.5331799 , -0.00160146,  0.16894472, -0.        ,\n",
      "        1.5691046 , -0.355802  ,  1.0478274 ], dtype=float32)]\n",
      "Epoch 277/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1912.1226\n",
      "Beta: [array([ 7.1760738e-01,  5.3407353e-01, -2.4959969e-04,  1.7012998e-01,\n",
      "        3.7335150e-04,  1.5729307e+00, -3.5697258e-01,  1.0513623e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 278/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1912.8364\n",
      "Beta: [array([ 7.1731287e-01,  5.3418434e-01, -4.6435304e-04,  1.7042112e-01,\n",
      "        4.6533681e-04,  1.5747358e+00, -3.5873711e-01,  1.0526886e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 279/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1915.5522\n",
      "Beta: [array([ 7.1699059e-01,  5.3430814e-01, -4.3987899e-04,  1.6968979e-01,\n",
      "        1.9898388e-04,  1.5766814e+00, -3.5901076e-01,  1.0532423e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 280/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1904.9248\n",
      "Beta: [array([ 0.7202961 ,  0.5307519 , -0.00179169,  0.16635671, -0.        ,\n",
      "        1.5770646 , -0.35629693,  1.0530287 ], dtype=float32)]\n",
      "Epoch 281/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1912.5208\n",
      "Beta: [array([ 7.2021288e-01,  5.3065801e-01, -3.3016244e-04,  1.6625515e-01,\n",
      "       -0.0000000e+00,  1.5789422e+00, -3.5643369e-01,  1.0546042e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 282/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1910.3816\n",
      "Beta: [array([ 7.2040468e-01,  5.3018671e-01,  0.0000000e+00,  1.6493501e-01,\n",
      "        3.4519701e-04,  1.5814533e+00, -3.5690245e-01,  1.0552218e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 283/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1910.5066\n",
      "Beta: [array([ 7.2286981e-01,  5.2758628e-01, -1.3128833e-04,  1.6327845e-01,\n",
      "        1.6273808e-03,  1.5806679e+00, -3.5577652e-01,  1.0549244e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 284/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1910.6097\n",
      "Beta: [array([ 7.2098792e-01,  5.2925819e-01,  0.0000000e+00,  1.6415013e-01,\n",
      "        4.2451091e-05,  1.5855563e+00, -3.5748482e-01,  1.0583162e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 285/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1914.1466\n",
      "Beta: [array([ 7.2068542e-01,  5.2933872e-01, -5.3851766e-04,  1.6539766e-01,\n",
      "        4.9666096e-07,  1.5872225e+00, -3.5901651e-01,  1.0606195e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 286/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1913.7657\n",
      "Beta: [array([ 7.2169125e-01,  5.2807981e-01, -1.8799710e-04,  1.6379018e-01,\n",
      "        1.6138781e-04,  1.5896662e+00, -3.5699233e-01,  1.0620171e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 287/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1913.3914\n",
      "Beta: [array([ 0.7225919 ,  0.5269497 ,  0.        ,  0.16174747, -0.        ,\n",
      "        1.5905738 , -0.35706642,  1.0612701 ], dtype=float32)]\n",
      "Epoch 288/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1908.7190\n",
      "Beta: [array([ 0.7227523 ,  0.5266456 ,  0.        ,  0.16102718, -0.        ,\n",
      "        1.5923612 , -0.3577243 ,  1.0621614 ], dtype=float32)]\n",
      "Epoch 289/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1913.1244\n",
      "Beta: [array([ 7.2463536e-01,  5.2455097e-01, -4.0134633e-04,  1.6048396e-01,\n",
      "        2.1743996e-04,  1.5927434e+00, -3.5568586e-01,  1.0643072e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 290/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1912.8162\n",
      "Beta: [array([ 7.2353929e-01,  5.2545267e-01, -7.9822040e-04,  1.5984602e-01,\n",
      "        1.4177069e-05,  1.5969833e+00, -3.5697377e-01,  1.0658942e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 291/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1908.8458\n",
      "Beta: [array([ 7.2643745e-01,  5.2234232e-01, -3.9707549e-04,  1.5719879e-01,\n",
      "        1.2536348e-03,  1.5952461e+00, -3.5511628e-01,  1.0642980e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 292/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1911.4012\n",
      "Beta: [array([ 7.2370452e-01,  5.2480876e-01, -4.6536364e-04,  1.5847404e-01,\n",
      "        4.4206692e-05,  1.6007675e+00, -3.5687152e-01,  1.0679278e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 293/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1924.1384\n",
      "Beta: [array([ 7.2223943e-01,  5.2610171e-01, -2.1658011e-03,  1.6016434e-01,\n",
      "        7.2626577e-04,  1.6035343e+00, -3.6053479e-01,  1.0701439e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 294/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1918.3104\n",
      "Beta: [array([ 7.2323108e-01,  5.2486914e-01, -8.0915977e-04,  1.5947998e-01,\n",
      "        1.4506961e-04,  1.6045779e+00, -3.6046320e-01,  1.0711052e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 295/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1916.1187\n",
      "Beta: [array([ 7.2534639e-01,  5.2253598e-01,  0.0000000e+00,  1.5754022e-01,\n",
      "        3.0934569e-04,  1.6039499e+00, -3.5952169e-01,  1.0704230e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 296/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1916.9775\n",
      "Beta: [array([ 7.2571295e-01,  5.2196288e-01,  0.0000000e+00,  1.5695827e-01,\n",
      "        3.9261713e-06,  1.6073666e+00, -3.5761288e-01,  1.0735649e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 297/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1913.1118\n",
      "Beta: [array([ 0.7271933 ,  0.52015746,  0.        ,  0.15474051, -0.        ,\n",
      "        1.6080242 , -0.35741907,  1.0725687 ], dtype=float32)]\n",
      "Epoch 298/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1905.8420\n",
      "Beta: [array([ 0.7285479 ,  0.51859456, -0.00178503,  0.15288232, -0.        ,\n",
      "        1.6091202 , -0.3550859 ,  1.0732578 ], dtype=float32)]\n",
      "Epoch 299/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1911.5032\n",
      "Beta: [array([ 0.7272893 ,  0.5197163 , -0.00222213,  0.15431026, -0.        ,\n",
      "        1.6127626 , -0.35768974,  1.0767664 ], dtype=float32)]\n",
      "Epoch 300/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1918.4714\n",
      "Beta: [array([ 7.27007926e-01,  5.19691348e-01, -1.13587295e-04,  1.53459847e-01,\n",
      "       -0.00000000e+00,  1.61533403e+00, -3.57180834e-01,  1.07823694e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 301/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1909.5028\n",
      "Beta: [array([ 7.2865492e-01,  5.1781958e-01, -9.0756128e-04,  1.5129942e-01,\n",
      "       -0.0000000e+00,  1.6155705e+00, -3.5651660e-01,  1.0774673e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 302/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1925.0034\n",
      "Beta: [array([ 7.2540569e-01,  5.2083635e-01, -2.5410524e-03,  1.5445279e-01,\n",
      "        1.2983291e-03,  1.6204154e+00, -3.6073142e-01,  1.0816561e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 303/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1920.2070\n",
      "Beta: [array([ 7.2758478e-01,  5.1840663e-01,  0.0000000e+00,  1.5214126e-01,\n",
      "        7.5718440e-04,  1.6205137e+00, -3.5894156e-01,  1.0808653e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 304/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1923.9352\n",
      "Beta: [array([ 7.2808087e-01,  5.1770788e-01,  0.0000000e+00,  1.5181895e-01,\n",
      "        1.7448729e-04,  1.6224098e+00, -3.5940123e-01,  1.0829921e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 305/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1925.7142\n",
      "Beta: [array([ 7.2632629e-01,  5.1924223e-01, -5.3531304e-04,  1.5299250e-01,\n",
      "        7.1630965e-04,  1.6254528e+00, -3.6053804e-01,  1.0854084e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 306/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1924.4794\n",
      "Beta: [array([ 7.2988421e-01,  5.1540649e-01, -3.6713514e-05,  1.4980109e-01,\n",
      "        8.2032493e-04,  1.6249087e+00, -3.5861760e-01,  1.0846692e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 307/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1919.3304\n",
      "Beta: [array([ 7.3021680e-01,  5.1487797e-01, -3.4040952e-04,  1.4869967e-01,\n",
      "        2.9665342e-04,  1.6267012e+00, -3.5820904e-01,  1.0850310e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 308/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1927.1868\n",
      "Beta: [array([ 7.2874767e-01,  5.1616794e-01, -9.5478969e-04,  1.5001269e-01,\n",
      "        1.2515009e-03,  1.6292119e+00, -3.6078259e-01,  1.0873355e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 309/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1924.0542\n",
      "Beta: [array([ 7.2904146e-01,  5.1560473e-01,  0.0000000e+00,  1.5073583e-01,\n",
      "        1.3848711e-04,  1.6312579e+00, -3.6068666e-01,  1.0901222e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 310/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1929.0909\n",
      "Beta: [array([ 7.2833180e-01,  5.1612020e-01, -1.2299430e-04,  1.5011306e-01,\n",
      "        8.9187943e-04,  1.6339577e+00, -3.6173767e-01,  1.0910054e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 311/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1927.0590\n",
      "Beta: [array([ 7.3051912e-01,  5.1367062e-01,  0.0000000e+00,  1.4725859e-01,\n",
      "        1.1561709e-03,  1.6344379e+00, -3.5989097e-01,  1.0904948e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 312/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1916.7954\n",
      "Beta: [array([ 7.3178935e-01,  5.1223212e-01, -1.1994473e-03,  1.4672001e-01,\n",
      "        1.5013646e-03,  1.6337968e+00, -3.6011767e-01,  1.0904834e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 313/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1918.1971\n",
      "Beta: [array([ 7.3315769e-01,  5.1057744e-01,  0.0000000e+00,  1.4404270e-01,\n",
      "        6.9897226e-04,  1.6342446e+00, -3.5865015e-01,  1.0889689e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 314/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1917.4038\n",
      "Beta: [array([ 7.3239136e-01,  5.1107258e-01, -6.3749088e-04,  1.4387429e-01,\n",
      "        5.2624173e-04,  1.6388820e+00, -3.5862786e-01,  1.0925719e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 315/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1917.7734\n",
      "Beta: [array([ 7.3278534e-01,  5.1047146e-01, -3.8590765e-04,  1.4337383e-01,\n",
      "       -0.0000000e+00,  1.6394045e+00, -3.5958141e-01,  1.0922368e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 316/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1932.3190\n",
      "Beta: [array([ 7.2940153e-01,  5.1370728e-01, -9.2428224e-04,  1.4613263e-01,\n",
      "        1.0354047e-03,  1.6448178e+00, -3.6309174e-01,  1.0969265e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 317/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1919.6263\n",
      "Beta: [array([ 0.7335845 ,  0.5091958 ,  0.        ,  0.14171651,  0.00215093,\n",
      "        1.6432161 , -0.3602544 ,  1.0944835 ], dtype=float32)]\n",
      "Epoch 318/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1920.8126\n",
      "Beta: [array([ 7.3373151e-01,  5.0876737e-01, -7.9110643e-04,  1.4156514e-01,\n",
      "        5.3801050e-04,  1.6453297e+00, -3.5962924e-01,  1.0966536e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 319/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1926.0154\n",
      "Beta: [array([ 7.3300225e-01,  5.0928646e-01, -5.4669159e-04,  1.4201471e-01,\n",
      "        1.5554435e-03,  1.6474276e+00, -3.6132953e-01,  1.0978727e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 320/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1923.4738\n",
      "Beta: [array([ 7.3428488e-01,  5.0776154e-01,  0.0000000e+00,  1.4073321e-01,\n",
      "        3.8197334e-04,  1.6484075e+00, -3.6051270e-01,  1.0986948e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 321/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1917.1855\n",
      "Beta: [array([ 7.3828995e-01,  5.0357080e-01, -2.9564096e-04,  1.3685773e-01,\n",
      "        2.6654233e-03,  1.6457975e+00, -3.5635167e-01,  1.0965440e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 322/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1918.4592\n",
      "Beta: [array([ 7.3379737e-01,  5.0786549e-01, -1.7093611e-03,  1.4046529e-01,\n",
      "        7.3951851e-05,  1.6532146e+00, -3.6161339e-01,  1.1020470e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 323/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1926.0352\n",
      "Beta: [array([ 7.3392737e-01,  5.0742865e-01, -1.4177999e-03,  1.4052959e-01,\n",
      "       -0.0000000e+00,  1.6535249e+00, -3.6188051e-01,  1.1023139e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 324/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1929.3290\n",
      "Beta: [array([ 7.3482853e-01,  5.0626153e-01,  0.0000000e+00,  1.3972752e-01,\n",
      "        4.7583395e-04,  1.6554893e+00, -3.6136830e-01,  1.1040632e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 325/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1923.9182\n",
      "Beta: [array([ 0.7353649 ,  0.50556946,  0.        ,  0.13836929, -0.        ,\n",
      "        1.6570641 , -0.36130357,  1.1045063 ], dtype=float32)]\n",
      "Epoch 326/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1922.7876\n",
      "Beta: [array([ 7.3752141e-01,  5.0312519e-01, -2.5050907e-04,  1.3683598e-01,\n",
      "        1.8831564e-04,  1.6563796e+00, -3.6022091e-01,  1.1043714e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 327/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1931.9780\n",
      "Beta: [array([ 7.3363352e-01,  5.0677288e-01, -1.6377140e-03,  1.3970141e-01,\n",
      "        4.9768708e-04,  1.6616672e+00, -3.6374971e-01,  1.1079508e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 328/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1922.5496\n",
      "Beta: [array([ 7.3717439e-01,  5.0294340e-01, -1.2581097e-03,  1.3610674e-01,\n",
      "        8.2000694e-04,  1.6608094e+00, -3.6021638e-01,  1.1067543e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 329/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1926.0225\n",
      "Beta: [array([ 7.3759431e-01,  5.0233555e-01, -6.6868303e-04,  1.3620734e-01,\n",
      "       -0.0000000e+00,  1.6623535e+00, -3.6031711e-01,  1.1092035e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 330/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1929.6121\n",
      "Beta: [array([ 0.73661464,  0.5030031 ,  0.        ,  0.13592018, -0.        ,\n",
      "        1.6653552 , -0.36174807,  1.1098484 ], dtype=float32)]\n",
      "Epoch 331/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1933.2885\n",
      "Beta: [array([ 0.7374415 ,  0.5019771 ,  0.        ,  0.1350407 ,  0.00171989,\n",
      "        1.6659962 , -0.3620389 ,  1.1105585 ], dtype=float32)]\n",
      "Epoch 332/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1917.3744\n",
      "Beta: [array([ 7.3991859e-01,  4.9928379e-01, -1.1700891e-03,  1.3205628e-01,\n",
      "        1.9957307e-03,  1.6653408e+00, -3.5941198e-01,  1.1093471e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 333/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1922.9454\n",
      "Beta: [array([ 7.3867404e-01,  5.0029403e-01, -6.9916860e-04,  1.3339321e-01,\n",
      "       -0.0000000e+00,  1.6685150e+00, -3.6158088e-01,  1.1121674e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 334/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1929.2494\n",
      "Beta: [array([ 7.3729253e-01,  5.0134504e-01, -3.0010645e-04,  1.3416162e-01,\n",
      "       -0.0000000e+00,  1.6720551e+00, -3.6292961e-01,  1.1147497e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 335/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1930.0310\n",
      "Beta: [array([ 7.3783082e-01,  5.0060081e-01, -6.5934908e-04,  1.3288784e-01,\n",
      "       -0.0000000e+00,  1.6734006e+00, -3.6205947e-01,  1.1151208e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 336/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1935.4340\n",
      "Beta: [array([ 7.3784697e-01,  5.0040191e-01, -3.3367382e-04,  1.3309172e-01,\n",
      "        9.2455011e-04,  1.6756822e+00, -3.6329392e-01,  1.1171215e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 337/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1930.5931\n",
      "Beta: [array([ 0.7380352 ,  0.4999174 ,  0.        ,  0.13226733, -0.        ,\n",
      "        1.6763861 , -0.3632827 ,  1.1169963 ], dtype=float32)]\n",
      "Epoch 338/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1929.5529\n",
      "Beta: [array([ 7.3711652e-01,  5.0060683e-01, -1.0108817e-03,  1.3337910e-01,\n",
      "        1.6445530e-05,  1.6783344e+00, -3.6541265e-01,  1.1185498e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 339/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1939.8997\n",
      "Beta: [array([ 7.3716116e-01,  5.0031060e-01,  0.0000000e+00,  1.3309972e-01,\n",
      "        7.5370917e-04,  1.6805698e+00, -3.6576769e-01,  1.1203111e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 340/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1934.4296\n",
      "Beta: [array([ 7.3877174e-01,  4.9840912e-01,  0.0000000e+00,  1.3033098e-01,\n",
      "        8.8816689e-04,  1.6810352e+00, -3.6362493e-01,  1.1188858e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 341/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1930.1158\n",
      "Beta: [array([ 7.4079251e-01,  4.9622703e-01, -3.8922215e-05,  1.3054366e-01,\n",
      "        4.9224583e-04,  1.6811181e+00, -3.6253765e-01,  1.1215702e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 342/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1939.3796\n",
      "Beta: [array([ 7.3923355e-01,  4.9753073e-01, -1.5065640e-04,  1.3096781e-01,\n",
      "        2.2999347e-04,  1.6853362e+00, -3.6329058e-01,  1.1245251e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 343/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1942.4868\n",
      "Beta: [array([ 7.3834783e-01,  4.9816233e-01, -2.7323255e-04,  1.3154911e-01,\n",
      "        1.3093441e-03,  1.6873927e+00, -3.6544362e-01,  1.1256461e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 344/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1933.5668\n",
      "Beta: [array([ 7.3888963e-01,  4.9732262e-01, -1.2667668e-03,  1.2945244e-01,\n",
      "        7.8100874e-04,  1.6873736e+00, -3.6657083e-01,  1.1233253e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 345/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1927.2626\n",
      "Beta: [array([ 7.4153298e-01,  4.9448532e-01, -1.4982525e-03,  1.2624316e-01,\n",
      "       -0.0000000e+00,  1.6882433e+00, -3.6278644e-01,  1.1236579e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 346/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1933.7812\n",
      "Beta: [array([ 7.4124962e-01,  4.9453777e-01, -4.0540338e-04,  1.2736268e-01,\n",
      "        1.6103020e-04,  1.6897552e+00, -3.6337784e-01,  1.1261548e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 347/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1932.0098\n",
      "Beta: [array([ 7.4180526e-01,  4.9366480e-01, -3.4875437e-04,  1.2530926e-01,\n",
      "        2.1164371e-04,  1.6910195e+00, -3.6364052e-01,  1.1250576e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 348/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1943.4690\n",
      "Beta: [array([ 0.7410664 ,  0.49416882,  0.        ,  0.12773877,  0.00228324,\n",
      "        1.6937078 , -0.36546135,  1.1289104 ], dtype=float32)]\n",
      "Epoch 349/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1940.7917\n",
      "Beta: [array([ 7.4084455e-01,  4.9416429e-01, -6.1474217e-04,  1.2683077e-01,\n",
      "        1.1047923e-03,  1.6944808e+00, -3.6700723e-01,  1.1281877e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 350/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1916.3044\n",
      "Beta: [array([ 0.7450384 ,  0.4896991 , -0.00170676,  0.12183488,  0.0025185 ,\n",
      "        1.6925739 , -0.3628873 ,  1.1248405 ], dtype=float32)]\n",
      "Epoch 351/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1929.2844\n",
      "Beta: [array([ 0.7421123 ,  0.49241903, -0.00256865,  0.12428977, -0.        ,\n",
      "        1.6966506 , -0.3660839 ,  1.1284362 ], dtype=float32)]\n",
      "Epoch 352/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1931.5439\n",
      "Beta: [array([ 0.7424125 ,  0.49184963, -0.00172629,  0.12464839, -0.        ,\n",
      "        1.6975772 , -0.36716926,  1.1296982 ], dtype=float32)]\n",
      "Epoch 353/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1938.8831\n",
      "Beta: [array([ 7.4195033e-01,  4.9206039e-01,  0.0000000e+00,  1.2493817e-01,\n",
      "        8.5655338e-04,  1.7015942e+00, -3.6654919e-01,  1.1333894e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 354/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1937.3624\n",
      "Beta: [array([ 7.4321193e-01,  4.9054265e-01, -5.0122768e-04,  1.2217878e-01,\n",
      "        7.1126065e-04,  1.7019272e+00, -3.6488363e-01,  1.1320914e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 355/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1928.0746\n",
      "Beta: [array([ 7.4455881e-01,  4.8892683e-01, -1.5436793e-03,  1.2135263e-01,\n",
      "        3.7675479e-04,  1.7018089e+00, -3.6531472e-01,  1.1320537e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 356/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1932.6331\n",
      "Beta: [array([ 7.43553102e-01,  4.89721239e-01, -9.98491538e-04,  1.22587875e-01,\n",
      "        1.72627847e-06,  1.70519555e+00, -3.65422159e-01,  1.13568318e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 357/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1935.1833\n",
      "Beta: [array([ 0.74290234,  0.49020308, -0.00339858,  0.12264167, -0.        ,\n",
      "        1.7058041 , -0.3689923 ,  1.1347677 ], dtype=float32)]\n",
      "Epoch 358/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1937.0645\n",
      "Beta: [array([ 7.4386024e-01,  4.8885536e-01, -3.5582209e-04,  1.2104012e-01,\n",
      "       -0.0000000e+00,  1.7077262e+00, -3.6691150e-01,  1.1356596e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 359/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1937.7590\n",
      "Beta: [array([ 0.746282  ,  0.48635042,  0.        ,  0.11951628,  0.00230811,\n",
      "        1.7057682 , -0.36618212,  1.1347946 ], dtype=float32)]\n",
      "Epoch 360/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1937.4520\n",
      "Beta: [array([ 7.4304289e-01,  4.8923615e-01, -6.5159274e-04,  1.2233706e-01,\n",
      "       -0.0000000e+00,  1.7105900e+00, -3.6824295e-01,  1.1391137e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 361/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1941.2112\n",
      "Beta: [array([ 7.4433655e-01,  4.8770210e-01, -2.2984885e-04,  1.2025415e-01,\n",
      "        4.2511561e-05,  1.7127104e+00, -3.6801270e-01,  1.1395025e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 362/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1944.0054\n",
      "Beta: [array([ 7.4441946e-01,  4.8734558e-01, -2.5847508e-04,  1.1988441e-01,\n",
      "        8.4005477e-04,  1.7140903e+00, -3.6722183e-01,  1.1406852e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 363/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1944.5234\n",
      "Beta: [array([ 7.4442029e-01,  4.8707154e-01, -1.2668346e-04,  1.1889740e-01,\n",
      "        1.6799531e-03,  1.7153925e+00, -3.6760154e-01,  1.1404989e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 364/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1939.0826\n",
      "Beta: [array([ 7.4550277e-01,  4.8573115e-01,  0.0000000e+00,  1.1841899e-01,\n",
      "        5.7546893e-04,  1.7160313e+00, -3.6822110e-01,  1.1412059e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 365/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1945.0118\n",
      "Beta: [array([ 7.4443227e-01,  4.8653716e-01,  0.0000000e+00,  1.1917610e-01,\n",
      "        9.9472038e-04,  1.7188922e+00, -3.6851239e-01,  1.1433703e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 366/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1934.7913\n",
      "Beta: [array([ 0.7480832 ,  0.48266503,  0.        ,  0.11523339,  0.0038836 ,\n",
      "        1.7156105 , -0.3673356 ,  1.1394942 ], dtype=float32)]\n",
      "Epoch 367/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1926.0504\n",
      "Beta: [array([ 7.4734932e-01,  4.8309577e-01, -1.3526598e-03,  1.1498933e-01,\n",
      "        2.2898326e-04,  1.7187390e+00, -3.6741957e-01,  1.1410050e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 368/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1941.9294\n",
      "Beta: [array([ 7.45532870e-01,  4.84816849e-01, -3.89472261e-04,  1.17874205e-01,\n",
      "        6.05083260e-05,  1.72295249e+00, -3.69453102e-01,  1.14644098e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 369/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1941.6342\n",
      "Beta: [array([ 7.4596900e-01,  4.8398486e-01, -1.1747462e-03,  1.1614792e-01,\n",
      "        7.9454324e-04,  1.7240090e+00, -3.6933050e-01,  1.1452674e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 370/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1943.5382\n",
      "Beta: [array([ 7.4589020e-01,  4.8380172e-01,  0.0000000e+00,  1.1615190e-01,\n",
      "        5.5893161e-04,  1.7254473e+00, -3.6953253e-01,  1.1464481e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 371/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1945.7480\n",
      "Beta: [array([ 0.7463298 ,  0.48312175,  0.        ,  0.11534521,  0.00188098,\n",
      "        1.7262331 , -0.37028667,  1.1466923 ], dtype=float32)]\n",
      "Epoch 372/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1941.4060\n",
      "Beta: [array([ 7.4526477e-01,  4.8394844e-01, -1.1720619e-03,  1.1570076e-01,\n",
      "        1.5613646e-04,  1.7277769e+00, -3.7238935e-01,  1.1468924e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 373/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1946.4540\n",
      "Beta: [array([ 7.4590069e-01,  4.8307586e-01, -2.6654470e-04,  1.1587640e-01,\n",
      "        6.2258617e-04,  1.7304080e+00, -3.7113219e-01,  1.1499802e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 374/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1943.1263\n",
      "Beta: [array([ 7.4744141e-01,  4.8123130e-01, -9.3697803e-05,  1.1394477e-01,\n",
      "        5.1197474e-04,  1.7304548e+00, -3.7013024e-01,  1.1496671e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 375/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1941.2870\n",
      "Beta: [array([ 7.4753761e-01,  4.8090851e-01, -1.1723080e-03,  1.1296830e-01,\n",
      "        9.4143866e-04,  1.7316302e+00, -3.7134907e-01,  1.1491050e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 376/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1929.2957\n",
      "Beta: [array([ 7.4925840e-01,  4.7895670e-01, -1.6734650e-03,  1.1091067e-01,\n",
      "        1.1992627e-03,  1.7308819e+00, -3.7034908e-01,  1.1475736e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 377/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1942.6967\n",
      "Beta: [array([ 7.48144269e-01,  4.79760081e-01, -5.03086718e-04,  1.12021066e-01,\n",
      "        1.11037667e-03,  1.73424435e+00, -3.71571958e-01,  1.15082133e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 378/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1941.0402\n",
      "Beta: [array([ 7.48100221e-01,  4.79591399e-01,  0.00000000e+00,  1.12142585e-01,\n",
      "        2.79470419e-06,  1.73540843e+00, -3.73065084e-01,  1.15155375e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 379/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1945.4402\n",
      "Beta: [array([ 7.4868637e-01,  4.7866553e-01, -2.7432537e-04,  1.1174900e-01,\n",
      "        4.7679359e-04,  1.7365251e+00, -3.7204009e-01,  1.1523937e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 380/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1939.5828\n",
      "Beta: [array([ 0.7487144 ,  0.4784553 ,  0.        ,  0.11137118, -0.        ,\n",
      "        1.737965  , -0.37363547,  1.1532172 ], dtype=float32)]\n",
      "Epoch 381/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1940.0360\n",
      "Beta: [array([ 7.5052631e-01,  4.7637206e-01, -8.6097769e-04,  1.1000973e-01,\n",
      "       -0.0000000e+00,  1.7376870e+00, -3.7200424e-01,  1.1532254e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 382/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1946.9236\n",
      "Beta: [array([ 7.4892443e-01,  4.7772679e-01, -6.5876002e-04,  1.1188282e-01,\n",
      "        2.4615286e-04,  1.7415124e+00, -3.7347895e-01,  1.1569530e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 383/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1948.7664\n",
      "Beta: [array([ 7.4898255e-01,  4.7746962e-01,  0.0000000e+00,  1.0990877e-01,\n",
      "        6.3187495e-04,  1.7427553e+00, -3.7456930e-01,  1.1554350e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 384/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1950.8232\n",
      "Beta: [array([ 7.4888992e-01,  4.7728816e-01,  0.0000000e+00,  1.0962064e-01,\n",
      "        1.7318022e-03,  1.7435592e+00, -3.7519562e-01,  1.1555353e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 385/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1936.1403\n",
      "Beta: [array([ 7.5121880e-01,  4.7469699e-01, -1.4358277e-03,  1.0796661e-01,\n",
      "        1.6125431e-03,  1.7432442e+00, -3.7356794e-01,  1.1556948e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 386/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1934.3394\n",
      "Beta: [array([ 7.52115428e-01,  4.73483980e-01, -1.10812986e-03,  1.06664814e-01,\n",
      "        6.03341963e-04,  1.74369037e+00, -3.72857451e-01,  1.15538251e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 387/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1939.3756\n",
      "Beta: [array([ 7.5072110e-01,  4.7463804e-01, -1.9177384e-03,  1.0780454e-01,\n",
      "        1.5091228e-04,  1.7469436e+00, -3.7449497e-01,  1.1579914e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 388/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1943.2102\n",
      "Beta: [array([ 7.5251633e-01,  4.7262064e-01, -3.8536981e-04,  1.0708355e-01,\n",
      "        7.0411188e-04,  1.7467601e+00, -3.7265298e-01,  1.1589922e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 389/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1940.8514\n",
      "Beta: [array([ 7.5048620e-01,  4.7428629e-01, -1.4131330e-03,  1.0775475e-01,\n",
      "       -0.0000000e+00,  1.7502167e+00, -3.7527916e-01,  1.1602519e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 390/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1955.5684\n",
      "Beta: [array([ 7.4976498e-01,  4.7473752e-01, -3.4766708e-05,  1.0818350e-01,\n",
      "        1.4730893e-03,  1.7526397e+00, -3.7540647e-01,  1.1621906e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 391/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1939.6989\n",
      "Beta: [array([ 7.53743649e-01,  4.70551223e-01, -1.00425619e-03,  1.04017235e-01,\n",
      "        4.10979427e-03,  1.74960947e+00, -3.72928679e-01,  1.15849793e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 392/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1943.9106\n",
      "Beta: [array([ 7.50796378e-01,  4.73193169e-01, -6.44416781e-04,  1.06447875e-01,\n",
      "       -0.00000000e+00,  1.75443673e+00, -3.76093149e-01,  1.16221035e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 393/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1949.6786\n",
      "Beta: [array([ 7.51053214e-01,  4.72709239e-01, -1.00300043e-04,  1.05407715e-01,\n",
      "        7.83886411e-04,  1.75573456e+00, -3.75566125e-01,  1.16242182e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 394/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1940.7908\n",
      "Beta: [array([ 0.75185627,  0.4716365 , -0.00250471,  0.10542746, -0.        ,\n",
      "        1.7564832 , -0.37575543,  1.1634754 ], dtype=float32)]\n",
      "Epoch 395/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1945.5256\n",
      "Beta: [array([ 7.53259301e-01,  4.70030218e-01, -6.38432684e-04,  1.04627654e-01,\n",
      "        6.13762822e-04,  1.75617826e+00, -3.75341982e-01,  1.16365492e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 396/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1953.8004\n",
      "Beta: [array([ 7.4962449e-01,  4.7338375e-01, -8.1403251e-04,  1.0658717e-01,\n",
      "        1.2744023e-04,  1.7611656e+00, -3.7866995e-01,  1.1660647e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 397/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1948.5640\n",
      "Beta: [array([ 0.7517098 ,  0.4709538 ,  0.        ,  0.10481583, -0.        ,\n",
      "        1.7608101 , -0.37811044,  1.1656134 ], dtype=float32)]\n",
      "Epoch 398/1000\n",
      "40/40 [==============================] - 70s 2s/step - loss: 1952.0790\n",
      "Beta: [array([ 7.5113583e-01,  4.7135961e-01, -6.0657231e-04,  1.0427894e-01,\n",
      "        7.7029399e-04,  1.7628901e+00, -3.7814003e-01,  1.1661723e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 399/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1951.0354\n",
      "Beta: [array([ 7.51950860e-01,  4.70275044e-01, -1.13374525e-04,  1.04119509e-01,\n",
      "        3.34608514e-04,  1.76368105e+00, -3.78008515e-01,  1.16740644e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 400/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1956.9398\n",
      "Beta: [array([ 7.51739681e-01,  4.70183313e-01,  0.00000000e+00,  1.04826674e-01,\n",
      "        1.19741331e-03,  1.76490033e+00, -3.79337072e-01,  1.16866362e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 401/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1948.2098\n",
      "Beta: [array([ 7.53698587e-01,  4.67967480e-01, -9.34809214e-04,  1.02335714e-01,\n",
      "        8.25730152e-04,  1.76484835e+00, -3.78660232e-01,  1.16755128e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 402/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1945.7098\n",
      "Beta: [array([ 7.5295413e-01,  4.6853656e-01, -1.3012026e-03,  1.0180777e-01,\n",
      "       -0.0000000e+00,  1.7668384e+00, -3.7915313e-01,  1.1679045e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 403/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1947.9304\n",
      "Beta: [array([ 7.5319338e-01,  4.6793258e-01, -6.5030681e-04,  1.0192675e-01,\n",
      "       -0.0000000e+00,  1.7682480e+00, -3.7958983e-01,  1.1691319e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 404/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1949.9940\n",
      "Beta: [array([ 7.5310999e-01,  4.6775702e-01, -4.1170715e-05,  1.0176235e-01,\n",
      "        3.3159324e-04,  1.7695825e+00, -3.7990794e-01,  1.1696254e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 405/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1957.2275\n",
      "Beta: [array([ 7.5238156e-01,  4.6829793e-01,  0.0000000e+00,  1.0285560e-01,\n",
      "        1.1731093e-03,  1.7714374e+00, -3.8076252e-01,  1.1718882e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 406/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1956.8496\n",
      "Beta: [array([ 0.75376403,  0.46659023,  0.        ,  0.10111973,  0.00230317,\n",
      "        1.7716662 , -0.38128433,  1.1708128 ], dtype=float32)]\n",
      "Epoch 407/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1939.0562\n",
      "Beta: [array([ 0.75639665,  0.46373364, -0.00202818,  0.09899782,  0.00299865,\n",
      "        1.7705457 , -0.37926725,  1.170056  ], dtype=float32)]\n",
      "Epoch 408/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1941.9486\n",
      "Beta: [array([ 7.5594085e-01,  4.6396095e-01, -1.1655597e-03,  9.9132426e-02,\n",
      "        6.9301797e-04,  1.7724829e+00, -3.8029686e-01,  1.1711413e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 409/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1959.4904\n",
      "Beta: [array([ 7.53414273e-01,  4.66160923e-01, -7.58042908e-04,  1.00584745e-01,\n",
      "        2.20218115e-03,  1.77634335e+00, -3.83039564e-01,  1.17316961e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 410/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1962.6090\n",
      "Beta: [array([ 0.75356257,  0.4657436 ,  0.        ,  0.10022856,  0.0024634 ,\n",
      "        1.7776535 , -0.38232318,  1.1737194 ], dtype=float32)]\n",
      "Epoch 411/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1949.0402\n",
      "Beta: [array([ 7.5511885e-01,  4.6395180e-01, -3.1870371e-04,  9.8238774e-02,\n",
      "        2.3539874e-03,  1.7773383e+00, -3.8172528e-01,  1.1728015e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 412/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1947.6404\n",
      "Beta: [array([ 7.5566852e-01,  4.6325925e-01, -4.9811602e-04,  9.7330451e-02,\n",
      "        6.2934664e-04,  1.7789389e+00, -3.8190570e-01,  1.1735238e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 413/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1949.6288\n",
      "Beta: [array([ 7.5387055e-01,  4.6470454e-01, -1.3189088e-03,  9.8864213e-02,\n",
      "        3.6749098e-04,  1.7815866e+00, -3.8408440e-01,  1.1750942e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 414/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1956.6031\n",
      "Beta: [array([ 7.5366890e-01,  4.6465617e-01, -7.0179551e-04,  9.9391527e-02,\n",
      "        1.3158733e-03,  1.7827634e+00, -3.8558811e-01,  1.1762681e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 415/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1958.4666\n",
      "Beta: [array([ 7.5316924e-01,  4.6491116e-01,  0.0000000e+00,  9.9537253e-02,\n",
      "        9.5332169e-04,  1.7844816e+00, -3.8671884e-01,  1.1771020e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 416/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1952.8920\n",
      "Beta: [array([ 7.5354064e-01,  4.6427447e-01, -9.9522504e-04,  9.9004991e-02,\n",
      "        2.0110200e-04,  1.7847522e+00, -3.8674378e-01,  1.1765809e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 417/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1959.3964\n",
      "Beta: [array([ 0.7553416 ,  0.46218288,  0.        ,  0.09765722,  0.00212626,\n",
      "        1.7854478 , -0.3857543 ,  1.1773894 ], dtype=float32)]\n",
      "Epoch 418/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1949.5244\n",
      "Beta: [array([ 0.75730914,  0.46002635,  0.        ,  0.09572656,  0.0023719 ,\n",
      "        1.7849219 , -0.38431582,  1.1762339 ], dtype=float32)]\n",
      "Epoch 419/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1938.3838\n",
      "Beta: [array([ 7.5997335e-01,  4.5710295e-01, -1.1855199e-03,  9.2750810e-02,\n",
      "        3.3268565e-03,  1.7834177e+00, -3.8163736e-01,  1.1746421e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 420/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1954.2664\n",
      "Beta: [array([ 7.5549251e-01,  4.6130002e-01, -1.7217996e-03,  9.7316891e-02,\n",
      "        3.4360695e-04,  1.7897977e+00, -3.8581029e-01,  1.1802752e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 421/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1956.1206\n",
      "Beta: [array([ 7.5725746e-01,  4.5928466e-01, -8.6045848e-06,  9.5428430e-02,\n",
      "        7.3757395e-04,  1.7889830e+00, -3.8586614e-01,  1.1789509e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 422/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1951.7262\n",
      "Beta: [array([ 7.5693268e-01,  4.5934382e-01, -6.2269351e-04,  9.4958551e-02,\n",
      "       -0.0000000e+00,  1.7907271e+00, -3.8584518e-01,  1.1794721e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 423/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1959.6115\n",
      "Beta: [array([ 7.5543010e-01,  4.6059069e-01, -4.1948428e-05,  9.6790999e-02,\n",
      "        5.1132968e-04,  1.7936893e+00, -3.8812706e-01,  1.1821744e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 424/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1959.4460\n",
      "Beta: [array([ 7.5645071e-01,  4.5931289e-01,  0.0000000e+00,  9.4984710e-02,\n",
      "        1.1361318e-03,  1.7942322e+00, -3.8752967e-01,  1.1812116e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 425/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1950.3862\n",
      "Beta: [array([ 7.5766379e-01,  4.5786160e-01,  0.0000000e+00,  9.3557492e-02,\n",
      "        1.6511496e-03,  1.7932405e+00, -3.8699022e-01,  1.1798508e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 426/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1958.0308\n",
      "Beta: [array([ 7.5435460e-01,  4.6094623e-01, -1.3614787e-03,  9.6415587e-02,\n",
      "        2.5788316e-04,  1.7977744e+00, -3.9116096e-01,  1.1831285e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 427/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1959.5808\n",
      "Beta: [array([ 7.5670356e-01,  4.5831376e-01, -4.9418781e-04,  9.5307909e-02,\n",
      "        5.0959626e-04,  1.7981927e+00, -3.8844350e-01,  1.1844344e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 428/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1955.8374\n",
      "Beta: [array([ 7.5840384e-01,  4.5644176e-01, -5.2148092e-04,  9.2533961e-02,\n",
      "        1.1100731e-03,  1.7972084e+00, -3.8755572e-01,  1.1819831e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 429/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1954.5696\n",
      "Beta: [array([ 7.5753969e-01,  4.5701420e-01, -1.2242723e-03,  9.3521997e-02,\n",
      "       -0.0000000e+00,  1.8002563e+00, -3.8908240e-01,  1.1843404e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 430/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1956.1462\n",
      "Beta: [array([ 7.5716013e-01,  4.5714545e-01, -8.6276728e-04,  9.2850730e-02,\n",
      "        7.7044475e-04,  1.8018930e+00, -3.8993034e-01,  1.1843237e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 431/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1965.2188\n",
      "Beta: [array([ 7.5613475e-01,  4.5798650e-01, -9.1226641e-05,  9.3381278e-02,\n",
      "        1.4988172e-03,  1.8043638e+00, -3.9070219e-01,  1.1856934e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 432/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1947.6720\n",
      "Beta: [array([ 7.6051199e-01,  4.5329896e-01, -1.0258071e-03,  8.9595899e-02,\n",
      "        4.4770795e-03,  1.8008523e+00, -3.8841438e-01,  1.1824875e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 433/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1962.7456\n",
      "Beta: [array([ 7.5727534e-01,  4.5628306e-01, -1.4672538e-03,  9.2070445e-02,\n",
      "        2.8095744e-03,  1.8056183e+00, -3.9199871e-01,  1.1855121e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 434/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1962.0100\n",
      "Beta: [array([ 0.7580824 ,  0.4552269 ,  0.        ,  0.09108824,  0.00221892,\n",
      "        1.8063812 , -0.3918843 ,  1.1854935 ], dtype=float32)]\n",
      "Epoch 435/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1959.3256\n",
      "Beta: [array([ 7.5743914e-01,  4.5555964e-01,  0.0000000e+00,  9.2800833e-02,\n",
      "        3.6383234e-04,  1.8079424e+00, -3.9205426e-01,  1.1880325e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 436/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1966.4050\n",
      "Beta: [array([ 0.7582228 ,  0.4545032 ,  0.        ,  0.09025338,  0.0035586 ,\n",
      "        1.8080928 , -0.39276943,  1.1854906 ], dtype=float32)]\n",
      "Epoch 437/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1949.2582\n",
      "Beta: [array([ 0.76054865,  0.45195404,  0.        ,  0.08879404,  0.00506179,\n",
      "        1.8061534 , -0.39165547,  1.1841067 ], dtype=float32)]\n",
      "Epoch 438/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1954.7146\n",
      "Beta: [array([ 7.5701529e-01,  4.5528135e-01, -2.1080393e-03,  9.1564856e-02,\n",
      "        1.1781124e-04,  1.8112799e+00, -3.9629656e-01,  1.1876500e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 439/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1957.6198\n",
      "Beta: [array([ 7.5986475e-01,  4.5209289e-01,  0.0000000e+00,  8.8906519e-02,\n",
      "        6.9751602e-04,  1.8108335e+00, -3.9286944e-01,  1.1868919e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 440/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1952.6545\n",
      "Beta: [array([ 7.6026231e-01,  4.5150173e-01, -1.5380625e-03,  8.8558450e-02,\n",
      "       -0.0000000e+00,  1.8118660e+00, -3.9273614e-01,  1.1876407e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 441/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1962.4130\n",
      "Beta: [array([ 7.5901574e-01,  4.5245039e-01, -5.5261457e-04,  9.0822875e-02,\n",
      "        5.0946092e-04,  1.8147714e+00, -3.9366564e-01,  1.1911994e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 442/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1973.6688\n",
      "Beta: [array([ 0.7566493 ,  0.45466566, -0.00318339,  0.09213566,  0.00234922,\n",
      "        1.8174086 , -0.39822894,  1.1917708 ], dtype=float32)]\n",
      "Epoch 443/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1958.5984\n",
      "Beta: [array([ 0.7601683 ,  0.45076692,  0.        ,  0.08773416,  0.00384998,\n",
      "        1.8151563 , -0.39564323,  1.1880801 ], dtype=float32)]\n",
      "Epoch 444/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1950.4326\n",
      "Beta: [array([ 7.6127696e-01,  4.4939968e-01, -1.1728222e-04,  8.6966276e-02,\n",
      "        2.6155985e-03,  1.8159118e+00, -3.9468342e-01,  1.1887981e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 445/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1944.4072\n",
      "Beta: [array([ 7.6200521e-01,  4.4847190e-01, -1.6223984e-03,  8.6539507e-02,\n",
      "        1.4738218e-03,  1.8167300e+00, -3.9461836e-01,  1.1894121e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 446/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1959.2816\n",
      "Beta: [array([ 7.5922889e-01,  4.5096552e-01, -1.1443765e-03,  8.9759842e-02,\n",
      "        3.4091351e-04,  1.8210307e+00, -3.9613336e-01,  1.1938076e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 447/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1967.6484\n",
      "Beta: [array([ 7.5946879e-01,  4.5049614e-01, -2.1848045e-04,  8.8465951e-02,\n",
      "        2.3858803e-03,  1.8218894e+00, -3.9794573e-01,  1.1927826e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 448/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1955.9358\n",
      "Beta: [array([ 7.6064509e-01,  4.4905284e-01,  0.0000000e+00,  8.6962916e-02,\n",
      "        1.6073112e-03,  1.8221991e+00, -3.9790934e-01,  1.1920058e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 449/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1958.8430\n",
      "Beta: [array([ 7.6169920e-01,  4.4777083e-01, -4.4602525e-04,  8.6158112e-02,\n",
      "        1.2661400e-03,  1.8220348e+00, -3.9686584e-01,  1.1917725e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 450/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1956.8534\n",
      "Beta: [array([ 0.76085436,  0.4483102 , -0.00207838,  0.08734765, -0.        ,\n",
      "        1.8244063 , -0.39775074,  1.1937892 ], dtype=float32)]\n",
      "Epoch 451/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1956.9969\n",
      "Beta: [array([ 7.6259291e-01,  4.4636846e-01, -1.0156980e-03,  8.5561745e-02,\n",
      "        5.1731407e-04,  1.8239932e+00, -3.9587429e-01,  1.1929179e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 452/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1963.3694\n",
      "Beta: [array([ 7.6097447e-01,  4.4772011e-01, -5.4797728e-04,  8.8357478e-02,\n",
      "       -0.0000000e+00,  1.8269502e+00, -3.9843258e-01,  1.1966763e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 453/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1956.3315\n",
      "Beta: [array([ 7.6284468e-01,  4.4560948e-01, -4.7361606e-05,  8.4584400e-02,\n",
      "        9.8966551e-04,  1.8254752e+00, -3.9851466e-01,  1.1923032e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 454/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1962.3892\n",
      "Beta: [array([ 7.5925362e-01,  4.4900295e-01, -2.2431018e-03,  8.9548223e-02,\n",
      "        1.7722965e-04,  1.8317621e+00, -4.0096325e-01,  1.1997629e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 455/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1973.4008\n",
      "Beta: [array([ 7.5897020e-01,  4.4897458e-01, -2.6728961e-04,  8.8005148e-02,\n",
      "        1.3081154e-03,  1.8326055e+00, -4.0107754e-01,  1.1980524e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 456/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1967.4170\n",
      "Beta: [array([ 0.761576  ,  0.44613555,  0.        ,  0.08563548,  0.00194906,\n",
      "        1.8316802 , -0.40118787,  1.196361  ], dtype=float32)]\n",
      "Epoch 457/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1962.8490\n",
      "Beta: [array([ 7.6127344e-01,  4.4613147e-01, -1.1837182e-03,  8.5181266e-02,\n",
      "        6.7898975e-04,  1.8328468e+00, -4.0188497e-01,  1.1962214e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 458/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1969.9930\n",
      "Beta: [array([ 7.5938153e-01,  4.4777355e-01, -2.6498446e-03,  8.6990312e-02,\n",
      "        3.1831628e-04,  1.8348217e+00, -4.0481508e-01,  1.1975224e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 459/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1955.4283\n",
      "Beta: [array([ 7.6415485e-01,  4.4277129e-01, -1.8075049e-03,  8.2534969e-02,\n",
      "        2.3043707e-03,  1.8324183e+00, -4.0045926e-01,  1.1948670e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 460/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1963.0608\n",
      "Beta: [array([ 7.6252615e-01,  4.4414914e-01, -8.0616039e-04,  8.4367394e-02,\n",
      "       -0.0000000e+00,  1.8353010e+00, -4.0225768e-01,  1.1975086e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 461/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1963.9976\n",
      "Beta: [array([ 7.6227909e-01,  4.4415236e-01, -4.1684433e-04,  8.3296649e-02,\n",
      "        8.8684028e-04,  1.8370546e+00, -4.0248328e-01,  1.1971440e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 462/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1970.8306\n",
      "Beta: [array([ 7.6173860e-01,  4.4449252e-01, -5.4811238e-04,  8.5021138e-02,\n",
      "        1.2513653e-03,  1.8396409e+00, -4.0320897e-01,  1.2004944e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 463/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1973.7510\n",
      "Beta: [array([ 7.6134437e-01,  4.4458330e-01, -1.8166384e-03,  8.4945440e-02,\n",
      "        1.9617253e-03,  1.8397508e+00, -4.0628773e-01,  1.1991528e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 464/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1971.0808\n",
      "Beta: [array([ 0.7626551 ,  0.44301665,  0.        ,  0.08278433,  0.00312095,\n",
      "        1.8401102 , -0.40515304,  1.1980641 ], dtype=float32)]\n",
      "Epoch 465/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1966.2885\n",
      "Beta: [array([ 7.6262569e-01,  4.4284648e-01,  0.0000000e+00,  8.2282215e-02,\n",
      "        1.5209902e-03,  1.8412973e+00, -4.0582624e-01,  1.1978940e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 466/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1958.9019\n",
      "Beta: [array([ 7.6673025e-01,  4.3850067e-01, -2.8526687e-04,  8.0530129e-02,\n",
      "        3.8099147e-03,  1.8386015e+00, -4.0293324e-01,  1.1974412e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 467/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1973.4894\n",
      "Beta: [array([ 7.6071334e-01,  4.4431877e-01, -1.8263890e-03,  8.6209476e-02,\n",
      "        1.1036338e-03,  1.8462520e+00, -4.0796959e-01,  1.2038366e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 468/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1967.9960\n",
      "Beta: [array([ 7.6389146e-01,  4.4079357e-01, -4.2687880e-06,  8.1546985e-02,\n",
      "        2.5874039e-03,  1.8441440e+00, -4.0540704e-01,  1.1995597e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 469/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1961.3452\n",
      "Beta: [array([ 7.6411885e-01,  4.4035766e-01,  0.0000000e+00,  8.0897875e-02,\n",
      "        1.3376608e-03,  1.8450649e+00, -4.0689501e-01,  1.1993296e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 470/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1967.6830\n",
      "Beta: [array([ 7.6207513e-01,  4.4219390e-01,  0.0000000e+00,  8.5011102e-02,\n",
      "        5.6395936e-04,  1.8484912e+00, -4.0875432e-01,  1.2043662e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 471/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1954.7506\n",
      "Beta: [array([ 7.6534051e-01,  4.3858969e-01, -1.5963707e-03,  7.9887360e-02,\n",
      "        1.8153593e-03,  1.8466879e+00, -4.0687943e-01,  1.1997534e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 472/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1968.6888\n",
      "Beta: [array([ 7.6146752e-01,  4.4227681e-01, -4.0164101e-03,  8.5957378e-02,\n",
      "        3.0447289e-04,  1.8512652e+00, -4.1112360e-01,  1.2060108e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 473/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1971.8176\n",
      "Beta: [array([ 7.6218939e-01,  4.4124141e-01, -2.4704179e-03,  8.2961991e-02,\n",
      "        1.5002648e-04,  1.8510457e+00, -4.1225782e-01,  1.2025508e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 474/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1957.3868\n",
      "Beta: [array([ 7.6702195e-01,  4.3620092e-01, -9.7385218e-04,  7.8571804e-02,\n",
      "        2.0522783e-03,  1.8487749e+00, -4.0740007e-01,  1.2000029e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 475/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1964.5416\n",
      "Beta: [array([ 7.6584232e-01,  4.3721887e-01, -8.1904145e-05,  7.9395749e-02,\n",
      "        1.1398828e-03,  1.8514513e+00, -4.0869164e-01,  1.2020545e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 476/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1963.5286\n",
      "Beta: [array([ 7.6384169e-01,  4.3885708e-01,  0.0000000e+00,  8.0835082e-02,\n",
      "        8.9448949e-05,  1.8538229e+00, -4.1093805e-01,  1.2031735e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 477/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1961.0884\n",
      "Beta: [array([ 7.6783371e-01,  4.3473813e-01, -2.7176744e-04,  7.7763513e-02,\n",
      "        1.8571361e-03,  1.8518968e+00, -4.0820312e-01,  1.2015722e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 478/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1965.2820\n",
      "Beta: [array([ 7.6421136e-01,  4.3805656e-01, -6.1141595e-04,  7.9876229e-02,\n",
      "        2.5839242e-04,  1.8568386e+00, -4.1068655e-01,  1.2043532e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 479/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1966.0240\n",
      "Beta: [array([ 7.6588279e-01,  4.3618724e-01, -6.0905900e-04,  7.9750232e-02,\n",
      "       -0.0000000e+00,  1.8570189e+00, -4.1057855e-01,  1.2052751e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 480/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1962.3932\n",
      "Beta: [array([ 7.6653343e-01,  4.3522805e-01, -8.2491513e-04,  7.7878073e-02,\n",
      "        1.4214549e-04,  1.8566147e+00, -4.0962178e-01,  1.2033683e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 481/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1963.3086\n",
      "Beta: [array([ 0.7658912 ,  0.43561846, -0.00196894,  0.07956281, -0.        ,\n",
      "        1.8590355 , -0.4113219 ,  1.2060504 ], dtype=float32)]\n",
      "Epoch 482/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1974.7328\n",
      "Beta: [array([ 7.6506203e-01,  4.3618503e-01, -6.1665470e-04,  8.0022596e-02,\n",
      "        1.6327363e-03,  1.8609699e+00, -4.1269186e-01,  1.2067901e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 483/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1980.2236\n",
      "Beta: [array([ 7.6257771e-01,  4.3849435e-01,  0.0000000e+00,  8.2413778e-02,\n",
      "        4.7436179e-04,  1.8647205e+00, -4.1384459e-01,  1.2096500e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 484/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1978.6062\n",
      "Beta: [array([ 7.6466948e-01,  4.3610787e-01, -1.2748028e-04,  8.1025921e-02,\n",
      "        1.1391342e-03,  1.8642113e+00, -4.1322592e-01,  1.2093312e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 485/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1976.4586\n",
      "Beta: [array([ 7.6515198e-01,  4.3537867e-01, -3.0579974e-04,  8.0012657e-02,\n",
      "        1.2688758e-03,  1.8648630e+00, -4.1343269e-01,  1.2087765e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 486/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1964.0344\n",
      "Beta: [array([ 0.7674536 ,  0.43284327,  0.        ,  0.07711319,  0.00270686,\n",
      "        1.8630248 , -0.41351193,  1.205444  ], dtype=float32)]\n",
      "Epoch 487/1000\n",
      "40/40 [==============================] - 70s 2s/step - loss: 1969.1294\n",
      "Beta: [array([ 7.6628542e-01,  4.3377146e-01, -3.0802982e-04,  7.7917017e-02,\n",
      "       -0.0000000e+00,  1.8659531e+00, -4.1418675e-01,  1.2074366e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 488/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1957.9214\n",
      "Beta: [array([ 7.6812112e-01,  4.3170261e-01, -2.3963572e-03,  7.6454557e-02,\n",
      "        3.8934962e-04,  1.8651659e+00, -4.1381729e-01,  1.2064661e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 489/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1974.2280\n",
      "Beta: [array([ 7.6541698e-01,  4.3414453e-01, -1.4154909e-03,  7.8825995e-02,\n",
      "        1.3059234e-03,  1.8691905e+00, -4.1595176e-01,  1.2093760e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 490/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1974.1580\n",
      "Beta: [array([ 7.6594675e-01,  4.3343702e-01,  0.0000000e+00,  7.7692695e-02,\n",
      "        6.9122331e-04,  1.8702110e+00, -4.1652933e-01,  1.2089399e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 491/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1969.8354\n",
      "Beta: [array([ 7.6662594e-01,  4.3244949e-01, -6.6450110e-04,  7.7752262e-02,\n",
      "       -0.0000000e+00,  1.8703036e+00, -4.1612810e-01,  1.2091284e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 492/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1975.2692\n",
      "Beta: [array([ 7.6628923e-01,  4.3260878e-01,  0.0000000e+00,  7.7329189e-02,\n",
      "        1.2766096e-03,  1.8721862e+00, -4.1760057e-01,  1.2094946e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 493/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1964.9816\n",
      "Beta: [array([ 7.6735663e-01,  4.3125984e-01,  0.0000000e+00,  7.6025940e-02,\n",
      "        1.2991442e-03,  1.8715552e+00, -4.1753116e-01,  1.2080333e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 494/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1975.8430\n",
      "Beta: [array([ 7.6536030e-01,  4.3309620e-01,  0.0000000e+00,  7.7890240e-02,\n",
      "        9.7405806e-04,  1.8752413e+00, -4.1989198e-01,  1.2107342e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 495/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1973.3416\n",
      "Beta: [array([ 7.6752895e-01,  4.3063459e-01, -3.8592370e-05,  7.7297509e-02,\n",
      "        1.2821567e-03,  1.8743850e+00, -4.1792840e-01,  1.2111326e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 496/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1972.8634\n",
      "Beta: [array([ 7.6689136e-01,  4.3098539e-01, -6.8556052e-04,  7.7319853e-02,\n",
      "        1.2839769e-04,  1.8763431e+00, -4.1825572e-01,  1.2114506e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 497/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1972.0815\n",
      "Beta: [array([ 0.7667787 ,  0.4308623 ,  0.        ,  0.07618985, -0.        ,\n",
      "        1.8772333 , -0.41922554,  1.21058   ], dtype=float32)]\n",
      "Epoch 498/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1969.3737\n",
      "Beta: [array([ 7.6740009e-01,  4.3000808e-01, -2.4788777e-04,  7.5055070e-02,\n",
      "       -0.0000000e+00,  1.8781751e+00, -4.1858527e-01,  1.2104337e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 499/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1977.0508\n",
      "Beta: [array([ 7.6724994e-01,  4.2995736e-01,  0.0000000e+00,  7.7458754e-02,\n",
      "        8.9998226e-05,  1.8795655e+00, -4.1997552e-01,  1.2130418e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 500/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1960.6989\n",
      "Beta: [array([ 7.7079976e-01,  4.2618477e-01, -1.6205423e-03,  7.2790593e-02,\n",
      "        2.3120234e-03,  1.8769432e+00, -4.1782185e-01,  1.2089725e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 501/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1966.5360\n",
      "Beta: [array([ 7.6851469e-01,  4.2823130e-01, -1.2903357e-03,  7.4735463e-02,\n",
      "       -0.0000000e+00,  1.8805547e+00, -4.2063737e-01,  1.2112741e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 502/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1977.9382\n",
      "Beta: [array([ 7.6707989e-01,  4.2942309e-01, -8.1366242e-04,  7.5957306e-02,\n",
      "        7.4953010e-04,  1.8825046e+00, -4.2247844e-01,  1.2122347e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 503/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1980.2308\n",
      "Beta: [array([ 7.6506901e-01,  4.3123814e-01, -1.3484369e-04,  7.8740761e-02,\n",
      "        2.9226180e-04,  1.8866589e+00, -4.2269549e-01,  1.2168064e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 504/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1982.4524\n",
      "Beta: [array([ 7.6568580e-01,  4.3037549e-01, -2.4207792e-04,  7.6871537e-02,\n",
      "        5.7932257e-04,  1.8870724e+00, -4.2338881e-01,  1.2149190e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 505/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1968.1276\n",
      "Beta: [array([ 7.7135837e-01,  4.2447099e-01, -5.2694086e-04,  7.1698532e-02,\n",
      "        5.1579652e-03,  1.8821523e+00, -4.2063087e-01,  1.2099789e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 506/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1972.0208\n",
      "Beta: [array([ 7.6780635e-01,  4.2774463e-01, -1.2436968e-04,  7.5025834e-02,\n",
      "       -0.0000000e+00,  1.8872892e+00, -4.2429930e-01,  1.2138926e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 507/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1974.4640\n",
      "Beta: [array([ 7.6940536e-01,  4.2589149e-01,  0.0000000e+00,  7.3788762e-02,\n",
      "        9.2168513e-04,  1.8863238e+00, -4.2411622e-01,  1.2123138e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 508/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1978.5394\n",
      "Beta: [array([ 7.6775455e-01,  4.2734635e-01,  0.0000000e+00,  7.4513480e-02,\n",
      "        9.5848157e-04,  1.8895764e+00, -4.2483756e-01,  1.2139888e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 509/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1971.2924\n",
      "Beta: [array([ 7.6911241e-01,  4.2571503e-01, -1.0241338e-03,  7.3447213e-02,\n",
      "        5.2144169e-04,  1.8895689e+00, -4.2423230e-01,  1.2137613e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 510/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1984.1482\n",
      "Beta: [array([ 7.6752383e-01,  4.2706043e-01, -2.9909157e-04,  7.6137878e-02,\n",
      "        7.6231192e-04,  1.8928270e+00, -4.2560282e-01,  1.2173275e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 511/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1974.8042\n",
      "Beta: [array([ 7.7014530e-01,  4.2425814e-01, -1.4617531e-04,  7.2825931e-02,\n",
      "        2.6042736e-03,  1.8906527e+00, -4.2578283e-01,  1.2136108e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 512/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1976.3918\n",
      "Beta: [array([ 7.7019686e-01,  4.2399433e-01, -2.2471622e-04,  7.2935782e-02,\n",
      "        1.0216840e-03,  1.8918166e+00, -4.2513293e-01,  1.2143013e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 513/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1972.6562\n",
      "Beta: [array([ 7.7013665e-01,  4.2383820e-01, -4.4855374e-04,  7.2615534e-02,\n",
      "       -0.0000000e+00,  1.8936490e+00, -4.2657849e-01,  1.2149360e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 514/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1980.1354\n",
      "Beta: [array([ 7.7042496e-01,  4.2332694e-01, -4.8557660e-05,  7.3562920e-02,\n",
      "        1.0300491e-03,  1.8940020e+00, -4.2626789e-01,  1.2161176e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 515/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1976.9257\n",
      "Beta: [array([ 7.6909518e-01,  4.2434353e-01, -2.0997776e-04,  7.3670194e-02,\n",
      "       -0.0000000e+00,  1.8969210e+00, -4.2839164e-01,  1.2164968e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 516/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1966.4034\n",
      "Beta: [array([ 7.7138722e-01,  4.2185307e-01, -6.1520142e-04,  7.1248189e-02,\n",
      "        1.0510557e-03,  1.8954802e+00, -4.2722237e-01,  1.2141995e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 517/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1983.3372\n",
      "Beta: [array([ 7.6846164e-01,  4.2452371e-01, -6.7201225e-05,  7.3529661e-02,\n",
      "        1.0456900e-03,  1.9000179e+00, -4.2948812e-01,  1.2172719e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 518/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1982.4514\n",
      "Beta: [array([ 7.6786989e-01,  4.2489049e-01, -7.5284578e-04,  7.4902847e-02,\n",
      "        4.9676292e-04,  1.9010506e+00, -4.3240806e-01,  1.2181650e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 519/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1978.9208\n",
      "Beta: [array([ 0.7697267 ,  0.42276663,  0.        ,  0.07328766, -0.        ,\n",
      "        1.9011292 , -0.43096504,  1.2175716 ], dtype=float32)]\n",
      "Epoch 520/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1976.2396\n",
      "Beta: [array([ 7.7097464e-01,  4.2138264e-01, -2.4396839e-05,  7.2124057e-02,\n",
      "        1.4842916e-03,  1.8994501e+00, -4.3124536e-01,  1.2156546e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 521/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1981.5031\n",
      "Beta: [array([ 7.7024937e-01,  4.2189839e-01,  0.0000000e+00,  7.3238201e-02,\n",
      "        6.2903872e-04,  1.9017953e+00, -4.3239141e-01,  1.2175691e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 522/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1979.9360\n",
      "Beta: [array([ 7.6984835e-01,  4.2203635e-01, -3.5519945e-04,  7.2187334e-02,\n",
      "        4.1778601e-04,  1.9048899e+00, -4.3180391e-01,  1.2181772e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 523/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1985.3690\n",
      "Beta: [array([ 7.6986426e-01,  4.2172948e-01,  0.0000000e+00,  7.3667370e-02,\n",
      "        7.6020678e-04,  1.9058641e+00, -4.3209687e-01,  1.2197756e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 524/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1976.2402\n",
      "Beta: [array([ 7.7079082e-01,  4.2061296e-01, -1.4714842e-05,  7.0986964e-02,\n",
      "        5.7902344e-04,  1.9057095e+00, -4.3182525e-01,  1.2174098e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 525/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1981.8002\n",
      "Beta: [array([ 7.7069098e-01,  4.2047679e-01, -2.4055704e-04,  7.2359681e-02,\n",
      "       -0.0000000e+00,  1.9075116e+00, -4.3275338e-01,  1.2194817e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 526/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1979.2574\n",
      "Beta: [array([ 0.7740677 ,  0.416924  ,  0.        ,  0.06940367,  0.00294707,\n",
      "        1.9043361 , -0.4315571 ,  1.2160628 ], dtype=float32)]\n",
      "Epoch 527/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1981.0634\n",
      "Beta: [array([ 7.7043903e-01,  4.2026743e-01, -3.9856444e-04,  7.0986897e-02,\n",
      "        8.1660273e-04,  1.9100820e+00, -4.3314624e-01,  1.2187920e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 528/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1988.8478\n",
      "Beta: [array([ 7.6733994e-01,  4.2320287e-01, -3.0598820e-03,  7.4969567e-02,\n",
      "        1.3328688e-03,  1.9132547e+00, -4.3789381e-01,  1.2221110e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 529/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1988.5594\n",
      "Beta: [array([ 7.6883650e-01,  4.2146835e-01,  0.0000000e+00,  7.2380811e-02,\n",
      "        1.0642366e-03,  1.9131632e+00, -4.3755150e-01,  1.2197788e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 530/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1985.6232\n",
      "Beta: [array([ 7.7057207e-01,  4.1952163e-01,  0.0000000e+00,  7.1907535e-02,\n",
      "        8.5774600e-04,  1.9130377e+00, -4.3598381e-01,  1.2204993e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 531/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1979.7778\n",
      "Beta: [array([ 7.7069598e-01,  4.1918212e-01, -1.2859352e-03,  6.9757231e-02,\n",
      "        1.2475683e-04,  1.9144859e+00, -4.3597823e-01,  1.2190635e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 532/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1978.7368\n",
      "Beta: [array([ 7.7272582e-01,  4.1695529e-01, -2.7411533e-04,  7.0111565e-02,\n",
      "        6.6294696e-04,  1.9135907e+00, -4.3467289e-01,  1.2197484e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 533/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1981.1230\n",
      "Beta: [array([ 7.7075785e-01,  4.1869292e-01, -9.2325691e-04,  7.1762502e-02,\n",
      "        3.2711559e-04,  1.9170144e+00, -4.3716875e-01,  1.2220559e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 534/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1991.0806\n",
      "Beta: [array([ 7.6977676e-01,  4.1944459e-01,  0.0000000e+00,  7.1565948e-02,\n",
      "        1.7496652e-03,  1.9188285e+00, -4.3877622e-01,  1.2218324e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 535/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1981.4113\n",
      "Beta: [array([ 7.7461225e-01,  4.1439417e-01, -2.7297687e-04,  6.9256365e-02,\n",
      "        4.7539668e-03,  1.9155002e+00, -4.3507838e-01,  1.2205445e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 536/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1986.8525\n",
      "Beta: [array([ 7.7207446e-01,  4.1664851e-01, -3.2015285e-04,  6.9017209e-02,\n",
      "        2.5128019e-03,  1.9191792e+00, -4.3918452e-01,  1.2200117e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 537/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1977.1049\n",
      "Beta: [array([ 7.7326494e-01,  4.1521460e-01, -2.0876658e-04,  6.8207338e-02,\n",
      "        1.9417354e-03,  1.9193120e+00, -4.3852177e-01,  1.2195456e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 538/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1975.7014\n",
      "Beta: [array([ 7.7393377e-01,  4.1434735e-01, -1.3670900e-03,  6.8541467e-02,\n",
      "        1.0573553e-03,  1.9198272e+00, -4.3775868e-01,  1.2207658e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 539/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1985.7910\n",
      "Beta: [array([ 7.7288783e-01,  4.1519827e-01, -9.2705677e-04,  6.9010466e-02,\n",
      "        1.5104336e-03,  1.9220972e+00, -4.4041732e-01,  1.2214681e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 540/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1980.3007\n",
      "Beta: [array([ 7.7169454e-01,  4.1619182e-01, -1.1585174e-03,  6.9224566e-02,\n",
      "        2.4883176e-04,  1.9242957e+00, -4.4116384e-01,  1.2218449e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 541/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1981.5730\n",
      "Beta: [array([ 7.7143729e-01,  4.1629422e-01, -1.3590838e-03,  6.9937401e-02,\n",
      "        1.5005439e-04,  1.9251400e+00, -4.4319752e-01,  1.2224044e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 542/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1983.7205\n",
      "Beta: [array([ 0.7733182 ,  0.41408238,  0.        ,  0.06881741, -0.        ,\n",
      "        1.9249357 , -0.44152573,  1.2220652 ], dtype=float32)]\n",
      "Epoch 543/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1988.3396\n",
      "Beta: [array([ 7.7298486e-01,  4.1421580e-01,  0.0000000e+00,  6.9142632e-02,\n",
      "        1.1855260e-03,  1.9268599e+00, -4.4228640e-01,  1.2229561e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 544/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1989.7562\n",
      "Beta: [array([ 7.7316934e-01,  4.1387653e-01,  0.0000000e+00,  6.8711013e-02,\n",
      "        1.6765910e-03,  1.9281483e+00, -4.4270855e-01,  1.2233752e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 545/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1984.7406\n",
      "Beta: [array([ 7.7327353e-01,  4.1348690e-01,  0.0000000e+00,  7.0281997e-02,\n",
      "        4.1843575e-04,  1.9288248e+00, -4.4232845e-01,  1.2251256e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 546/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1995.3698\n",
      "Beta: [array([ 0.77232146,  0.4142532 ,  0.        ,  0.0694122 ,  0.00289271,\n",
      "        1.9307706 , -0.44454828,  1.2241696 ], dtype=float32)]\n",
      "Epoch 547/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1983.4852\n",
      "Beta: [array([ 7.7383190e-01,  4.1251919e-01, -3.3880898e-04,  6.9333009e-02,\n",
      "        2.3920028e-03,  1.9308634e+00, -4.4268587e-01,  1.2246644e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 548/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1991.3170\n",
      "Beta: [array([ 7.7147371e-01,  4.1470259e-01, -2.0682402e-03,  6.9187708e-02,\n",
      "        8.2845706e-04,  1.9332377e+00, -4.4770542e-01,  1.2235079e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 549/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1988.6366\n",
      "Beta: [array([ 7.7393126e-01,  4.1200739e-01,  0.0000000e+00,  6.7835972e-02,\n",
      "        1.1092204e-03,  1.9327174e+00, -4.4539732e-01,  1.2234761e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 550/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1993.9490\n",
      "Beta: [array([ 0.7740906 ,  0.41159603,  0.        ,  0.06809863,  0.00295941,\n",
      "        1.9340969 , -0.4448501 ,  1.2244419 ], dtype=float32)]\n",
      "Epoch 551/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1981.0308\n",
      "Beta: [array([ 7.7557486e-01,  4.0992427e-01, -5.5763801e-04,  6.6533342e-02,\n",
      "        2.7758058e-03,  1.9339799e+00, -4.4422570e-01,  1.2234735e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 552/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1987.5194\n",
      "Beta: [array([ 7.7454174e-01,  4.1073313e-01, -4.0507533e-05,  6.7696072e-02,\n",
      "        1.1225442e-03,  1.9360644e+00, -4.4602430e-01,  1.2246643e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 553/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1986.0927\n",
      "Beta: [array([ 7.7298629e-01,  4.1214171e-01, -8.4370945e-04,  6.7413628e-02,\n",
      "        1.1897963e-03,  1.9380283e+00, -4.4917819e-01,  1.2237639e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 554/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1980.3690\n",
      "Beta: [array([ 7.7531725e-01,  4.0951514e-01, -1.9559858e-03,  6.6939130e-02,\n",
      "        8.8959135e-04,  1.9377910e+00, -4.4609702e-01,  1.2246808e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 555/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1982.9738\n",
      "Beta: [array([ 7.7569228e-01,  4.0893149e-01, -7.6101563e-04,  6.5909855e-02,\n",
      "        2.1297862e-04,  1.9381124e+00, -4.4762790e-01,  1.2233922e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 556/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1988.7795\n",
      "Beta: [array([ 7.7463776e-01,  4.0981799e-01,  0.0000000e+00,  6.7663953e-02,\n",
      "        6.7652488e-04,  1.9402952e+00, -4.4841650e-01,  1.2255924e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 557/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1986.3380\n",
      "Beta: [array([ 7.7594471e-01,  4.0823874e-01,  0.0000000e+00,  6.6007592e-02,\n",
      "        1.9233701e-04,  1.9405214e+00, -4.4849929e-01,  1.2244810e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 558/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1974.6783\n",
      "Beta: [array([ 7.7768713e-01,  4.0635556e-01, -8.4625243e-04,  6.3749567e-02,\n",
      "        6.5813318e-04,  1.9398454e+00, -4.4685605e-01,  1.2226679e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 559/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1990.1484\n",
      "Beta: [array([ 7.7451533e-01,  4.0933976e-01, -2.8515519e-03,  6.7499563e-02,\n",
      "        9.9067600e-04,  1.9437903e+00, -4.5207351e-01,  1.2261300e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 560/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1985.4662\n",
      "Beta: [array([ 7.7871537e-01,  4.0496391e-01, -3.7068457e-05,  6.3438587e-02,\n",
      "        3.4906194e-03,  1.9409847e+00, -4.4831917e-01,  1.2228755e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 561/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1981.5988\n",
      "Beta: [array([ 7.7642643e-01,  4.0694490e-01, -2.4979032e-05,  6.5062374e-02,\n",
      "       -0.0000000e+00,  1.9449173e+00, -4.5012951e-01,  1.2248350e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 562/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1982.8784\n",
      "Beta: [array([ 7.7635711e-01,  4.0678710e-01, -1.4088774e-04,  6.5310575e-02,\n",
      "       -0.0000000e+00,  1.9457911e+00, -4.5016664e-01,  1.2253069e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 563/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1996.1313\n",
      "Beta: [array([ 7.7481312e-01,  4.0809178e-01,  0.0000000e+00,  6.7624964e-02,\n",
      "        1.8824947e-03,  1.9484050e+00, -4.5256212e-01,  1.2277592e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 564/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1985.1407\n",
      "Beta: [array([ 7.7909541e-01,  4.0365940e-01, -8.5765991e-04,  6.4709984e-02,\n",
      "        4.3210965e-03,  1.9456886e+00, -4.4877228e-01,  1.2258993e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 565/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1997.7030\n",
      "Beta: [array([ 7.7494580e-01,  4.0761536e-01, -5.0468172e-04,  6.9118075e-02,\n",
      "        4.9632933e-04,  1.9517806e+00, -4.5238024e-01,  1.2312058e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 566/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1996.0632\n",
      "Beta: [array([ 7.7571750e-01,  4.0664873e-01, -1.9836074e-04,  6.6284895e-02,\n",
      "        9.3923206e-04,  1.9518261e+00, -4.5158923e-01,  1.2284192e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 567/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1990.2178\n",
      "Beta: [array([ 7.7633172e-01,  4.0580192e-01, -4.3603737e-04,  6.5721676e-02,\n",
      "        3.9400739e-04,  1.9519827e+00, -4.5260739e-01,  1.2275088e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 568/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1985.8656\n",
      "Beta: [array([ 7.7805293e-01,  4.0384954e-01, -1.2709032e-03,  6.4671129e-02,\n",
      "        4.2614993e-04,  1.9516368e+00, -4.5197576e-01,  1.2269619e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 569/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1994.5323\n",
      "Beta: [array([ 7.7606213e-01,  4.0560561e-01, -2.5220247e-04,  6.7291342e-02,\n",
      "        3.8556333e-04,  1.9549327e+00, -4.5456353e-01,  1.2297760e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 570/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1991.4144\n",
      "Beta: [array([ 7.7691281e-01,  4.0452299e-01,  0.0000000e+00,  6.5177731e-02,\n",
      "        3.7836497e-05,  1.9549013e+00, -4.5528632e-01,  1.2275523e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 571/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1984.9614\n",
      "Beta: [array([ 7.7666140e-01,  4.0463805e-01, -1.3292393e-03,  6.5220520e-02,\n",
      "        5.0862305e-05,  1.9567543e+00, -4.5550188e-01,  1.2283764e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 572/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1995.2054\n",
      "Beta: [array([ 0.7776106 ,  0.403457  ,  0.        ,  0.06457587,  0.00237421,\n",
      "        1.9567533 , -0.45625898,  1.2273899 ], dtype=float32)]\n",
      "Epoch 573/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1999.7224\n",
      "Beta: [array([ 0.77706736,  0.40373874,  0.        ,  0.06559455,  0.00264451,\n",
      "        1.9585904 , -0.45722   ,  1.2287792 ], dtype=float32)]\n",
      "Epoch 574/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1988.5480\n",
      "Beta: [array([ 7.7781755e-01,  4.0278152e-01,  0.0000000e+00,  6.4270400e-02,\n",
      "        1.9282971e-03,  1.9589503e+00, -4.5710349e-01,  1.2274717e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 575/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 2003.1938\n",
      "Beta: [array([ 0.775883  ,  0.40457985,  0.        ,  0.06545509,  0.00300765,\n",
      "        1.962156  , -0.45894402,  1.2288774 ], dtype=float32)]\n",
      "Epoch 576/1000\n",
      "40/40 [==============================] - 70s 2s/step - loss: 1989.7686\n",
      "Beta: [array([ 0.77696097,  0.4032554 ,  0.        ,  0.06377969,  0.00316569,\n",
      "        1.961606  , -0.45933312,  1.2271866 ], dtype=float32)]\n",
      "Epoch 577/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1994.3892\n",
      "Beta: [array([ 0.77768284,  0.40231794,  0.        ,  0.06501579,  0.0020553 ,\n",
      "        1.9623793 , -0.45977384,  1.2289504 ], dtype=float32)]\n",
      "Epoch 578/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1981.2732\n",
      "Beta: [array([ 7.8340542e-01,  3.9648864e-01, -2.2602500e-04,  5.9971098e-02,\n",
      "        5.9628785e-03,  1.9583526e+00, -4.5577148e-01,  1.2250823e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 579/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1993.4095\n",
      "Beta: [array([ 7.7650821e-01,  4.0311560e-01, -2.6250019e-04,  6.4093687e-02,\n",
      "        4.0988447e-04,  1.9664297e+00, -4.6048641e-01,  1.2290171e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 580/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1995.5874\n",
      "Beta: [array([ 7.7706099e-01,  4.0233186e-01,  0.0000000e+00,  6.5205954e-02,\n",
      "        7.2742917e-04,  1.9668596e+00, -4.6049061e-01,  1.2301733e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 581/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 2002.4794\n",
      "Beta: [array([ 7.7696651e-01,  4.0221351e-01,  0.0000000e+00,  6.6163845e-02,\n",
      "        1.6098171e-03,  1.9686981e+00, -4.6088690e-01,  1.2318361e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 582/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1992.8092\n",
      "Beta: [array([ 7.7824688e-01,  4.0072480e-01, -1.4397486e-03,  6.4273700e-02,\n",
      "        1.2056585e-03,  1.9687643e+00, -4.6002734e-01,  1.2304134e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 583/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1983.2968\n",
      "Beta: [array([ 7.7926838e-01,  3.9948055e-01, -1.7866361e-03,  6.2348600e-02,\n",
      "        1.0311432e-03,  1.9685696e+00, -4.6078658e-01,  1.2280203e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 584/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 2005.7402\n",
      "Beta: [array([ 7.7560586e-01,  4.0302497e-01, -4.5533180e-03,  6.5912195e-02,\n",
      "        1.7701561e-03,  1.9724433e+00, -4.6613815e-01,  1.2309542e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 585/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1990.0601\n",
      "Beta: [array([ 7.8081143e-01,  3.9758256e-01, -6.6244166e-04,  6.0669225e-02,\n",
      "        4.5470567e-03,  1.9693362e+00, -4.6107888e-01,  1.2270787e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 586/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1997.2552\n",
      "Beta: [array([ 7.7653199e-01,  4.0163505e-01, -2.8695345e-03,  6.5379784e-02,\n",
      "        5.5868179e-04,  1.9742084e+00, -4.6601504e-01,  1.2309914e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 587/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1998.4486\n",
      "Beta: [array([ 7.7847588e-01,  3.9953968e-01,  0.0000000e+00,  6.2783092e-02,\n",
      "        7.2219817e-04,  1.9745678e+00, -4.6422872e-01,  1.2301239e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 588/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1986.0958\n",
      "Beta: [array([ 7.8211445e-01,  3.9566392e-01, -2.7330098e-04,  5.9800923e-02,\n",
      "        3.3128546e-03,  1.9714894e+00, -4.6249822e-01,  1.2266355e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 589/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1993.8312\n",
      "Beta: [array([ 7.79158533e-01,  3.98407549e-01, -1.96500827e-04,  6.28567487e-02,\n",
      "        1.19632845e-04,  1.97583735e+00, -4.66189951e-01,  1.22980046e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 590/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1996.2795\n",
      "Beta: [array([ 7.7931631e-01,  3.9804769e-01,  0.0000000e+00,  6.2871769e-02,\n",
      "        1.9033793e-04,  1.9772923e+00, -4.6576396e-01,  1.2306664e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 591/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1989.6028\n",
      "Beta: [array([ 0.77997136,  0.3972083 ,  0.        ,  0.06253703, -0.        ,\n",
      "        1.977324  , -0.46605512,  1.2302327 ], dtype=float32)]\n",
      "Epoch 592/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1992.5134\n",
      "Beta: [array([ 7.8111410e-01,  3.9588425e-01, -8.8984008e-05,  6.1461158e-02,\n",
      "        1.2945187e-04,  1.9778600e+00, -4.6547699e-01,  1.2299865e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 593/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 1995.4634\n",
      "Beta: [array([ 7.8017163e-01,  3.9665958e-01, -7.8111998e-04,  6.3518763e-02,\n",
      "       -0.0000000e+00,  1.9801918e+00, -4.6486390e-01,  1.2328391e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 594/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1992.7393\n",
      "Beta: [array([ 7.8064781e-01,  3.9596462e-01, -1.2644744e-05,  6.1832447e-02,\n",
      "       -0.0000000e+00,  1.9803112e+00, -4.6673146e-01,  1.2305743e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 595/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 2000.1923\n",
      "Beta: [array([ 7.7807164e-01,  3.9829701e-01, -6.6914980e-04,  6.4134374e-02,\n",
      "        3.0094216e-04,  1.9836671e+00, -4.6980792e-01,  1.2324018e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 596/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1997.2804\n",
      "Beta: [array([ 7.8015518e-01,  3.9603713e-01, -4.5438406e-05,  6.2546164e-02,\n",
      "        2.3373002e-05,  1.9837016e+00, -4.6784893e-01,  1.2318481e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 597/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1992.4618\n",
      "Beta: [array([ 0.78333765,  0.3927004 ,  0.        ,  0.0598957 ,  0.00300075,\n",
      "        1.9806714 , -0.46750167,  1.228819  ], dtype=float32)]\n",
      "Epoch 598/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 2007.1492\n",
      "Beta: [array([ 7.7927989e-01,  3.9655066e-01, -2.4018014e-05,  6.3383594e-02,\n",
      "        1.5955971e-03,  1.9873407e+00, -4.6950364e-01,  1.2339579e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 599/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 2000.4568\n",
      "Beta: [array([ 7.7999645e-01,  3.9559525e-01,  0.0000000e+00,  6.2470134e-02,\n",
      "        1.2909707e-03,  1.9871750e+00, -4.7034982e-01,  1.2323101e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 600/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 2000.8954\n",
      "Beta: [array([ 7.8083390e-01,  3.9459470e-01,  0.0000000e+00,  6.2228318e-02,\n",
      "        4.6482711e-04,  1.9878011e+00, -4.7074568e-01,  1.2325249e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 601/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 2000.8746\n",
      "Beta: [array([ 7.8034377e-01,  3.9487010e-01, -4.5931505e-05,  6.2095642e-02,\n",
      "        8.9041254e-04,  1.9895755e+00, -4.7070220e-01,  1.2327149e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 602/1000\n",
      "40/40 [==============================] - 70s 2s/step - loss: 2004.8916\n",
      "Beta: [array([ 7.8057206e-01,  3.9448228e-01, -1.5507125e-04,  6.3806474e-02,\n",
      "        3.9501555e-04,  1.9909519e+00, -4.7116795e-01,  1.2351081e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 603/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 2008.4170\n",
      "Beta: [array([ 7.7862531e-01,  3.9626265e-01, -2.2895387e-03,  6.4284392e-02,\n",
      "        6.1242841e-04,  1.9924604e+00, -4.7517541e-01,  1.2336358e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 604/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 2005.7142\n",
      "Beta: [array([ 7.8095490e-01,  3.9366797e-01,  0.0000000e+00,  6.2305313e-02,\n",
      "        1.4709126e-03,  1.9919807e+00, -4.7429094e-01,  1.2326912e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 605/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 2001.4828\n",
      "Beta: [array([ 7.8069007e-01,  3.9374745e-01, -4.0602489e-04,  6.3123100e-02,\n",
      "        4.2605383e-04,  1.9932816e+00, -4.7478971e-01,  1.2334136e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 606/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 2005.5844\n",
      "Beta: [array([ 7.8098404e-01,  3.9337349e-01,  0.0000000e+00,  6.2932462e-02,\n",
      "        9.5810147e-04,  1.9953740e+00, -4.7334215e-01,  1.2348963e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 607/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1998.8538\n",
      "Beta: [array([ 0.7837    ,  0.3904546 ,  0.        ,  0.05973796,  0.00278348,\n",
      "        1.9932846 , -0.47378594,  1.2313555 ], dtype=float32)]\n",
      "Epoch 608/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 2000.3296\n",
      "Beta: [array([ 7.8059942e-01,  3.9329922e-01, -8.4114086e-04,  6.3438274e-02,\n",
      "        4.7572679e-04,  1.9970634e+00, -4.7624147e-01,  1.2346215e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 609/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1999.7070\n",
      "Beta: [array([ 7.8256494e-01,  3.9118326e-01, -8.0807816e-04,  6.0504746e-02,\n",
      "        4.8935809e-04,  1.9976555e+00, -4.7395793e-01,  1.2333990e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 610/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 2003.9728\n",
      "Beta: [array([ 7.8066391e-01,  3.9292702e-01, -1.5101009e-03,  6.2095616e-02,\n",
      "        6.7750819e-04,  2.0001781e+00, -4.7788531e-01,  1.2343626e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 611/1000\n",
      "40/40 [==============================] - 69s 2s/step - loss: 2011.0444\n",
      "Beta: [array([ 0.7820748 ,  0.3912945 ,  0.        ,  0.06180695,  0.00253462,\n",
      "        2.0002642 , -0.47733736,  1.2345725 ], dtype=float32)]\n",
      "Epoch 612/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1997.7040\n",
      "Beta: [array([ 7.8334183e-01,  3.8980603e-01, -1.1333546e-03,  6.0136873e-02,\n",
      "        2.2136739e-03,  2.0001230e+00, -4.7607857e-01,  1.2328080e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 613/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1992.5024\n",
      "Beta: [array([ 7.8449935e-01,  3.8848230e-01, -4.3547715e-04,  5.8966350e-02,\n",
      "        1.9930331e-03,  2.0000780e+00, -4.7579300e-01,  1.2320979e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 614/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 2003.1394\n",
      "Beta: [array([ 7.8259486e-01,  3.9015323e-01, -9.5575507e-04,  6.1897710e-02,\n",
      "        1.6437419e-04,  2.0027106e+00, -4.7901747e-01,  1.2345320e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 615/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 2000.0472\n",
      "Beta: [array([ 7.8490454e-01,  3.8766599e-01, -7.5680749e-05,  6.0153063e-02,\n",
      "        4.3772889e-04,  2.0021498e+00, -4.7633213e-01,  1.2334586e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 616/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 2003.7994\n",
      "Beta: [array([ 0.78365767,  0.38878557,  0.        ,  0.06201107, -0.        ,\n",
      "        2.0045412 , -0.4764556 ,  1.2358046 ], dtype=float32)]\n",
      "Epoch 617/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1997.5736\n",
      "Beta: [array([ 7.8437352e-01,  3.8782880e-01, -9.3871022e-05,  5.9703022e-02,\n",
      "       -0.0000000e+00,  2.0047991e+00, -4.7769478e-01,  1.2333920e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 618/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1994.7238\n",
      "Beta: [array([ 7.8500205e-01,  3.8705382e-01, -1.3431655e-03,  5.9593070e-02,\n",
      "       -0.0000000e+00,  2.0060222e+00, -4.7735479e-01,  1.2344846e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 619/1000\n",
      "40/40 [==============================] - 67s 2s/step - loss: 1999.4380\n",
      "Beta: [array([ 7.8371644e-01,  3.8809258e-01, -8.1876153e-04,  6.0685176e-02,\n",
      "       -0.0000000e+00,  2.0083442e+00, -4.7911331e-01,  1.2350777e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 620/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 1998.3306\n",
      "Beta: [array([ 7.8417337e-01,  3.8745731e-01, -2.8178535e-04,  5.9517398e-02,\n",
      "       -0.0000000e+00,  2.0090394e+00, -4.7894245e-01,  1.2343711e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 621/1000\n",
      "40/40 [==============================] - 68s 2s/step - loss: 2007.9962\n",
      "Beta: [array([ 0.78303283,  0.38841486,  0.        ,  0.06136072, -0.        ,\n",
      "        2.0115905 , -0.48063537,  1.2364264 ], dtype=float32)]\n",
      "Epoch 622/1000\n",
      "40/40 [==============================] - 71s 2s/step - loss: 2012.4310\n",
      "Beta: [array([ 7.8269792e-01,  3.8862130e-01, -5.4594944e-04,  6.3291915e-02,\n",
      "       -0.0000000e+00,  2.0119500e+00, -4.8231241e-01,  1.2375301e+00],\n",
      "      dtype=float32)]\n",
      "Epoch 623/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mfit_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madstock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43memission_real\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/AttributionSingleUser/src/hmm_package/generate_hmm.py:335\u001B[0m, in \u001B[0;36mfit_model\u001B[0;34m(model, adstock, emission_real)\u001B[0m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit_model\u001B[39m(model, adstock, emission_real):\n\u001B[1;32m    334\u001B[0m     print_weights \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mLambdaCallback(on_epoch_begin\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m batch, logs: \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBeta: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(model\u001B[38;5;241m.\u001B[39mget_weights())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m--> 335\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43madstock\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    336\u001B[0m \u001B[43m                     \u001B[49m\u001B[43memission_real\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    337\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mEPOCHS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    338\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    339\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mprint_weights\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    340\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/engine/training.py:1384\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1377\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1378\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   1379\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   1380\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[1;32m   1381\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m   1382\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m   1383\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1384\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1385\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1386\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/engine/training.py:1021\u001B[0m, in \u001B[0;36mModel.make_train_function.<locals>.train_function\u001B[0;34m(iterator)\u001B[0m\n\u001B[1;32m   1019\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_function\u001B[39m(iterator):\n\u001B[1;32m   1020\u001B[0m   \u001B[38;5;124;03m\"\"\"Runs a training execution with a single step.\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1021\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mstep_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/engine/training.py:1010\u001B[0m, in \u001B[0;36mModel.make_train_function.<locals>.step_function\u001B[0;34m(model, iterator)\u001B[0m\n\u001B[1;32m   1007\u001B[0m   run_step \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mfunction(\n\u001B[1;32m   1008\u001B[0m       run_step, jit_compile\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, experimental_relax_shapes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   1009\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(iterator)\n\u001B[0;32m-> 1010\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistribute_strategy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_step\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1011\u001B[0m outputs \u001B[38;5;241m=\u001B[39m reduce_per_replica(\n\u001B[1;32m   1012\u001B[0m     outputs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistribute_strategy, reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfirst\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m   1013\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1312\u001B[0m, in \u001B[0;36mStrategyBase.run\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m   1307\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscope():\n\u001B[1;32m   1308\u001B[0m   \u001B[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001B[39;00m\n\u001B[1;32m   1309\u001B[0m   \u001B[38;5;66;03m# applied when the caller is also in Eager mode.\u001B[39;00m\n\u001B[1;32m   1310\u001B[0m   fn \u001B[38;5;241m=\u001B[39m autograph\u001B[38;5;241m.\u001B[39mtf_convert(\n\u001B[1;32m   1311\u001B[0m       fn, autograph_ctx\u001B[38;5;241m.\u001B[39mcontrol_status_ctx(), convert_by_default\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m-> 1312\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_extended\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_for_each_replica\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2888\u001B[0m, in \u001B[0;36mStrategyExtendedV1.call_for_each_replica\u001B[0;34m(self, fn, args, kwargs)\u001B[0m\n\u001B[1;32m   2886\u001B[0m   kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m   2887\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_container_strategy()\u001B[38;5;241m.\u001B[39mscope():\n\u001B[0;32m-> 2888\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_for_each_replica\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3689\u001B[0m, in \u001B[0;36m_DefaultDistributionExtended._call_for_each_replica\u001B[0;34m(self, fn, args, kwargs)\u001B[0m\n\u001B[1;32m   3687\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_call_for_each_replica\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn, args, kwargs):\n\u001B[1;32m   3688\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ReplicaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_container_strategy(), replica_id_in_sync_group\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m-> 3689\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:595\u001B[0m, in \u001B[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    593\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    594\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ag_ctx\u001B[38;5;241m.\u001B[39mControlStatusCtx(status\u001B[38;5;241m=\u001B[39mag_ctx\u001B[38;5;241m.\u001B[39mStatus\u001B[38;5;241m.\u001B[39mUNSPECIFIED):\n\u001B[0;32m--> 595\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/engine/training.py:1000\u001B[0m, in \u001B[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m    999\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_step\u001B[39m(data):\n\u001B[0;32m-> 1000\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1001\u001B[0m   \u001B[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001B[39;00m\n\u001B[1;32m   1002\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/engine/training.py:859\u001B[0m, in \u001B[0;36mModel.train_step\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m    857\u001B[0m \u001B[38;5;66;03m# Run forward pass.\u001B[39;00m\n\u001B[1;32m    858\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mGradientTape() \u001B[38;5;28;01mas\u001B[39;00m tape:\n\u001B[0;32m--> 859\u001B[0m   y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    860\u001B[0m   loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss(x, y, y_pred, sample_weight)\n\u001B[1;32m    861\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_target_and_loss(y, loss)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/engine/base_layer.py:1096\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1092\u001B[0m   inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_cast_inputs(inputs, input_list)\n\u001B[1;32m   1094\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m autocast_variable\u001B[38;5;241m.\u001B[39menable_auto_cast_variables(\n\u001B[1;32m   1095\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_dtype_object):\n\u001B[0;32m-> 1096\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mcall_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_activity_regularizer:\n\u001B[1;32m   1099\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:92\u001B[0m, in \u001B[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     90\u001B[0m bound_signature \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     91\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 92\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     94\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_keras_call_info_injected\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m     95\u001B[0m     \u001B[38;5;66;03m# Only inject info for the innermost failing call\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/engine/functional.py:451\u001B[0m, in \u001B[0;36mFunctional.call\u001B[0;34m(self, inputs, training, mask)\u001B[0m\n\u001B[1;32m    432\u001B[0m \u001B[38;5;129m@doc_controls\u001B[39m\u001B[38;5;241m.\u001B[39mdo_not_doc_inheritable\n\u001B[1;32m    433\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, mask\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    434\u001B[0m   \u001B[38;5;124;03m\"\"\"Calls the model on new inputs.\u001B[39;00m\n\u001B[1;32m    435\u001B[0m \n\u001B[1;32m    436\u001B[0m \u001B[38;5;124;03m  In this case `call` just reapplies\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    449\u001B[0m \u001B[38;5;124;03m      a list of tensors if there are more than one outputs.\u001B[39;00m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m--> 451\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_internal_graph\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    452\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmask\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/engine/functional.py:589\u001B[0m, in \u001B[0;36mFunctional._run_internal_graph\u001B[0;34m(self, inputs, training, mask)\u001B[0m\n\u001B[1;32m    586\u001B[0m   \u001B[38;5;28;01mcontinue\u001B[39;00m  \u001B[38;5;66;03m# Node is not computable, try skipping.\u001B[39;00m\n\u001B[1;32m    588\u001B[0m args, kwargs \u001B[38;5;241m=\u001B[39m node\u001B[38;5;241m.\u001B[39mmap_arguments(tensor_dict)\n\u001B[0;32m--> 589\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mnode\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    591\u001B[0m \u001B[38;5;66;03m# Update tensor_dict.\u001B[39;00m\n\u001B[1;32m    592\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x_id, y \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(node\u001B[38;5;241m.\u001B[39mflat_output_ids, tf\u001B[38;5;241m.\u001B[39mnest\u001B[38;5;241m.\u001B[39mflatten(outputs)):\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow_probability/python/layers/distribution_layer.py:220\u001B[0m, in \u001B[0;36mDistributionLambda.__call__\u001B[0;34m(self, inputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    218\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    219\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enter_dunder_call \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 220\u001B[0m   distribution, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mDistributionLambda\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    221\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    222\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enter_dunder_call \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    223\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m distribution\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/engine/base_layer.py:1096\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1092\u001B[0m   inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_cast_inputs(inputs, input_list)\n\u001B[1;32m   1094\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m autocast_variable\u001B[38;5;241m.\u001B[39menable_auto_cast_variables(\n\u001B[1;32m   1095\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_dtype_object):\n\u001B[0;32m-> 1096\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mcall_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_activity_regularizer:\n\u001B[1;32m   1099\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:92\u001B[0m, in \u001B[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     90\u001B[0m bound_signature \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     91\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 92\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     94\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_keras_call_info_injected\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m     95\u001B[0m     \u001B[38;5;66;03m# Only inject info for the innermost failing call\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow_probability/python/layers/distribution_layer.py:226\u001B[0m, in \u001B[0;36mDistributionLambda.call\u001B[0;34m(self, inputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    225\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 226\u001B[0m   distribution, value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mDistributionLambda\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    227\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    228\u001B[0m   \u001B[38;5;66;03m# We always save the most recently built distribution variables for tracking\u001B[39;00m\n\u001B[1;32m    229\u001B[0m   \u001B[38;5;66;03m# purposes.\u001B[39;00m\n\u001B[1;32m    230\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_most_recently_built_distribution_vars \u001B[38;5;241m=\u001B[39m distribution\u001B[38;5;241m.\u001B[39mvariables\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/keras/layers/core/lambda_layer.py:196\u001B[0m, in \u001B[0;36mLambda.call\u001B[0;34m(self, inputs, mask, training)\u001B[0m\n\u001B[1;32m    192\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m var\n\u001B[1;32m    194\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mGradientTape(watch_accessed_variables\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m tape,\\\n\u001B[1;32m    195\u001B[0m     tf\u001B[38;5;241m.\u001B[39mvariable_creator_scope(_variable_creator):\n\u001B[0;32m--> 196\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_variables(created_variables, tape\u001B[38;5;241m.\u001B[39mwatched_variables())\n\u001B[1;32m    198\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow_probability/python/layers/distribution_layer.py:180\u001B[0m, in \u001B[0;36mDistributionLambda.__init__.<locals>._fn\u001B[0;34m(*fargs, **fkwargs)\u001B[0m\n\u001B[1;32m    171\u001B[0m distribution \u001B[38;5;241m=\u001B[39m dtc\u001B[38;5;241m.\u001B[39m_TensorCoercible(  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    172\u001B[0m     distribution\u001B[38;5;241m=\u001B[39md,\n\u001B[1;32m    173\u001B[0m     convert_to_tensor_fn\u001B[38;5;241m=\u001B[39mmaybe_composite_convert_to_tensor_fn)\n\u001B[1;32m    175\u001B[0m \u001B[38;5;66;03m# Calling `distrbution._value()` is equivalent to:\u001B[39;00m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;66;03m# from tensorflow.python.framework import ops\u001B[39;00m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;66;03m# value = ops.convert_to_tensor_or_composite(distribution)\u001B[39;00m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;66;03m# We'd prefer to call ops.convert_to_tensor_or_composite but do not,\u001B[39;00m\n\u001B[1;32m    179\u001B[0m \u001B[38;5;66;03m# favoring our own non-public API over TF's.\u001B[39;00m\n\u001B[0;32m--> 180\u001B[0m value \u001B[38;5;241m=\u001B[39m \u001B[43mdistribution\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    182\u001B[0m \u001B[38;5;66;03m# TODO(b/126056144): Remove silent handle once we identify how/why Keras\u001B[39;00m\n\u001B[1;32m    183\u001B[0m \u001B[38;5;66;03m# is losing the distribution handle for activity_regularizer.\u001B[39;00m\n\u001B[1;32m    184\u001B[0m value\u001B[38;5;241m.\u001B[39m_tfp_distribution \u001B[38;5;241m=\u001B[39m distribution  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow_probability/python/layers/internal/distribution_tensor_coercible.py:213\u001B[0m, in \u001B[0;36m_TensorCoercible._value\u001B[0;34m(self, dtype, name, as_ref)\u001B[0m\n\u001B[1;32m    204\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[1;32m    205\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFailed to convert object of type \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m to Tensor. Contents: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    206\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCall `distribution.set_tensor_conversion(lambda self: ...)` to \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    209\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m results in `tf.convert_to_tensor(x)` being identical to \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    210\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m`x.mean()`.\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m), \u001B[38;5;28mself\u001B[39m))\n\u001B[1;32m    211\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_name_and_control_scope(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m    212\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_concrete_value \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m--> 213\u001B[0m       \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_convert_to_tensor_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor_distribution\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    214\u001B[0m       \u001B[38;5;28;01mif\u001B[39;00m callable(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_to_tensor_fn)\n\u001B[1;32m    215\u001B[0m       \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_to_tensor_fn)\n\u001B[1;32m    216\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mis_tensor(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_concrete_value) \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    217\u001B[0m       \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_concrete_value,\n\u001B[1;32m    218\u001B[0m                      composite_tensor\u001B[38;5;241m.\u001B[39mCompositeTensor)):\n\u001B[1;32m    219\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_concrete_value \u001B[38;5;241m=\u001B[39m nest_util\u001B[38;5;241m.\u001B[39mconvert_to_nested_tensor(  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    220\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_concrete_value,\n\u001B[1;32m    221\u001B[0m         name\u001B[38;5;241m=\u001B[39mname \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconcrete_value\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    222\u001B[0m         dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[1;32m    223\u001B[0m         dtype_hint\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtensor_distribution\u001B[38;5;241m.\u001B[39mdtype)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow_probability/python/distributions/distribution.py:1234\u001B[0m, in \u001B[0;36mDistribution.sample\u001B[0;34m(self, sample_shape, seed, name, **kwargs)\u001B[0m\n\u001B[1;32m   1219\u001B[0m \u001B[38;5;124;03m\"\"\"Generate samples of the specified shape.\u001B[39;00m\n\u001B[1;32m   1220\u001B[0m \n\u001B[1;32m   1221\u001B[0m \u001B[38;5;124;03mNote that a call to `sample()` without arguments will generate a single\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1231\u001B[0m \u001B[38;5;124;03m  samples: a `Tensor` with prepended dimensions `sample_shape`.\u001B[39;00m\n\u001B[1;32m   1232\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1233\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_name_and_control_scope(name):\n\u001B[0;32m-> 1234\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_sample_n\u001B[49m\u001B[43m(\u001B[49m\u001B[43msample_shape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow_probability/python/distributions/distribution.py:1211\u001B[0m, in \u001B[0;36mDistribution._call_sample_n\u001B[0;34m(self, sample_shape, seed, **kwargs)\u001B[0m\n\u001B[1;32m   1207\u001B[0m sample_shape \u001B[38;5;241m=\u001B[39m ps\u001B[38;5;241m.\u001B[39mconvert_to_shape_tensor(\n\u001B[1;32m   1208\u001B[0m     ps\u001B[38;5;241m.\u001B[39mcast(sample_shape, tf\u001B[38;5;241m.\u001B[39mint32), name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msample_shape\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m   1209\u001B[0m sample_shape, n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_sample_shape_to_vector(\n\u001B[1;32m   1210\u001B[0m     sample_shape, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msample_shape\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m-> 1211\u001B[0m samples \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sample_n\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1212\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcallable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mseed\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1213\u001B[0m samples \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mnest\u001B[38;5;241m.\u001B[39mmap_structure(\n\u001B[1;32m   1214\u001B[0m     \u001B[38;5;28;01mlambda\u001B[39;00m x: tf\u001B[38;5;241m.\u001B[39mreshape(x, ps\u001B[38;5;241m.\u001B[39mconcat([sample_shape, ps\u001B[38;5;241m.\u001B[39mshape(x)[\u001B[38;5;241m1\u001B[39m:]], \u001B[38;5;241m0\u001B[39m)),\n\u001B[1;32m   1215\u001B[0m     samples)\n\u001B[1;32m   1216\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_sample_static_shape(samples, sample_shape)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow_probability/python/distributions/hidden_markov_model.py:389\u001B[0m, in \u001B[0;36mHiddenMarkovModel._sample_n\u001B[0;34m(self, n, seed)\u001B[0m\n\u001B[1;32m    384\u001B[0m   multiples \u001B[38;5;241m=\u001B[39m ps\u001B[38;5;241m.\u001B[39mconcat([[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_steps],\n\u001B[1;32m    385\u001B[0m                          ps\u001B[38;5;241m.\u001B[39mones(ps\u001B[38;5;241m.\u001B[39mrank(init_state), tf\u001B[38;5;241m.\u001B[39mint32)],\n\u001B[1;32m    386\u001B[0m                         axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    387\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mtile(init_state[tf\u001B[38;5;241m.\u001B[39mnewaxis, \u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m], multiples)\n\u001B[0;32m--> 389\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[43mps\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcond\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    390\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_steps\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    391\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_scan_multiple_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    392\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_scan_one_step\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    394\u001B[0m hidden_one_hot \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mone_hot(hidden_states, num_states,\n\u001B[1;32m    395\u001B[0m                             dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_observation_distribution\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[1;32m    396\u001B[0m \u001B[38;5;66;03m# hidden_one_hot :: num_steps n batch_size num_states\u001B[39;00m\n\u001B[1;32m    397\u001B[0m \n\u001B[1;32m    398\u001B[0m \u001B[38;5;66;03m# The observation distribution batch size might not match\u001B[39;00m\n\u001B[1;32m    399\u001B[0m \u001B[38;5;66;03m# the required batch size so as with the initial and\u001B[39;00m\n\u001B[1;32m    400\u001B[0m \u001B[38;5;66;03m# transition distributions we generate more samples and\u001B[39;00m\n\u001B[1;32m    401\u001B[0m \u001B[38;5;66;03m# reshape.\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow_probability/python/internal/prefer_static.py:260\u001B[0m, in \u001B[0;36mcond\u001B[0;34m(pred, true_fn, false_fn, name)\u001B[0m\n\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pred_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    259\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m pred_value:\n\u001B[0;32m--> 260\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrue_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    261\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    262\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m false_fn()\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow_probability/python/distributions/hidden_markov_model.py:376\u001B[0m, in \u001B[0;36mHiddenMarkovModel._sample_n.<locals>._scan_multiple_steps\u001B[0;34m()\u001B[0m\n\u001B[1;32m    374\u001B[0m \u001B[38;5;124;03m\"\"\"Take multiple steps with tf.scan.\"\"\"\u001B[39;00m\n\u001B[1;32m    375\u001B[0m step \u001B[38;5;241m=\u001B[39m ps\u001B[38;5;241m.\u001B[39mrange(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_steps \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mint32)\n\u001B[0;32m--> 376\u001B[0m hidden_states, _ \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscan\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgenerate_step\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    377\u001B[0m \u001B[43m                           \u001B[49m\u001B[43minitializer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43minit_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscan_seed\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;66;03m# TODO(b/115618503): add/use prepend_initializer to tf.scan\u001B[39;00m\n\u001B[1;32m    380\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mconcat([[init_state],\n\u001B[1;32m    381\u001B[0m                   hidden_states], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1082\u001B[0m, in \u001B[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1080\u001B[0m \u001B[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001B[39;00m\n\u001B[1;32m   1081\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1082\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdispatch_target\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1083\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[1;32m   1084\u001B[0m   \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[1;32m   1085\u001B[0m   \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[1;32m   1086\u001B[0m   result \u001B[38;5;241m=\u001B[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:616\u001B[0m, in \u001B[0;36mdeprecated_arg_values.<locals>.deprecated_wrapper.<locals>.new_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    609\u001B[0m           _PRINTED_WARNING[(func, arg_name)] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    610\u001B[0m         logging\u001B[38;5;241m.\u001B[39mwarning(\n\u001B[1;32m    611\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFrom \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: calling \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m (from \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m) with \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m=\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m is deprecated and \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    612\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwill be removed \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mInstructions for updating:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    613\u001B[0m             _call_location(), decorator_utils\u001B[38;5;241m.\u001B[39mget_qualified_name(func),\n\u001B[1;32m    614\u001B[0m             func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__module__\u001B[39m, arg_name, arg_value, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124min a future version\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    615\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m date \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mafter \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m date), instructions)\n\u001B[0;32m--> 616\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/ops/functional_ops.py:805\u001B[0m, in \u001B[0;36mscan_v2\u001B[0;34m(fn, elems, initializer, parallel_iterations, back_prop, swap_memory, infer_shape, reverse, name)\u001B[0m\n\u001B[1;32m    693\u001B[0m \u001B[38;5;129m@tf_export\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscan\u001B[39m\u001B[38;5;124m\"\u001B[39m, v1\u001B[38;5;241m=\u001B[39m[])\n\u001B[1;32m    694\u001B[0m \u001B[38;5;129m@dispatch\u001B[39m\u001B[38;5;241m.\u001B[39madd_dispatch_support\n\u001B[1;32m    695\u001B[0m \u001B[38;5;129m@deprecation\u001B[39m\u001B[38;5;241m.\u001B[39mdeprecated_arg_values(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    711\u001B[0m             reverse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    712\u001B[0m             name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    713\u001B[0m   \u001B[38;5;124;03m\"\"\"scan on the list of tensors unpacked from `elems` on dimension 0.\u001B[39;00m\n\u001B[1;32m    714\u001B[0m \n\u001B[1;32m    715\u001B[0m \u001B[38;5;124;03m  The simplest version of `scan` repeatedly applies the callable `fn` to a\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    803\u001B[0m \u001B[38;5;124;03m    ```\u001B[39;00m\n\u001B[1;32m    804\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m--> 805\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mscan\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    806\u001B[0m \u001B[43m      \u001B[49m\u001B[43mfn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    807\u001B[0m \u001B[43m      \u001B[49m\u001B[43melems\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43melems\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    808\u001B[0m \u001B[43m      \u001B[49m\u001B[43minitializer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitializer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    809\u001B[0m \u001B[43m      \u001B[49m\u001B[43mparallel_iterations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparallel_iterations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    810\u001B[0m \u001B[43m      \u001B[49m\u001B[43mback_prop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mback_prop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    811\u001B[0m \u001B[43m      \u001B[49m\u001B[43mswap_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mswap_memory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    812\u001B[0m \u001B[43m      \u001B[49m\u001B[43minfer_shape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minfer_shape\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    813\u001B[0m \u001B[43m      \u001B[49m\u001B[43mreverse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreverse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    814\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1082\u001B[0m, in \u001B[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1080\u001B[0m \u001B[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001B[39;00m\n\u001B[1;32m   1081\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1082\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdispatch_target\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1083\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[1;32m   1084\u001B[0m   \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[1;32m   1085\u001B[0m   \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[1;32m   1086\u001B[0m   result \u001B[38;5;241m=\u001B[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/ops/functional_ops.py:663\u001B[0m, in \u001B[0;36mscan\u001B[0;34m(fn, elems, initializer, parallel_iterations, back_prop, swap_memory, infer_shape, reverse, name)\u001B[0m\n\u001B[1;32m    661\u001B[0m   initial_i \u001B[38;5;241m=\u001B[39m i\n\u001B[1;32m    662\u001B[0m   condition \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m i, _1, _2: i \u001B[38;5;241m<\u001B[39m n\n\u001B[0;32m--> 663\u001B[0m _, _, r_a \u001B[38;5;241m=\u001B[39m \u001B[43mcontrol_flow_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwhile_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    664\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcondition\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    665\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompute\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43minitial_i\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma_flat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccs_ta\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    666\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparallel_iterations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparallel_iterations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    667\u001B[0m \u001B[43m    \u001B[49m\u001B[43mback_prop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mback_prop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    668\u001B[0m \u001B[43m    \u001B[49m\u001B[43mswap_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mswap_memory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    669\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmaximum_iterations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    671\u001B[0m results_flat \u001B[38;5;241m=\u001B[39m [r\u001B[38;5;241m.\u001B[39mstack() \u001B[38;5;28;01mfor\u001B[39;00m r \u001B[38;5;129;01min\u001B[39;00m r_a]\n\u001B[1;32m    673\u001B[0m n_static \u001B[38;5;241m=\u001B[39m tensor_shape\u001B[38;5;241m.\u001B[39mDimension(\n\u001B[1;32m    674\u001B[0m     tensor_shape\u001B[38;5;241m.\u001B[39mdimension_value(\n\u001B[1;32m    675\u001B[0m         elems_flat[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_shape()\u001B[38;5;241m.\u001B[39mwith_rank_at_least(\u001B[38;5;241m1\u001B[39m)[\u001B[38;5;241m0\u001B[39m]))\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py:2795\u001B[0m, in \u001B[0;36mwhile_loop\u001B[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001B[0m\n\u001B[1;32m   2792\u001B[0m loop_var_structure \u001B[38;5;241m=\u001B[39m nest\u001B[38;5;241m.\u001B[39mmap_structure(type_spec\u001B[38;5;241m.\u001B[39mtype_spec_from_value,\n\u001B[1;32m   2793\u001B[0m                                         \u001B[38;5;28mlist\u001B[39m(loop_vars))\n\u001B[1;32m   2794\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m cond(\u001B[38;5;241m*\u001B[39mloop_vars):\n\u001B[0;32m-> 2795\u001B[0m   loop_vars \u001B[38;5;241m=\u001B[39m \u001B[43mbody\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mloop_vars\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2796\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m try_to_pack \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(loop_vars, (\u001B[38;5;28mlist\u001B[39m, _basetuple)):\n\u001B[1;32m   2797\u001B[0m     packed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py:2786\u001B[0m, in \u001B[0;36mwhile_loop.<locals>.<lambda>\u001B[0;34m(i, lv)\u001B[0m\n\u001B[1;32m   2783\u001B[0m     loop_vars \u001B[38;5;241m=\u001B[39m (counter, loop_vars)\n\u001B[1;32m   2784\u001B[0m     cond \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m i, lv: (  \u001B[38;5;66;03m# pylint: disable=g-long-lambda\u001B[39;00m\n\u001B[1;32m   2785\u001B[0m         math_ops\u001B[38;5;241m.\u001B[39mlogical_and(i \u001B[38;5;241m<\u001B[39m maximum_iterations, orig_cond(\u001B[38;5;241m*\u001B[39mlv)))\n\u001B[0;32m-> 2786\u001B[0m     body \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m i, lv: (i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, \u001B[43morig_body\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mlv\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   2787\u001B[0m   try_to_pack \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   2789\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m executing_eagerly:\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow/python/ops/functional_ops.py:646\u001B[0m, in \u001B[0;36mscan.<locals>.compute\u001B[0;34m(i, a_flat, tas)\u001B[0m\n\u001B[1;32m    644\u001B[0m packed_elems \u001B[38;5;241m=\u001B[39m input_pack([elem_ta\u001B[38;5;241m.\u001B[39mread(i) \u001B[38;5;28;01mfor\u001B[39;00m elem_ta \u001B[38;5;129;01min\u001B[39;00m elems_ta])\n\u001B[1;32m    645\u001B[0m packed_a \u001B[38;5;241m=\u001B[39m output_pack(a_flat)\n\u001B[0;32m--> 646\u001B[0m a_out \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpacked_a\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpacked_elems\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    647\u001B[0m nest\u001B[38;5;241m.\u001B[39massert_same_structure(elems \u001B[38;5;28;01mif\u001B[39;00m initializer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m initializer,\n\u001B[1;32m    648\u001B[0m                            a_out)\n\u001B[1;32m    649\u001B[0m flat_a_out \u001B[38;5;241m=\u001B[39m output_flatten(a_out)\n",
      "File \u001B[0;32m~/Library/Caches/JetBrains/PyCharm2021.3/demo/PyCharmLearningProject/venv/lib/python3.8/site-packages/tensorflow_probability/python/distributions/hidden_markov_model.py:348\u001B[0m, in \u001B[0;36mHiddenMarkovModel._sample_n.<locals>.generate_step\u001B[0;34m(state_and_seed, step)\u001B[0m\n\u001B[1;32m    345\u001B[0m sample_seed, next_seed \u001B[38;5;241m=\u001B[39m samplers\u001B[38;5;241m.\u001B[39msplit_seed(seed)\n\u001B[1;32m    347\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time_varying_transition_distribution:\n\u001B[0;32m--> 348\u001B[0m   gen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_transition_distribution\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msample\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    349\u001B[0m \u001B[43m      \u001B[49m\u001B[43mn\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtransition_repeat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_seed\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    350\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    351\u001B[0m   gen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transition_distribution\u001B[38;5;241m.\u001B[39msample(n \u001B[38;5;241m*\u001B[39m transition_repeat,\n\u001B[1;32m    352\u001B[0m                                              seed\u001B[38;5;241m=\u001B[39msample_seed)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "history = fit_model(model, adstock, emission_real)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=\narray([[[ 0.08950578, -0.09371506,  0.00420926],\n        [-0.02535208,  0.02153634,  0.00381574],\n        [ 0.        ,  0.        ,  0.        ]]], dtype=float32)>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(make_transition_matrix(MU, [ 0.60443544,  0.6717377 , -0.23794842,  0.28381994, -0.        ,\n",
    "        1.0300579 , -0.29468915,  0.808104  ], adstock[0:1]) - make_transition_matrix(MU,BETA, adstock[0:1]), axis=1)/30"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BETA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}